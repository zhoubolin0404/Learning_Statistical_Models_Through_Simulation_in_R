# 交互作用

```{r chapter-status, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
library(kableExtra)
library(tidyverse)
library(webexercises)
```

```{r setup, include=FALSE}
library(kableExtra)
library(tidyverse)

.mk_tib <- function(x) {
  tibble(CBT = rep(c("No CBT", "CBT"), 2),
         Drugs = rep(c("Placebo", "Drug"), each = 2) %>%
           fct_relevel("Placebo"),
         Mood = x)
}

.fac_plot <- function(x) {
  ggplot(.mk_tib(x), aes(Drugs, Mood, color = CBT, group = CBT)) +
    geom_point(aes(shape = CBT)) +
    geom_line() +
    scale_y_continuous(breaks = seq(0, 100, 20)) +
    scale_x_discrete(breaks = c("Placebo", "Drug")) +
    coord_cartesian(ylim = c(0, 100)) 
}

.mean_tbl <- function(x) {
  .mk_tib(x) %>%
    pivot_wider(names_from = "CBT", values_from = "Mood") %>%
    rename(" " = Drugs) %>%
    bind_rows(tibble(` ` = "",
                     `No CBT` = (x[1] + x[3]) / 2,
                     CBT = (x[2] + x[4]) / 2)) %>%
    bind_cols(tibble("  " = c((x[1] + x[2]) / 2,
                              (x[3] + x[4]) / 2,
                              "")))
}

## paste
.p <- paste0

## .fraction
.f <- function(x, y) {
  paste0("\\frac{", x, "}{", y, "}")
}

## y-bar
.yb1 <- function(x) {
  paste0("$\\bar{Y}_{", x, "}$")
}

.yb2 <- function(x) {
  paste0("\\bar{Y}_{", x, "}")
}

## subtraction term
.st <- function(x, y, bracket = NULL) {
  if (is.null(bracket)) {
    paste0(x, " - ", y)
  } else {
    paste0(bracket[1], x, " - ", y, bracket[2])
  }
}

.rb <- c("(", ")")
.dr <- c("\\displaystyle\\left(", "\\right)")
.ds <- c("\\displaystyle\\left[", "\\right]")
```

<!-- understand a common fallacy regarding interactions -->

到目前为止，我们一直专注于估计和解释一个变量或预测变量线性组合对响应变量的影响。然而，往往存在这样的情况，一个预测变量对响应变量的影响取决于另一个预测变量。实际上，我们可以在模型中包含一个**交互**项来估计和解释这种依赖性。

## 连续变量-分类变量交互作用 {#cont-by-cat}

让我们考虑一个简单的虚构例子。假设你对声波干扰对认知表现的影响感兴趣。你的研究中的每个被试在执行一个简单的反应时任务时(尽快对闪光灯做出反应)，被随机分配接受特定水平的声波干扰。你有一种技术，可以自动生成不同水平的背景噪音（例如城市声音的频率和振幅：鸣笛声、钻地声、喧哗声、玻璃破碎声等）。每个参与者在一个随机选择的干扰水平(0到100)下执行任务。你的假设是，城市生活使人们的任务表现更不受声波干扰的影响。你想要比较城市居民和乡村居民(来自更安静的乡村环境)之间干扰与表现关系的差异。

你有3个变量：

-   一个连续响应变量，`mean_RT`，其较高的水平反映较慢的反应时；
-   一个连续预测变量，声波干扰水平(`dist_level`)，其较高的水平表示更多的干扰；
-   一个两水平的因子，`group` (城市vs.乡村)。

让我们从模拟一些城市组的数据开始。假设在0干扰(静音)下，平均反应时约为450毫秒，且干扰每增加1个单位，反应时就增加约2毫秒。这给了我们以下线性模型：

$$Y_i = 450 + 2 X_i + e_i$$

其中$X_i$是声音干扰的水平。

让我们模拟100名被试的数据，设定$\sigma = 80$，并在开始之前设置种子。

```{r sim-urban, message = FALSE}
library(tidyverse)
set.seed(1031)

n_subj <- 100L  # 模拟100名被试的数据(注：L是说明100是整数)
b0_urban <- 450 # y轴截距
b1_urban <- 2   # 斜率

# 分解表(decomposition table)
urban <- tibble(
  subj_id = 1:n_subj,
  group = "urban",
  b0 = 450,
  b1 = 2,
  dist_level = sample(0:n_subj, n_subj, replace = TRUE),
  err = rnorm(n_subj, mean = 0, sd = 80),
  simple_rt = b0 + b1 * dist_level + err)

urban
```

让我们绘制创建的数据，并作出最佳拟合线。

```{r plot-urban, message=FALSE, warning=FALSE, fig.cap = "*声波干扰对简单反应时的影响(城市组)*"}
ggplot(urban, aes(dist_level, simple_rt)) + 
  geom_point(alpha = .2) +
  geom_smooth(method = "lm", se = FALSE)
```

现在让我们为乡村组模拟数据。我们假设这些被试的截距可能会略高一些，可能是因为他们对技术不太熟悉。最重要的是，我们假设他们的斜率会更陡，因为他们受到噪音的影响更大。大致如下：

$$Y_i = 500 + 3 X_i + e_i$$

```{r sim-rural}
b0_rural <- 500
b1_rural <- 3

rural <- tibble(
  subj_id = 1:n_subj + n_subj,
  group = "rural",
  b0 = b0_rural,
  b1 = b1_rural,
  dist_level = sample(0:n_subj, n_subj, replace = TRUE),
  err = rnorm(n_subj, mean = 0, sd = 80),
  simple_rt = b0 + b1 * dist_level + err)
```

现在让我们把这两组的数据一起画出来。

```{r combined-plot, message=FALSE, warning=FALSE, fig.cap = "*声波干扰对简单反应时的影响(城市和乡村)*"}
all_data <- bind_rows(urban, rural)

ggplot(all_data %>% mutate(group = fct_relevel(group, "urban")), 
       aes(dist_level, simple_rt, colour = group)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  facet_wrap(~ group) + 
  theme(legend.position = "none")
```

这里我们可以很清楚地看到我们在数据中建立的斜率差异。我们如何测试两个斜率是否有显著不同呢？要做到这一点，我们不能做两个单独的回归。我们需要将这两条回归线纳入同一个模型中。我们应该怎么做呢？

请注意，我们可以用"偏移(offset)"值来表示其中一条回归线。我们(任意地)选一组作为我们的"基线"组，并将另一组的y轴截距和斜率表示为相对于这个基准的偏移值。因此，如果我们选择城市组作为基线，我们可以用两个偏移值$\beta_2$和$\beta_3$分别表示乡村组的y轴截距和斜率偏移。

-   y轴截距: $\beta_{0\_rural} = \beta_{0\_urban} + \beta_2$
-   斜率: $\beta_{1\_rural} = \beta_{1\_urban} + \beta_3$

我们有城市组参数：$\beta_{0\_urban} = 450$和$\beta_{1\_urban} = 2$，乡村组参数：$\beta_{0\_rural} = 500$和$\beta_{1\_rural} = 3$。因此可以得出：

-   $\beta_2 = 50$，因为$\beta_{0\_rural} - \beta_{0\_urban} = 500 - 450 = 50$
-   $\beta_3 = 1$，因为$\beta_{1\_rural} - \beta_{1\_urban} = 3 - 2 = 1$

现在我们的两个回归模型是：

$$Y_{i\_urban} = \beta_{0\_urban} + \beta_{1\_urban} X_i + e_i$$

和

$$Y_{i\_rural} = (\beta_{0\_urban} + \beta_2) + (\beta_{1\_urban} + \beta_3) X_i + e_i$$

好的，看起来我们更接近将这些模型合并为一个单一的回归模型了。这里有最后的技巧。我们定义一个额外的虚拟变量，该变量在城市组中取值为0(我们选择作为"基线"组)，在其他组中取值为1。下框包含我们的最终模型。

::: bluebox
**含有连续-分类变量交互作用的回归模型**

$$Y_{i} = \beta_0 + \beta_1 X_{1i} + \beta_2 X_{2i} + \beta_3 X_{1i} X_{2i} + e_{i}$$

其中

-   $X_{1i}$是连续变量
-   $X_{2i}$是虚拟变量，0表示基线组，1表示其他组

参数解释：

-   $\beta_0$: 基线组y轴截距；
-   $\beta_1$: 基线组斜率；
-   $\beta_2$: 其他组的y轴截距偏移量；
-   $\beta_3$: 其他组的斜率偏移量。

用R估计：

`lm(Y ~ X1 + X2 + X1:X2, data)`或者缩写:

`lm(Y ~ X1 * X2, data)`。这里`*`的意思是："所有可能的主效应以及X1和X2的交互"
:::

$\beta_3 X_{1i} X_{2i}$项是两个预测变量相乘，被称为**交互项(interaction term)**。现在让我们展示上述广义线性模型(GLM)是如何得出两条回归线的。

为了得到城市组的回归方程，我们将0代入到$X_{2i}$中。得到公式：

$$Y_{i} = \beta_0 + \beta_1 X_{1i} + \beta_2 0 + \beta_3 X_{1i} 0 + e_i$$

去掉等于0的项，就得到：

$$Y_{i} = \beta_0 + \beta_1 X_{1i} + e_i,$$

这就是基线组(城市组)的回归方程。将其与上面的$Y_{i\_urban}$进行对比。

将1代入到$X_{2i}$里会得到乡村组的方程。我们得到：

$$Y_{i} = \beta_0 + \beta_1 X_{1i} + \beta_2 1 + \beta_3 X_{1i} 1 + e_i$$

化简和运用一些代数后，也能表示为：

$$Y_{i} = \beta_0 + \beta_2 + (\beta_1 + \beta_3) X_{1i} + e_i.$$

将其和上面的$Y_{i\_rural}$进行对比。虚拟编码起作用了！

我们如何在R中估计回归系数？假设我们想检验两条线的斜率是否不同。注意，这实际上只是检验原假设$\beta_3 = 0$，因为$\beta_3$是我们的斜率偏移量。如果这个参数为0，意味着两个组具有相同的斜率(尽管它们可以有不同的截距)。换句话说，这意味着两条斜线是**平行的**。如果它非0，这意味着两个组具有不同的斜率，也就是说，两条斜线**不平行**。

::: yellowbox
**样本中的平行线 vs. 总体中的平行线**

我刚刚提到，两条不平行的线意味着分类预测变量和连续预测变量之间存在*交互作用*，而平行的线则意味着不存在交互作用。要明确的是，我所说的平行与否是指在总体(population)中的情况。在样本(sample)中的平行与否不仅取决于它们在总体中的情况，还取决于测量和抽样引入的偏差。总体中是平行的线，在样本中却极有可能出现斜率不同的线，尤其是在样本量较小的情况下。

通常，你会对总体中斜率相同与否感兴趣，而不是样本中的情况。因此，你不能仅仅看样本数据的图表就推断出"线不平行，因此存在交互作用"，或相反"线看起来平行，所以没有交互作用"。你必须进行推论统计检验。

当交互项在某个$\alpha$水平(如0.05)上具有统计显著性时，你会拒绝交互系数为0的原假设(如$H_0: \beta_3 = 0$)，这意味着在总体中这些线不是平行的。

然而，交互项不显著并*不一定*意味着在总体中这些线是平行的。它们可能是平行的，但也可能不是，而你的研究只是缺乏足够的统计效力(power)来检测出差异。

为了获得关于原假设的证据，最好的方法是进行所谓的等效性检验(equivalence test)。在这个检验中你试图拒绝一个原假设，该原假设是总体效应大于某个你感兴趣的最小效应值；教程详见[@Lakens_Scheel_Isager_2018]。
:::

我们已经创建了结合两组模拟数据的数据集`all_data`。我们使用R公式语法表示模型的方式是`Y ~ X1 + X2 + X1:X2`，其中`X1:X2`告诉R创建一个预测变量，该预测变量是`X1`和`X2`的乘积。还有一个缩写方式`Y ~ X1 * X2`，它告诉R计算所有可能的主效应和交互效应。首先，我们将向模型添加一个虚拟预测变量，并将结果存储在`all_data2`中。

```{r all-data2}
all_data2 <- all_data %>%
  mutate(grp = if_else(group == "rural", 1, 0))
```

```{r sonic-model}
sonic_mod <- lm(simple_rt ~ dist_level + grp + dist_level:grp,
                all_data2)

summary(sonic_mod)
```

::: purplebox

**练习**

在下面的空格中输入你的答案，至少保留两位小数。

给定回归模型

$$Y_{i} = \beta_0 + \beta_1 X_{1i} + \beta_2 X_{2i} + \beta_3 X_{1i} X_{2i} + e_{i}$$

(其中$X_{1i}$是连续预测变量，$X_{2i}$是分类预测变量)且上方给出了`lm()`的输出结果，填写以下参数的估计值。

- $\hat{\beta}_0$: `r fitb(coef(sonic_mod)[1], width = 4, tol = .01)`
- $\hat{\beta}_1$: `r fitb(coef(sonic_mod)[2], width = 4, tol = .01)`
- $\hat{\beta}_2$: `r fitb(coef(sonic_mod)[3], width = 4, tol = .01)`
- $\hat{\beta}_3$: `r fitb(coef(sonic_mod)[4], width = 4, tol = .01)`

根据这些参数估计，(基线)城市组的回归线为:

$Y_i =$ `r fitb(coef(sonic_mod)[1], width = 2, tol = .01)` $+$ `r fitb(coef(sonic_mod)[2], width = 2, tol = .01)` $X_{1i}$

乡村组的：

$Y_i =$ `r fitb(coef(sonic_mod)[1] + coef(sonic_mod)[3], width = 2, tol = .01)` $+$ `r fitb(coef(sonic_mod)[2] + coef(sonic_mod)[4], width = 2, tol = .01)` $X_{1i}$

`r hide("展开答案")`

- $\beta_0=$ `r round(coef(sonic_mod)[1], 2)`
- $\beta_1=$ `r round(coef(sonic_mod)[2], 2)`
- $\beta_2=$ `r round(coef(sonic_mod)[3], 2)`
- $\beta_3=$ `r round(coef(sonic_mod)[4], 2)`

城市组的回归线是：

$Y_i = \beta_0 + \beta_1 X_{1i}$即

$Y_i =$ `r round(coef(sonic_mod)[1], 2)` $+$ `r round(coef(sonic_mod)[2], 2)` $X_{1i}$

乡村组的是：

$Y_i = \beta_0 + \beta_2 + \left(\beta_1 + \beta_3\right) X_{1i}$即

$Y_i=$ `r round(coef(sonic_mod)[1] + coef(sonic_mod)[3], 2)` $+$ `r round(coef(sonic_mod)[2] + coef(sonic_mod)[4], 2)` $X_{1i}$

`r unhide()`

:::

## 分类变量-分类变量交互作用

**因子设计(factorial design)**在心理学中很常见，通常使用基于ANOVA的技术进行分析，这可能掩盖了ANOVA与回归一样也假设了一个潜在的线性模型的事实。

因子是一种所有预测变量(自变量，IVs)都是分类变量的设计：每个都是具有固定数量**水平**的**因子**。在一个全因子设计(full-factorial design)中，因子之间完全交叉，以表示每种可能的因子组合。我们称每个唯一的组合为设计的一个**单元(cell)**。你经常会听到设计被称为“二乘二(two-by-two)设计”(2x2)，这意味着有2个因子，每个因子有2个水平。一个“三乘三设计”(3x3)是其中有2个因子，每个因子有3个水平的设计；一个“二乘二乘二设计”(2x2x2)是其中有3个因子，每个因子有2个水平，以此类推。

通常，因子设计都以表格形式给出，显示所有因子水平的组合。下面是一个2x2设计的表格表示。

```{r full-factorial-2x3, echo = FALSE}
.a <- data.frame(`$B_1$` = c("$AB_{11}$", "$AB_{21}$"),
                 `$B_2$` = c("$AB_{12}$", "$AB_{22}$"), check.names = FALSE)

rownames(.a) <- c("$A_1$", "$A_2$")

knitr::kable(.a) %>%
  kable_styling(full_width = FALSE)
```

一个3x2设计可能如下所示。

```{r full-factorial, echo = FALSE}
.a <- data.frame(`$B_1$` = c("$AB_{11}$", "$AB_{21}$", "$AB_{31}$"),
                 `$B_2$` = c("$AB_{12}$", "$AB_{22}$", "$AB_{32}$"), check.names = FALSE)

rownames(.a) <- c("$A_1$", "$A_2$", "$A_3$")

knitr::kable(.a) %>%
  kable_styling(full_width = FALSE)
```

最后是一个2x2x2设计.

$$C_1$$

```{r full-factorial-2x2-c1, echo = FALSE}
.a <- data.frame(`$B_1$` = c("$ABC_{111}$", "$ABC_{211}$"),
                 `$B_2$` = c("$ABC_{121}$", "$ABC_{221}$"), check.names = FALSE)

rownames(.a) <- c("$A_1$", "$A_2$")

knitr::kable(.a) %>%
  kable_styling(full_width = FALSE)
```

$$C_2$$

```{r full-factorial-2x2-c2, echo = FALSE}
.a <- data.frame(`$B_1$` = c("$ABC_{112}$", "$ABC_{212}$"),
                 `$B_2$` = c("$ABC_{122}$", "$ABC_{222}$"), check.names = FALSE)

rownames(.a) <- c("$A_1$", "$A_2$")

knitr::kable(.a) %>%
  kable_styling(full_width = FALSE)
```