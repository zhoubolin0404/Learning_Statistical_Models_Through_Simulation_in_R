# 多元回归

```{r chapter-status, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
library("corrr") 
library("tidyverse")
```

单层数据包含$m$个预测变量的一般模型是：

$$
Y_i = \beta_0 + \beta_1 X_{1i} + \beta_2 X_{2i} + \ldots + \beta_m X_{mi} + e_i
$$

其中$e_i \sim \mathcal{N}\left(0, \sigma^2\right)$，换句话说，我们假设误差来自一个均值为0，方差为$\sigma^2$的正态分布。

注意，这里的关键假设**不是**响应变量($Y$)服从正态分布，**也不是**单个预测变量($X$)服从正态分布；而是**仅**模型残差服从正态分布(详细讨论见这篇[博客](https://datahowler.wordpress.com/2018/08/04/checking-model-assumptions-look-at-the-residuals-not-the-raw-data/))。单个$X$预测变量可以是任意组合的连续变量和/或分类变量，包括变量之间的交互。这个特定模型背后的进一步假设是，关系是"平面的"(可以用一个平面描述，类似于简单回归中的线性假设)，且误差方差与预测变量无关。

$\beta$的值被称为**回归系数(regression coefficient)**。每个$\beta_h$被解释为**在保持其他所有预测变量不变的情况下**$\beta_h$的偏效应(partial effect)。如果你有$m$个预测变量，你将有$m+1$个回归系数：一个用于截距，每个预测变量各一个

尽管在统计教科书中对多元回归的讨论很常见，但你很少有机会应用到上述的精确模型。因为上述模型假设的是单层数据，而大多数心理学数据是多层的。然而，这两种数据集的基本原理是相同的，因此先学习比较简单的案例是值得的。

## 一个例子：如何在统计学上取得好成绩

让我们来看一些(虚构但基于现实的)数据，看看我们如何使用多元回归来回答各种研究问题。在这个假设的研究中，你有一个包含100名统计学学生的数据集，其中包括他们的最终课程成绩(`grade`)、每个学生参加讲座的次数(`lecture`，一个范围为0-10的整数)、每个学生点击下载在线资料的次数(`nclicks`)以及每个学生在修这门课程之前的平均绩点(`GPA`)，其范围从0(不及格)到4(最高可能成绩)。

### 数据导入和可视化

让我们加载数据[grades.csv](https://raw.githubusercontent.com/PsyTeachR/stat-models-v1/master/data/grades.csv){target="_download"}并看一看。

```{r load-data, message=FALSE}
library("corrr") # 相关矩阵
library("tidyverse")

grades <- read_csv("data/grades.csv", col_types = "ddii")

grades
```

首先，让我们看一看所有的两两相关。

```{r correlation-matrix}
grades %>%
  correlate() %>%
  shave() %>%
  fashion()
```

```{r pairs, fig.cap="`grades`数据集中的所有成对关系"}
pairs(grades)
```

### 估计和解释

我们将使用`lm()`函数来估计回归系数($\beta$s)。针对一个有$m$个预测变量的GLM：

$$
Y_i = \beta_0 + \beta_1 X_{1i} + \beta_2 X_{2i} + \ldots + \beta_m X_{mi} + e_i
$$

对base R的`lm()`调用如下：

`lm(Y ~ X1 + X2 + ... + Xm, data)`

变量`Y`是你的响应变量，变量`X`是预测变量。注意，你不需要明确指定截距或残差项;这些是默认包含的。

对于当前数据，让我们通过`lecture`和`nclicks`来预测`grade`。

```{r fit-the-model}
my_model <- lm(grade ~ lecture + nclicks, grades)

summary(my_model)
```

```{r get-coef, echo=FALSE}
.coef <- coef(my_model) %>% round(2)
```

我们通常会在参数符号的顶部加上一个帽子(hat)，以明确我们正在处理样本的估计值，而不是(未知的)真实总体值。由上可知:

-   $\hat{\beta}_0$ = `r round(.coef[[1]], 2)`
-   $\hat{\beta}_1$ = `r round(.coef[[2]], 2)`
-   $\hat{\beta}_2$ = `r round(.coef[[3]], 2)`

这告诉我们，一个人的预期成绩与他们的参加讲座的次数和点击下载在线资料的次数通过以下公式相关联：

`grade` = `r .coef[[1]]` + `r .coef[[2]]` $\times$ `lecture` + `r .coef[[3]]` $\times$ `nclicks`

因为$\hat{\beta}_1$和$\hat{\beta}_2$都是正数，所以我们知道`lecture`和`nclicks`的值越高，成绩越好。

因此，如果有人问你，你预测一个参加了3次讲座并下载了70次的学生成绩是多少，你可以通过代入相应的值轻松算出来。

`grade` = `r .coef[[1]]` + `r .coef[[2]]` $\times$ 3 + `r .coef[[3]]` $\times$ 70

相当于：

`grade` = `r .coef[[1]]` + `r round(.coef[[2]] * 3, 2)` + `r round(.coef[[3]] * 70, 2)`

可化简为：

`grade` = `r .coef[[1]] + round(.coef[[2]] * 3, 2) + round(.coef[[3]] * 70, 2)`

### 使用`predict()`通过线性模型进行预测

如果我们想通过新的预测变量值来预测响应变量值，我们可以使用base R 的`predict()`函数。

`predict()`函数有两个主要参数。第一个参数是拟合的模型对象(即上面的my_model)，第二个参数是包含预测变量新值的数据框(或tibble，R中和数据框data frame类似的一种数据格式)。

::: yellowbox
在新表中，你需要包含**所有的**预测变量。如果您的tibble缺少任何预测变量，你将收到错误消息(error message)。您还需要确保新表中的变量名与模型中的变量名**完全**匹配。
:::

让我们创建一个带有新值的tibble并进行测试。

```{r}
## “tribble”是一种按行而不是按列创建tibble的方法。有时这样做会很有用。
new_data <- tribble(~lecture, ~nclicks,
                    3, 70,
                    10, 130,
                    0, 20,
                    5, 100)
```

::: bluebox
`tribble()`函数提供了一种按行而不是按列逐步构建tibble的方法，而使用`tibble()`函数则是按列逐步构建表格。

`tribble()`的第一行包含列名，每个列名前面都有一个波浪号(`~`)。

有时这种方法比逐行构建更容易阅读，尽管结果是相同的。考虑到这些，我们也可以使用以下方式创建上述表格：

```{r tibble-example, eval = FALSE}
new_data <- tibble(lecture = c(3, 10, 0, 5),
                   nclicks = c(70, 130, 20, 100))
```
:::

现在我们已经创建了表`new_data`，只需将其传递给`predict()`函数，这会返回一个关于$Y$(grade)预测值的向量。

```{r predict-it}
predict(my_model, new_data)
```

这很好，但也许我们希望将预测值和预测变量对应起来。我们可以通过将预测值作为新列添加到`new_data`中来实现这一点。

```{r}
new_data %>%
  mutate(predicted_grade = predict(my_model, new_data))
```

想查看`predict()`的更多操作吗？使用`?predict.lm`来获得帮助。

### 偏效应可视化

如上所述，每个回归系数的参数估计值告诉我们该变量的**偏**效应；即保持其他所有变量不变时它的效应。有办法可视化这个偏效应吗？是的，你可以使用`predict()`函数来实现，通过创建一个表，其中焦点预测变量(focal predictor)的值是多样的，其他所有预测变量用均值填充。

例如，我们要可视化`lecture`对`grade`的偏效应，同时将`nclicks`的值保持在其均值不变。

```{r partial-lecture}
nclicks_mean <- grades %>% pull(nclicks) %>% mean()

## 预测用的新数据
new_lecture <- tibble(lecture = 0:10,
                      nclicks = nclicks_mean)

## 将预测值添加到new_lecture
new_lecture2 <- new_lecture %>%
  mutate(grade = predict(my_model, new_lecture))

new_lecture2
```

现在让我们作图。

```{r partial-lecture-plot, fig.cap = "nclicks固定在均值，`lecture`对成绩的偏效应"}
ggplot(grades, aes(lecture, grade)) + 
  geom_point() +
  geom_line(data = new_lecture2)
```

::: yellowbox
偏效应图只有在模型中焦点预测变量与其他预测变量之间没有交互作用时才有意义。

原因是当存在交互作用时，焦点预测变量$X_i$的偏效应会随着与其交互的变量的变动而变动。
:::

现在你能可视化`nclicks`对`grade`的偏效应吗?

本页最后给出解决方法。

### 标准化系数

我们经常用多元回归来解决的一类问题是，**哪个预测变量对预测Y最重要？**

现在，你不能简单地读取$\hat{\beta}$值并选择绝对值最大的一个，因为这些预测变量都在不同的尺度上。为了回答这个问题，你需要对预测变量进行**中心化(center)**和**比例化(scale)**。

还记得$z$分数吗？

$$
z = \frac{X - \mu_x}{\sigma_x}
$$

$z$分数($z$-score)表示$X$与样本均值($\mu_x$)之间的标准差单位距离($\sigma_x$)。因此，$z$分数为1意味着该值高于均值1个标准差；$z$分数为-2.5意味着低于均值2.5个标准差。$Z$分数通过将它们校准为标准正态分布(均值为0，标准差为1的分布)给了我们一种比较来自不同总体的事物的办法。

那么我们通过将预测变量转换为$z$分数来重新缩放它们。这是相当容易做到的。

```{r rescale-predictors}
grades2 <- grades %>%
  mutate(lecture_c = (lecture - mean(lecture)) / sd(lecture),
         nclicks_c = (nclicks - mean(nclicks)) / sd(nclicks))

grades2
```

现在让我们用居中和缩放后的预测变量重新拟合模型。

```{r my-model2}

my_model_scaled <- lm(grade ~ lecture_c + nclicks_c, grades2)

summary(my_model_scaled)
```

```{r which-larger, include=FALSE}
.bigger <- names(which.max(coef(my_model_scaled)[-1]))
.smaller <- setdiff(names(coef(my_model_scaled)[-1]), .bigger)

if (coef(my_model_scaled)[[2]] > coef(my_model_scaled)[[1]]) "nclicks_c" else "lecture_c"
```

这告诉我们`r .bigger`的影响相对更大，该变量每个标准差的提高，`grade`相应地提高`r coef(my_model_scaled)[[.bigger]] %>% round(2)`。

另一种常见的标准化方法是同时对响应变量和预测变量进行标准化，即对$Y$值和$X$值都进行$z$分数转换。采用这种方法时，回归系数的相对(影响力)排序将保持不变。主要区别在于，系数将反映响应变量以标准差($SD$)为单位的变化，而不是原始单位。

::: bluebox
**多重共线性(multicollinearity)及其不足**

在关于多元回归的讨论中，你可能会听到对"多重共线性"的担忧，这是指预测变量之间存在交互关系的一种高级说法。这只是一个潜在的问题，因为它可能会影响对单个预测变量效应的解释。当预测变量相关时，$\beta$值可能会根据模型中包含或排除的预测变量而变化，有时甚至会改变符号。关于这一点需要记住的关键是：

-   观察性研究(observational studies)中预测变量之间相关是不可避免的；
-   回归**不**假设你的预测变量彼此独立(换句话说，在预测变量之间找到相关性本身并不是质疑模型的理由)；
-   当存在强相关时，解释单个回归系数时要谨慎；
-   目前没有已知的"补救措施"，也不清楚是否需要任何此类补救措施，许多所谓的补救措施弊大于利。

更多信息和指导请查阅[@Vanhove_2021]。
:::

### 模型比较

另一种使用多元回归模型解决的常见问题是：某个预测变量或一组预测变量**在超出某些控制变量的影响之外**，对我的响应变量有显著影响吗？

举个例子，上述包含`lecture`和`nclicks`的模型在统计上是显著的， $F(`r .df1 <- summary(my_model)$fstatistic[["numdf"]]; .df1`,`r .df2 <- summary(my_model)$fstatistic[["dendf"]]; .df2`) = `r .f <- summary(my_model)$fstatistic[["value"]]; round(.f, 3)`, p =`r .p <- pf(.f, .df1, .df2, lower.tail = FALSE); round(.p, 3)`$。

$m$个预测因子的回归模型的原假设(null hypothesis)为：

$$H_0: \beta_1 = \beta_2 = \ldots = \beta_m = 0;$$

换句话说，所有的系数(除了截距)都是0。如果原假设成立，那么原模型(null model)

$$Y_i = \beta_0$$

与包含所有预测变量及其系数的模型一样能给出很好的预测。换句话说，你对$Y$的最佳预测只是它的均值($\mu_y$)；$X$变量是无关紧要的。我们拒绝了这个原假设，意味着通过纳入我们的两个预测变量`lecture`和`nclicks`，可以做得更好。

但你可能会问：也许是成绩更好的学生获得了更好的成绩，而`lecture`、`nclicks`和`grade`之间的关系仅仅是通过学生质量的中介来实现。毕竟，成绩更好的学生更有可能去听讲座并下载材料。因此，我们可以问，出勤率和下载次数是否在**超出**学生能力(通过GPA测量)之外与更好的成绩相关？

我们可以通过**模型比较**来检验这一假设。逻辑是这样的：首先，估计一个包含所有控制预测变量但不包含焦点预测变量的模型。其次，估计一个包含控制预测变量和焦点预测变量的模型。最后，比较这两个模型，看看包含预测因子是否有统计学上显著的增益。

下面展示你如何做到这一点：

```{r model-comparison}
m1 <- lm(grade ~ GPA, grades) # control model
m2 <- lm(grade ~ GPA + lecture + nclicks, grades) # bigger model

anova(m1, m2)
```

```{r m1-m2, include = FALSE}
.anova <- anova(m1, m2)
```

原假设是我们仅通过`GPA`预测`grade`与通过`GPA`加上`lecture`和`nclicks`预测`grade`一样准确。如果添加这两个变量能够显著减少**残差平方和(RSS)**，即它们能解释足够多的残差方差，我们就会拒绝这个原假设。

我们看到情况并非如此：$F(`r .df1 <- .anova$Df[2]; .df1`,`r .df2 <- .anova$Res.Df[2]; .df2`) = `r .f <- .anova$F[2]; round(.f, 3)`$, $p =`r round(pf(.f, .df1, .df2, lower.tail = FALSE), 3)`$。因此，我们没有证据表明课堂出勤率和下载在线材料在通过GPA衡量的学生能力之外与更好的成绩相关。

## 处理分类预测变量

回归公式将响应变量描述为加权预测变量的总和。但如果其中一个预测变量是分类变量(如代表"农村"或"城市"等群组)，而不是数值型变量会怎样呢？许多变量是**名义(nominal)**变量：包含名称的分类变量，在变量的级别之间没有固有的顺序。例如，宠物所有权(猫、狗、雪貂)是一个名义变量；不考虑喜好，拥有猫不等于拥有狗，拥有狗不等于拥有雪貂。

::: bluebox
**使用数值型预测变量表示名义数据**

在回归模型中表示一个$k$水平的名义变量需要$k-1$个数值型预测变量；例如，如果有4水平，你需要3个预测变量。大多数编码方案要求你在$k$个水平中选择一个作为基线水平。$k-1$个变量中，每个变量都是其表示的水平与基线水平对比。

**举例：**你有一个三水平变量`pet_type`(猫、狗、雪貂)。

你选择猫为基线并创建两个数值型预测变量：

-   `dog_v_cat`用来编码狗和猫之间的对比；
-   `ferret_v_cat`用来编码雪貂和猫之间的对比。
:::

名义变量通常在数据框中表示`character`或`factor`类型。

字符(character)变量和因子(factor)变量的区别在于因子包含关于水平及其顺序的信息，而字符向量则缺乏此信息。

当你使用R公式语法(R formula syntax)指定模型时，R会检查公式右侧预测变量的数据类型。例如，如果你的模型将`income`回归到`pet_type`上(`income ~ pet_type`)，R会检查`pet_type`的数据类型。

对于所有类型为字符或因子的变量，R都会隐式地(implicitly)创建一个(或一组)数值型预测变量来表示该变量在模型中的作用。有多种方案可用于创建名义变量的数值表示。R中的默认方法是使用**虚拟**(dummy，或叫treatment)编码(见下文)。不幸的是，这种默认方法不适合心理学中的许多研究设计，因此我建议你学习如何“手动”编码你的预测变量，并养成这样做的习惯。