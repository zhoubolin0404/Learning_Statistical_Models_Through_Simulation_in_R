# 多元回归

```{r chapter-status, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
library("corrr") 
library("tidyverse")
```

单层数据包含$m$个预测变量的一般模型是：

$$
Y_i = \beta_0 + \beta_1 X_{1i} + \beta_2 X_{2i} + \ldots + \beta_m X_{mi} + e_i
$$

其中$e_i \sim \mathcal{N}\left(0, \sigma^2\right)$，换句话说，我们假设误差来自一个均值为0，方差为$\sigma^2$的正态分布。

注意，这里的关键假设**不是**响应变量($Y$)服从正态分布，**也不是**单个预测变量($X$)服从正态分布；而是**仅**模型残差服从正态分布(详细讨论见这篇[博客](https://datahowler.wordpress.com/2018/08/04/checking-model-assumptions-look-at-the-residuals-not-the-raw-data/))。单个$X$预测变量可以是任意组合的连续变量和/或分类变量，包括变量之间的交互。这个特定模型背后的进一步假设是，关系是“平面的”(可以用一个平面描述，类似于简单回归中的线性假设)，且误差方差与预测变量无关。

$\beta$的值被称为**回归系数(regression coefficient)**。每个$\beta_h$被解释为**在保持其他所有预测变量不变的情况下$\beta_h$的偏效应(partial effect)**。如果你有$m$个预测变量，你将有$m+1$个回归系数：一个用于截距，每个预测变量各一个

尽管在统计教科书中对多元回归的讨论很常见，但你很少有机会应用到上述的精确模型。因为上述模型假设的是单层数据，而大多数心理学数据是多层的。然而，这两种数据集的基本原理是相同的，因此先学习比较简单的案例是值得的。

## 一个例子：如何在统计学上取得好成绩

让我们来看一些(虚构但基于现实的)数据，看看我们如何使用多元回归来回答各种研究问题。在这个假设的研究中，你有一个包含100名统计学学生的数据集，其中包括他们的最终课程成绩(`grade`)、每个学生参加讲座的次数(`lecture`，一个范围为0-10的整数)、每个学生点击下载在线资料的次数(`nclicks`)以及每个学生在修这门课程之前的平均绩点(`GPA`)，其范围从0(不及格)到4(最高可能成绩)。

### 数据导入和可视化

让我们加载数据[grades.csv](https://raw.githubusercontent.com/PsyTeachR/stat-models-v1/master/data/grades.csv){target="_download"}并看一看。

```{r load-data, message=FALSE}
library("corrr") # 相关矩阵
library("tidyverse")

grades <- read_csv("data/grades.csv", col_types = "ddii")

grades
```

首先，让我们看一看所有的两两相关。

```{r correlation-matrix}
grades %>%
  correlate() %>%
  shave() %>%
  fashion()
```

```{r pairs, fig.cap="`grades`数据集中的所有成对关系"}
pairs(grades)
```

### 估计和解释

我们将使用`lm()`函数来估计回归系数($\beta$s)。针对一个有$m$个预测变量的GLM：

$$
Y_i = \beta_0 + \beta_1 X_{1i} + \beta_2 X_{2i} + \ldots + \beta_m X_{mi} + e_i
$$

对base R的`lm()`调用如下：

`lm(Y ~ X1 + X2 + ... + Xm, data)`

变量`Y`是你的响应变量，变量`X`是预测变量。注意，你不需要明确指定截距或残差项;这些是默认包含的。

对于当前数据，让我们通过`lecture`和`nclicks`来预测`grade`。

```{r fit-the-model}
my_model <- lm(grade ~ lecture + nclicks, grades)

summary(my_model)
```

```{r get-coef, echo=FALSE}
.coef <- coef(my_model) %>% round(2)
```

我们通常会在参数符号的顶部加上一个帽子(hat)，以明确我们正在处理样本的估计值，而不是(未知的)真实总体值。由上可知:

* $\hat{\beta}_0$ = `r round(.coef[[1]], 2)`
* $\hat{\beta}_1$ = `r round(.coef[[2]], 2)`
* $\hat{\beta}_2$ = `r round(.coef[[3]], 2)`

这告诉我们，一个人的预期成绩与他们的参加讲座的次数和点击下载在线资料的次数通过以下公式相关联：

`grade` = `r .coef[[1]]` + `r .coef[[2]]` $\times$ `lecture` + `r .coef[[3]]` $\times$ `nclicks`

因为$\hat{\beta}_1$和$\hat{\beta}_2$都是正数，所以我们知道`lecture`和`nclicks`的值越高，成绩越好。

因此，如果有人问你，你预测一个参加了3次讲座并下载了70次的学生成绩是多少，你可以通过代入相应的值轻松算出来。

`grade` = `r .coef[[1]]` + `r .coef[[2]]` $\times$ 3 + `r .coef[[3]]` $\times$ 70

相当于：

`grade` = `r .coef[[1]]` + `r round(.coef[[2]] * 3, 2)` + `r round(.coef[[3]] * 70, 2)`

可化简为：

`grade` = `r .coef[[1]] + round(.coef[[2]] * 3, 2) + round(.coef[[3]] * 70, 2)`

### 使用`predict()`通过线性模型进行预测

如果我们想通过新的预测变量值来预测响应变量值，我们可以使用base R 的`predict()`函数。

`predict()`函数有两个主要参数。第一个参数是拟合的模型对象(即上面的my_model)，第二个参数是包含预测变量新值的数据框(或tibble，R中和数据框data frame类似的一种数据格式)。

<div class = "yellowbox">

在新表中，你需要包含**所有的**预测变量。如果您的tibble缺少任何预测变量，你将收到错误消息(error message)。您还需要确保新表中的变量名与模型中的变量名**完全**匹配。

</div>

让我们创建一个带有新值的tibble并进行测试。

```{r}
## “tribble”是一种按行而不是按列创建tibble的方法。有时这样做会很有用。
new_data <- tribble(~lecture, ~nclicks,
                    3, 70,
                    10, 130,
                    0, 20,
                    5, 100)
```

<div class = "bluebox">

`tribble()`函数提供了一种按行而不是按列逐步构建tibble的方法，而使用`tibble()`函数则是按列逐步构建表格。

`tribble()`的第一行包含列名，每个列名前面都有一个波浪号(`~`)。

有时这种方法比逐行构建更容易阅读，尽管结果是相同的。考虑到这些，我们也可以使用以下方式创建上述表格：

```{r tibble-example, eval = FALSE}
new_data <- tibble(lecture = c(3, 10, 0, 5),
                   nclicks = c(70, 130, 20, 100))
```

</div>

现在我们已经创建了表`new_data`，只需将其传递给`predict()`函数，这会返回一个关于$Y$(grade)预测值的向量。

```{r predict-it}
predict(my_model, new_data)
```

这很好，但也许我们希望将预测值和预测变量对应起来。我们可以通过将预测值作为新列添加到`new_data`中来实现这一点。

```{r}
new_data %>%
  mutate(predicted_grade = predict(my_model, new_data))
```

想查看`predict()`的更多操作吗？使用`?predict.lm`来获得帮助。

### 偏效应可视化

如上所述，每个回归系数的参数估计值告诉我们该变量的**偏**效应；即保持其他所有变量不变时它的效应。有办法可视化这个偏效应吗？是的，你可以使用`predict()`函数来实现，通过创建一个表，其中关注的预测变量的值是多样的，其他所有预测变量用均值填充。

例如，我们要可视化`lecture`对`grade`的偏效应，同时将`nclicks`的值保持在其均值不变。

```{r partial-lecture}
nclicks_mean <- grades %>% pull(nclicks) %>% mean()

## 预测用的新数据
new_lecture <- tibble(lecture = 0:10,
                      nclicks = nclicks_mean)

## 将预测值添加到new_lecture
new_lecture2 <- new_lecture %>%
  mutate(grade = predict(my_model, new_lecture))

new_lecture2
```

现在让我们作图。

```{r partial-lecture-plot, fig.cap = "nclicks固定在均值，`lecture`对成绩的偏效应"}
ggplot(grades, aes(lecture, grade)) + 
  geom_point() +
  geom_line(data = new_lecture2)
```

<div class = "yellowbox>

偏效应图只有在模型中关注的预测变量与其他预测变量之间没有交互作用时才有意义。

原因是当存在交互作用时，关注的预测变量$X_i$的偏效应会随着与其交互的变量的变动而变动。

</div>

现在你能可视化`nclicks`对`grade`的偏效应吗?

本页最后给出解决方法。

### 标准化系数

我们经常用多元回归来解决的一类问题是，**哪个预测变量对预测Y最重要？**

现在，你不能简单地读取$\hat{\beta}$值并选择绝对值最大的一个，因为这些预测变量都在不同的尺度上。为了回答这个问题，你需要对预测变量进行**中心化(center)**和**比例化(scale)**。

还记得$z$分数吗？

$$
z = \frac{X - \mu_x}{\sigma_x}
$$

$z$分数($z$-score)表示$X$与样本均值($\mu_x$)之间的标准差单位距离($\sigma_x$)。因此，$z$分数为1意味着该值高于均值1个标准差；$z$分数为-2.5意味着低于均值2.5个标准差。$Z$分数通过将它们校准为标准正态分布(均值为0，标准差为1的分布)给了我们一种比较来自不同总体的事物的办法。

那么我们通过将预测变量转换为$z$分数来重新缩放它们。这是相当容易做到的。

```{r rescale-predictors}
grades2 <- grades %>%
  mutate(lecture_c = (lecture - mean(lecture)) / sd(lecture),
         nclicks_c = (nclicks - mean(nclicks)) / sd(nclicks))

grades2
```

现在让我们用居中和缩放后的预测变量重新拟合模型。

```{r my-model2}

my_model_scaled <- lm(grade ~ lecture_c + nclicks_c, grades2)

summary(my_model_scaled)
```

```{r which-larger, include=FALSE}
.bigger <- names(which.max(coef(my_model_scaled)[-1]))
.smaller <- setdiff(names(coef(my_model_scaled)[-1]), .bigger)

if (coef(my_model_scaled)[[2]] > coef(my_model_scaled)[[1]]) "nclicks_c" else "lecture_c"
```

