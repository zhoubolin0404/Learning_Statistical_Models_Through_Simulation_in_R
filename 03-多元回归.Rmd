# 多元回归

```{r chapter-status, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
library("corrr") 
library("tidyverse")
```

单层数据包含$m$个预测变量的一般模型是：

$$
Y_i = \beta_0 + \beta_1 X_{1i} + \beta_2 X_{2i} + \ldots + \beta_m X_{mi} + e_i
$$

其中$e_i \sim \mathcal{N}\left(0, \sigma^2\right)$，换句话说，我们假设误差来自一个均值为0，方差为$\sigma^2$的正态分布。

注意，这里的关键假设**不是**响应变量($Y$)服从正态分布，**也不是**单个预测变量($X$)服从正态分布；而是**仅**模型残差服从正态分布(详细讨论见这篇[博客](https://datahowler.wordpress.com/2018/08/04/checking-model-assumptions-look-at-the-residuals-not-the-raw-data/))。单个$X$预测变量可以是任意组合的连续变量和/或分类变量，包括变量之间的交互。这个特定模型背后的进一步假设是，关系是“平面的”(可以用一个平面描述，类似于简单回归中的线性假设)，且误差方差与预测变量无关。

$\beta$的值被称为**回归系数(regression coefficient)**。每个$\beta_h$被解释为**在保持其他所有预测变量不变的情况下$\beta_h$的偏效应(partial effect)**。如果你有$m$个预测变量，你将有$m+1$个回归系数：一个用于截距，每个预测变量各一个

尽管在统计教科书中对多元回归的讨论很常见，但你很少有机会应用到上述的精确模型。因为上述模型假设的是单层数据，而大多数心理学数据是多层的。然而，这两种数据集的基本原理是相同的，因此先学习比较简单的案例是值得的。

## 一个例子：如何在统计学上取得好成绩

让我们来看一些(虚构但基于现实的)数据，看看我们如何使用多元回归来回答各种研究问题。在这个假设的研究中，你有一个包含100名统计学学生的数据集，其中包括他们的最终课程成绩(`grade`)、每个学生参加讲座的次数(`lecture`，一个范围为0-10的整数)、每个学生点击下载在线资料的次数(`nclicks`)以及每个学生在修这门课程之前的平均绩点(`GPA`)，其范围从0(不及格)到4(最高可能成绩)。

### 数据导入和可视化

让我们加载数据[grades.csv](https://raw.githubusercontent.com/PsyTeachR/stat-models-v1/master/data/grades.csv){target="_download"}并看一看。

```{r load-data, message=FALSE}
library("corrr") # 相关矩阵
library("tidyverse")

grades <- read_csv("data/grades.csv", col_types = "ddii")

grades
```

首先，让我们看一看所有的两两相关。

```{r correlation-matrix}
grades %>%
  correlate() %>%
  shave() %>%
  fashion()
```

```{r pairs, fig.cap="`grades`数据集中的所有成对关系"}
pairs(grades)
```

### 估计和解释

我们将使用`lm()`函数来估计回归系数($\beta$s)。针对一个有$m$个预测变量的GLM：

$$
Y_i = \beta_0 + \beta_1 X_{1i} + \beta_2 X_{2i} + \ldots + \beta_m X_{mi} + e_i
$$

对base R的`lm()`调用如下：

`lm(Y ~ X1 + X2 + ... + Xm, data)`

变量`Y`是你的响应变量，变量`X`是预测变量。注意，你不需要明确指定截距或残差项;这些是默认包含的。

对于当前数据，让我们通过`lecture`和`nclicks`来预测`grade`。

```{r fit-the-model}
my_model <- lm(grade ~ lecture + nclicks, grades)

summary(my_model)
```

```{r get-coef, echo=FALSE}
.coef <- coef(my_model) %>% round(2)
```

我们通常会在参数符号的顶部加上一个帽子(hat)，以明确我们正在处理样本的估计值，而不是(未知的)真实总体值。由上可知:

* $\hat{\beta}_0$ = `r round(.coef[[1]], 2)`
* $\hat{\beta}_1$ = `r round(.coef[[2]], 2)`
* $\hat{\beta}_2$ = `r round(.coef[[3]], 2)`

这告诉我们，一个人的预期成绩与他们的参加讲座的次数和点击下载在线资料的次数通过以下公式相关联：

`grade` = `r .coef[[1]]` + `r .coef[[2]]` $\times$ `lecture` + `r .coef[[3]]` $\times$ `nclicks`

因为$\hat{\beta}_1$和$\hat{\beta}_2$都是正数，所以我们知道`lecture`和`nclicks`的值越高，成绩越好。

因此，如果有人问你，你预测一个参加了3次讲座并下载了70次的学生成绩是多少，你可以通过代入相应的值轻松算出来。

`grade` = `r .coef[[1]]` + `r .coef[[2]]` $\times$ 3 + `r .coef[[3]]` $\times$ 70

相当于：

`grade` = `r .coef[[1]]` + `r round(.coef[[2]] * 3, 2)` + `r round(.coef[[3]] * 70, 2)`

可化简为：

`grade` = `r .coef[[1]] + round(.coef[[2]] * 3, 2) + round(.coef[[3]] * 70, 2)`

### 使用`predict()`通过线性模型进行预测

如果我们想通过新的预测变量值来预测响应变量值，我们可以使用base R 的`predict()`函数。

`predict()`函数有两个主要参数。第一个参数是拟合的模型对象(即上面的my_model)，第二个参数是包含预测变量新值的数据框(或tibble，R中和数据框data frame类似的一种数据格式)。

<div class = "yellowbox">

在新表中，你需要包含**所有的**预测变量。如果您的tibble缺少任何预测变量，你将收到错误消息(error message)。您还需要确保新表中的变量名与模型中的变量名**完全**匹配。

</div>

让我们创建一个带有新值的tibble并进行测试。

```{r}
## “tribble”是一种按行而不是按列创建tibble的方法。有时这样做会很有用。
new_data <- tribble(~lecture, ~nclicks,
                    3, 70,
                    10, 130,
                    0, 20,
                    5, 100)
```

<div class = "bluebox">

`tribble()`函数提供了一种按行而不是按列逐步构建tibble的方法，而使用`tibble()`函数则是按列逐步构建表格。

`tribble()`的第一行包含列名，每个列名前面都有一个波浪号(`~`)。

有时这种方法比逐行构建更容易阅读，尽管结果是相同的。考虑到这些，我们也可以使用以下方式创建上述表格：

```{r tibble-example, eval = FALSE}
new_data <- tibble(lecture = c(3, 10, 0, 5),
                   nclicks = c(70, 130, 20, 100))
```

</div>