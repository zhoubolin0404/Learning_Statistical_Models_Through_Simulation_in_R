[["index.html", "学习统计模型——通过R模拟 概述 如何引用本书 发现问题？ 教育者需知", " 学习统计模型——通过R模拟 Zhou Bolin 2024-05-29 概述 本教材采用在R语言环境下模拟广义线性模型(General Linear Model, GLM)的方法来介绍统计分析。总体目标是教会学生如何将研究设计的描述转化为线性模型，来分析该研究的数据。重点是分析心理学实验数据所需的技能。 本教材包括以下内容： 线性模型工作流程; 方差-协方差矩阵; 多元回归; 交互作用(连续与分类; 分类与分类); 线性混合模型; 广义线性混合模型。 本课程的内容构成了格拉斯哥大学心理学院(University of Glasgow School of Psychology)由Dale Barr讲授的大学三年级一学期课程的基础。这也是由格拉斯哥大学心理学院工作人员开发的PsyTeachR系列课程材料的一部分。 与你可能遇到的其他教材不同，这是一本互动教材。每一章都包含嵌入式练习和网页应用来帮助学生更好地理解内容。你只有通过浏览器访问这些材料，这些互动内容才能正常工作。因此，不建议打印这些材料。如果你希望在没网的情况下访问教材或保存本地版本以防止网站变化或迁移，可以下载离线使用版本。只需要从ZIP压缩包中提取文件，在docs目录中找到index.html文件，然后使用浏览器打开这个文件即可。 如何引用本书 Barr, Dale J. (2021). Learning statistical models through simulation in R: An interactive textbook. Version 1.0.0. Retrieved from https://psyteachr.github.io/stat-models-v1. 发现问题？ 如果你发现错误或书写错误，有问题或建议，请在https://github.com/psyteachr/stat-models-v1/issues提交问题。谢谢！ 教育者需知 您可以根据自己的需求免费重复使用和修改本教材中的材料，但需要注明原作出处。请注意关于重复使用本材料的 Creative Commons CC-BY-SA 4.0 许可证的其他条款。 本书是使用R bookdown包构建的。源文件可在github上获得。 "],["前言.html", "1 前言 1.1 课程目的 1.2 广义线性混合模型(Generalized Linear Mixed-Effects Models, GLMMs) 1.3 关于可重复性的说明 1.4 基于模拟的方法", " 1 前言 1.1 课程目的 本课程的目的是教你如何分析(还有模拟!)作为心理学家你可能遇到的各种数据集。重点是行为数据——反应时、知觉判断、选择、决策、李克特量表评分、眼动、睡眠时间等。这些数据通常是在有计划的研究或实验中收集到的。 本课程旨在教授灵活、可推广、可重复的分析技术。你将学习到的技术是灵活的，这意味着它们可以应用到各式各样的研究设计和不同类型的数据上。通过充分考虑抽样对统计推断的潜在偏倚影响，它们在最大程度上具有可推广性——这有助于支持超越特定被试和实验中涉及的刺激得出结论。最后，你将学习到的技术会尽可能地做到可完全重复，因为你的分析将以R代码的纯文本脚本形式明确记录从原始数据到研究结果的每一个步骤。 1.2 广义线性混合模型(Generalized Linear Mixed-Effects Models, GLMMs) 本课程强调一个灵活的回归模型框架而不是教授处理不同类型数据的”公式”。课程假设你需要分析的基本数据类型将是多层的(multilevel)，而且你不仅仅需要处理连续测量数据，还要处理有序测量数据（李克特量表评分）、计数数据（特定事件发生的次数）以及名义数据（某物所属的类别）。 本课程结束时，你将学会如何使用广义线性混合模型(GLMMs)来量化因变量和一组预测变量之间的关系。要理解GLMMs，你需要学习以下三部分： “线性模型”部分，包括如何捕捉不同类型的预测变量及其交互作用； “混合”部分，包括如何使用随机效应来表示通过对同一批被试或刺激进行重复测量而产生的多层次依赖关系； “广义”部分，包括拓展线性模型来表示非完全正态自变量，包括计数、有序和二元变量。 1.2.1 线性模型 GLMMs是一般线性模型的扩展。一般线性模型是方差分析(ANOVA)、t检验和古典回归等更简单方法的基础。本课程的主要观点是：你可能遇到的几乎所有实验得到的数据都可以用GLMMs进行分析。 一个线性模型的简单例子： \\[Y_i = \\beta_0 + \\beta_1 X_i + e_i\\] 其中\\(Y_i\\)是样本\\(i\\)的因变量的观测值，由截距加上被系数\\(\\beta_1\\)加权的预测值\\(X_i\\)以及误差项构成。表示线性关系\\(Y_i = 3 + 2X_i + e_i\\)的模拟数据如图1.1所示。 图1.1: 线性模型Y = 3 + 2X的模拟数据 library(&quot;tidyverse&quot;) # if needed set.seed(62) dat &lt;- tibble(X = runif(100, -3, 3), Y = 3 + 2 * X + rnorm(100)) ggplot(dat, aes(X, Y)) + geom_point() + geom_abline(intercept = 3, slope = 2, color = &quot;blue&quot;) 你可能会发现上述方程表示的是一条直线(\\(y = mx + b\\))，其中\\(\\beta_0\\)是截距，\\(\\beta_1\\)是斜率。\\(e_i\\)是样本\\(i\\)的模型误差，表示样本观测值\\(Y_i\\)与给定\\(X_i\\)的模型预测值之间的差距。 表示法惯例 希腊字母(\\(\\beta\\), \\(\\rho\\), \\(\\tau\\))表示总体参数，通常是未观测到的，需要从数据中估计得到的。当我们想要区分估计参数和真实值时，我们会使用”hat”：如\\(\\hat{\\beta}_0\\)表示从数据中估计得到的\\(\\beta_0\\)的值。 大写拉丁字母(\\(X\\)、\\(Y\\))表示观测值——即你已经测量过的值，因此是已知的。你也会看到小写拉丁字母(如\\(e_i\\))，表示统计误差或其他我将称之为派生量或虚拟量的东西(这将在课程后面进行解释)。 线性模型中的”线性”并不像你想象的那样! 许多人认为”线性模型”只能捕捉线性关系，即可以用直线(或平面)来描述的关系。这是错误的。 线性模型是各种项的加权和，每个项都有一个预测变量(或常数)乘上一个系数。在上述模型中，系数是\\(\\beta_0\\)和\\(\\beta_1\\)。你可以用线性模型拟合各种复杂的关系，包括非线性关系，如下所示。 图1.2: 用线性模型建模的非线性关系 在左边面板中，我们使用线性模型\\(Y = \\beta_0 + \\beta_1 X + \\beta_2 X^2\\)捕捉了一个二次(抛物线)函数。X和Y之间的关系是非线性的，但模型本身是线性的。我们对预测变量\\(X\\)进行了平方处理，但系数\\(\\beta_0\\)、\\(\\beta_1\\)和\\(\\beta_2\\)并没有被平方、立方或类似的处理(它们都是”一次幂”)。 在中间面板中，我们使用线性模型捕捉了一个S形函数。在这里，Y变量表示某个事件的概率，例如基于学习时间来预测通过考试的概率。在这种情况下，我们通过在一个特殊的转换空间中估计线性模型来建模X和Y之间的关系，使得X-Y关系是线性的，然后将模型投影回非线性的概率空间(使用”链接函数”)。非线性来自于”链接函数”，但模型本身是线性的。 最后，右边面板展示了一种略显任意的波动模式，由广义可加混合模型捕获——这是一种我们在本课程中不会学到的高级技术。但从根本上说，它仍然是一个线性模型，因为它还是一系列复杂事物(在这种情况下是”基础函数”)的加权和，而系数提供了权重。 线性模型是一个系数是线性的模型；模型中的每个系数(\\(\\beta_0\\)、\\(\\beta_1\\))只允许被设置为一次幂，并且每个项\\(\\beta_i X_j\\)都只涉及单个系数。这些项只能与涉及其他系数的项相加，但不能相乘或相除(如\\(Y = \\frac{\\beta_1}{\\beta_2} X\\)是不允许的)。 当前课程的一个局限性是主要关注单变量数据，即将单一响应变量作为分析的焦点。通常情况下，你会处理相同对象的多个响应变量，但是同时对它们进行建模在技术上是非常困难的，并且超出了本课程的范围。一种更简单的方法(也是这里采用的方法)是对每个响应变量进行单独的单变量分析。 1.2.2 混合模型 研究结果的推断或解释的可推广性指的是它能够被轻松应用于超出特定研究背景(对象、刺激、任务等)的情境的程度。最理想的情况是，我们的发现能够适用于人类物种的所有成员，涵盖各种各样的刺激和任务；最糟糕的情况是，它们只能适用于那些受到我们使用的特定刺激的特定的人，在我们研究的特定背景下才观察得到。 研究结果的可推广性取决于几个因素：研究的设计方式、所使用的材料、被试的招募方式、给予被试的任务的性质以及数据分析的方式。在这门课程中我们将重点关注最后一点。在分析一个数据集时，如果你想要提出具有推广性的论断，你必须决定哪些可以算作你研究的重复——关于哪些方面应该在复制中保持不变，以及哪些方面允许变化。 不幸的是，有时你会发现数据以一种不太支持广泛意义上的可推广性的方式进行分析，这往往是因为低估了刺激材料或实验任务的独特特征对观测结果的影响 (Yarkoni, 2019)。 1.3 关于可重复性的说明 本课程的数据分析是使用R编写脚本进行的。 可重复性指的是在不同情况下重现研究结果的可能性程度。 如果我们能在给定原始数据的情况下得到相同的结果，我们会说这个发现在分析(analytically)或计算(computationally)上是可重复的。需要注意的是，这与说一个发现可复制(replicable)是不同的。可复制指的是能够在新样本中复制这一发现。对于这些术语并没有广泛的共识，但方便起见，我们可以将分析上的可重复性(reproducibility)和可复制性(replicability)视为两种不同但相关的可重复性(reproducibility)类型，前者反映分析员之间(或同一分析员随时间变化)的可重复性，而后者反映了在被试样本或亚群体之间的可重复性。 确保分析可重复性是一个难题。如果你未能正确记录自己的分析过程，或者你使用的软件被修改或过时并且变得不可用，你可能会在重现自己的发现时遇到麻烦！ 分析的另一个重要属性是透明度——在某种研究中所有步骤都可以公开的程度。一项研究可能是透明的但不可重复，反之亦然。使用促进透明度的工作流程非常重要。这使得脚本编程的“编辑–执行”工作流程对于数据分析来说是理想的选择，远远优于大多数商业统计软件的“点–点击”的工作流程。通过编写代码，你可以使逻辑和决策过程对他人明确，并易于重建。 1.4 基于模拟的方法 本课程最后一个重要特点是采用了基于模拟的方法来学习统计模型。通过数据模拟，我们定义一个特定模型来描述感兴趣的总体，然后利用计算机的随机数生成器来模拟从该总体中抽样的过程。我们将在下面看一个简单的例子。 在分析数据时，你会面临的经典问题是你不知道你正在研究的总体的“真实情况”。你从该总体中抽取一个样本，对观测到的数据获取方式做出一些假设，然后利用观察到的数据来估计未知的总体参数及这些参数的不确定性。 数据模拟颠倒了这个过程。你会定义一个模型的参数，代表关于(假设的)总体的真实情况，从中获取数据。然后，你可以像平常一样分析获得的数据，并考察参数估计与真实值之间的对应程度。 让我们看一个例子。假设你对以下问题感兴趣：作为学步幼儿的父母是否会“提高”你的反应能力。如果你曾经照顾过一个幼儿，你就会知道身体危险似乎总是在即——他们可能从刚刚爬上的椅子上摔下来，被门里夹到，头撞在桌子角上等等——所以你需要保持警惕并准备迅速行动。你假设这种警惕会转化为在幼儿不在场的其他情况下的更快反应时间，比如在心理实验室里。因此，你招募了一组有幼儿的父母来实验室。你让每个父母在闪烁的灯光出现时尽快按下按钮，并测量他们的反应时(以毫秒为单位)。对于每个父母，你计算了他们在所有试验中的平均反应时。我们可以使用R中的rnorm()函数模拟50个父母的平均反应时。但在我们开始之前，我们将加载我们需要的包（tidyverse）并设置随机种子(random seed)，以确保你(读者)得到和我(作者)相同的随机值。 library(&quot;tidyverse&quot;) set.seed(2021) # 可以是任意整数 parents &lt;- rnorm(n = 50, mean = 480, sd = 40) ## [1] 475.1016 502.0983 493.9460 494.3853 515.9221 403.0972 490.4698 516.6227 ## [9] 480.5509 549.1985 436.7118 469.0870 487.2798 540.3417 544.1788 406.3410 ## [17] 544.9324 485.2556 539.2449 540.5327 442.3023 472.5726 435.9550 528.3246 ## [25] 415.0025 484.2151 421.7823 465.8394 476.2520 524.0267 401.4470 422.0822 ## [33] 520.7777 423.1433 455.8187 416.6610 428.5627 421.8126 476.5172 500.1895 ## [41] 484.6555 550.4085 466.1953 564.8000 478.6249 448.3138 539.0206 450.9777 ## [49] 492.4952 507.6786 我们选择使用rnorm()来生成数据，这是一个从正态分布中生成随机数的函数，这反映了我们的假设——平均反应时在总体中呈正态分布。正态分布由两个参数定义，一个是均值(通常用希腊字母\\(\\mu\\)表示，发音为”myoo”)，另一个是标准差(通常用希腊字母\\(\\sigma\\)表示，发音为”sigma”)。由于我们自己生成了数据，所以\\(\\mu\\)和\\(\\sigma\\)都是已知的，在调用rnorm()时，我们将它们分别设置为480和40。 当然，为了验证我们的假设，我们需要一个对照组，所以我们定义了一个非父母的对照组。我们用相同的方式从这个对照组生成数据，但改变了平均值。 control &lt;- rnorm(n = 50, mean = 500, sd = 40) 让我们将它们放入数据框(tibble)中，以便更容易绘制和分析数据。该数据框中的每一行表示来自特定被试的平均反应时。 dat &lt;- tibble(group = rep(c(&quot;parent&quot;, &quot;control&quot;), each = 50), rt = c(parents, control)) dat ## # A tibble: 100 × 2 ## group rt ## &lt;chr&gt; &lt;dbl&gt; ## 1 parent 475. ## 2 parent 502. ## 3 parent 494. ## 4 parent 494. ## 5 parent 516. ## 6 parent 403. ## 7 parent 490. ## 8 parent 517. ## 9 parent 481. ## 10 parent 549. ## # ℹ 90 more rows 下面是对模拟数据的一些尝试。 以某种合理的方式绘制数据。 计算平均值和标准差。它们与总体参数相比如何? 对这些数据进行t检验。群组效应显著吗? 做完这些后，再做一次，但改变样本量、总体参数或两者都改变。 参考文献 Yarkoni, T. (2019). The generalizability crisis. https://doi.org/10.31234/osf.io/jqw35 "],["相关和回归.html", "2 相关和回归 2.1 相关矩阵(Correlation matrices) 2.2 模拟二元数据 2.3 相关和回归的关系 2.4 练习", " 2 相关和回归 2.1 相关矩阵(Correlation matrices) 你可能已经通过阅读心理学论文对相关矩阵这个概念有所了解。相关矩阵是总结同一个体的多个测量值之间关系的常用方法。 假设你用多个量表测量了心理幸福感。一个问题是这些量表在多大程度上测量了相同的东西。通常，你会查看相关矩阵来探索测量之间所有成对关系。 回忆一下，相关系数量化了两个变量之间关系的强度和方向。它通常用符号\\(r\\)或\\(\\rho\\)(希腊字母”rho”)表示。相关系数的范围在-1到1之间，其中0表示没有关系，正值反映正相关(一个变量增加，另一个也增加)，负值反映负相关(一个变量增加，另一个减少)。 图2.1: 不同类型的二元关系 如果你有\\(n\\)个测量值，你可以计算多少个成对相关？你可以用下面蓝框中的公式来计算，也可以更简单地通过R中的choose(n, 2)函数直接计算。例如，要获得6个测量值之间可能的成对相关数量，你可以输入choose(6, 2)，这会告诉你有15对组合。 对于任意\\(n\\)个测量值，你可以计算\\(\\frac{n!}{2(n - 2)!}\\)个各值之间的成对相关。符号\\(!\\)称为阶乘(factorial)运算符，定义为从1到\\(n\\)所有数字的乘积。因此，如果你有6个测量值，你可以得到 \\[ \\frac{6!}{2(6-2)!} = \\frac{1 \\times 2 \\times 3 \\times 4 \\times 5 \\times 6}{2\\left(1 \\times 2 \\times 3 \\times 4\\right)} = \\frac{720}{2(24)} = 15 \\] 你可以使用R中的base::cor()或corrr::correlate()来创建相关矩阵。我们更喜欢后者函数，因为cor()要求你的数据存储在矩阵中，而我们将处理的大多数数据是存储在数据框中的表格数据。corrr::correlate()函数将数据框作为第一个参数，并提供”整洁”的输出，因此它可以更好地与tidyverse系列函数和管道操作符(%&gt;%)联动。 让我们创建一个相关矩阵来看看它是如何工作的。首先加载我们需要的包。 library(&quot;tidyverse&quot;) library(&quot;corrr&quot;) # 如缺失(missing)，在控制台(console)中输入install.packages(&quot;corrr&quot;) 我们将使用starwars数据集，这是在加载tidyverse包后可用的内置数据集。该数据集包含了出现在星球大战电影系列中的各种角色的信息。让我们来看看之间的相关性 starwars %&gt;% select(height, mass, birth_year) %&gt;% correlate() ## Correlation computed with ## • Method: &#39;pearson&#39; ## • Missing treated using: &#39;pairwise.complete.obs&#39; ## # A tibble: 3 × 4 ## term height mass birth_year ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 height NA 0.131 -0.404 ## 2 mass 0.131 NA 0.478 ## 3 birth_year -0.404 0.478 NA 你可以在任意给定的行或列的交叉处查找任何双变量相关系数。因此，height和mass之间的相关系数是.131，你可以在第1行，第2列或第2行，第1列找到它——它们是相同的。请注意，这里只有choose(3, 2) = 3个唯一的双变量关系，但每个关系在表中出现了两次。我们可能只想显示唯一的组合，这可以通过在管道中附加corrr::shave()来实现。 starwars %&gt;% select(height, mass, birth_year) %&gt;% correlate() %&gt;% shave() ## Correlation computed with ## • Method: &#39;pearson&#39; ## • Missing treated using: &#39;pairwise.complete.obs&#39; ## # A tibble: 3 × 4 ## term height mass birth_year ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 height NA NA NA ## 2 mass 0.131 NA NA ## 3 birth_year -0.404 0.478 NA 现在我们只有相关矩阵的下三角部分，但NA看起来很难看，前导0也不美观。corrr包还提供了fashion()函数，可以对其进行清理(更多选项请查阅?corrr::fashion)。 starwars %&gt;% select(height, mass, birth_year) %&gt;% correlate() %&gt;% shave() %&gt;% fashion() ## Correlation computed with ## • Method: &#39;pearson&#39; ## • Missing treated using: &#39;pairwise.complete.obs&#39; ## term height mass birth_year ## 1 height ## 2 mass .13 ## 3 birth_year -.40 .48 相关性只有在关系(大致)线性且没有严重的异常值对结果产生过大影响时才能很好地描述关系。因此，可视化相关性通常和量化它们一样是个好主意。base::pairs()函数可以实现这一点。pairs()的第一个参数形式为~ v1 + v2 + v3 + ... + vn，其中v1、v2等是你想要进行相关分析的变量名。 pairs(~ height + mass + birth_year, starwars) 图2.2: 星球大战数据集相关关系 我们会发现一个巨大的离群值影响了我们的数据。具体来说是有个体重超过1200kg的生物。让我们找出它并从数据集里面删掉它。 starwars %&gt;% filter(mass &gt; 1200) %&gt;% select(name, mass, height, birth_year) ## # A tibble: 1 × 4 ## name mass height birth_year ## &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 Jabba Desilijic Tiure 1358 175 600 好了，让我们看看没有了这个庞然大物的数据会是什么样子。 starwars2 &lt;- starwars %&gt;% filter(name != &quot;Jabba Desilijic Tiure&quot;) pairs(~height + mass + birth_year, starwars2) 图2.3: 去除体重离群值后星球大战数据集相关关系 好多了，但还有个生物的离群出生年份可能是我们不想要的。 starwars2 %&gt;% filter(birth_year &gt; 800) %&gt;% select(name, height, mass, birth_year) ## # A tibble: 1 × 4 ## name height mass birth_year ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Yoda 66 17 896 是尤达大师！他和宇宙一样古老。让我们抛开他看看图会怎么样。 starwars3 &lt;- starwars2 %&gt;% filter(name != &quot;Yoda&quot;) pairs(~height + mass + birth_year, starwars3) 图2.4: 去除体重和出生年份离群值后星球大战数据集相关关系 看起来更好了。让我们看看它是怎样改变我们的相关矩阵的。 starwars3 %&gt;% select(height, mass, birth_year) %&gt;% correlate() %&gt;% shave() %&gt;% fashion() ## Correlation computed with ## • Method: &#39;pearson&#39; ## • Missing treated using: &#39;pairwise.complete.obs&#39; ## term height mass birth_year ## 1 height ## 2 mass .73 ## 3 birth_year .44 .24 请注意，这些值与我们开始时的值有很大不同。 有时移除离群值不是一个好办法。处理离群值的另一个办法是使用一种更稳健(robust)的方法。使用corrr::correlate()默认计算的相关系数是Pearson积差相关(Pearson product-moment correlation)系数。我们也能通过改变correlate()的method()参数来计算Spearman相关系数。这将在计算相关性之前用排名替换原始值，因此仍会包括离群值，但影响将大大减小。 starwars %&gt;% select(height, mass, birth_year) %&gt;% correlate(method = &quot;spearman&quot;) %&gt;% shave() %&gt;% fashion() ## Correlation computed with ## • Method: &#39;spearman&#39; ## • Missing treated using: &#39;pairwise.complete.obs&#39; ## term height mass birth_year ## 1 height ## 2 mass .72 ## 3 birth_year .15 .15 顺便一提，如果你用R Markdown生成报告，并希望你的表格有个好看的格式，可以使用knitr:: able()。 starwars %&gt;% select(height, mass, birth_year) %&gt;% correlate(method = &quot;spearman&quot;) %&gt;% shave() %&gt;% fashion() %&gt;% knitr::kable() term height mass birth_year height mass .72 birth_year .15 .15 2.2 模拟二元数据 你已经学会了使用rnorm()函数从正态分布中模拟数据。回忆一下，rnorm()允许你指定单个变量的均值和标准差。那我们怎么模拟相关变量呢？ 应该很明确，你不能仅仅运行两次rnorm()后组合变量就完事。因为这会得到两个不相关的变量，即相关性为零。 MASS包提供mvrnorm()函数，这是rnorm的”多元”(multivariate)版(因此函数的名字是’mv’ + ‘rnorm’，这样更容易记住)。 R预装了MASS包。但MASS包中你唯一可能会用到的函数只是mvrnorm()，因此相比于使用library(\"MASS\")加载包，使用MASS::mvrnorm()是更好的办法，尤其是在MASS和tidyverse里的dplyr包不太合得来的情况下(因为两个包都有select()函数)。因此，如果在加载tidyverse之后加载MASS，那么最终得到的select()是MASS版本，而不是dplyr版本。这会让你绞尽脑汁来找出代码的问题所在，所以总在不加载的情况下使用MASS::mvrnorm()吧。 这里作者贴了一则他在Twitter(现X)上吐槽MASS的打油诗，不过现在已经查不到了QwQ，考虑到翻译水平不佳，附上原文！ MASS before dplyr, clashes not dire; dplyr before MASS, pain in the ass. —— Dale Barr(September 30, 2014) 请查看mvrnorm()函数的文档(在控制台输入?MASS::mvrnorm)。 有3个参数需要注意： 参数 描述 n 所需样本数 mu 一个给出变量均值的向量 Sigma 一个正定对称矩阵，用于指定变量的协方差矩阵 对n和mu的描述可以理解，但“一个正定对称矩阵(positive-definite symmetric matrix)，用于指定变量的协方差矩阵”是什么意思呢？ 当你有个多元数据时，协方差矩阵(也叫方差-协方差矩阵)反映了各个变量的方差及其相互关系。它类似于标准差的多维版本。要充分描述单变量正态分布，你只需要知道均值和标准差；要描述双变量正态分布，你需要分别知道两个变量的均值、标准差和他们的相关性；对于包含两个以上变量的多元分布，你需要知道所有变量的均值、它们的标准差以及所有可能的成对相关性。这些概念在我们开始讨论混合效应模型时会变得非常重要。 你可以将协方差矩阵看作类似于之前见过的相关矩阵；实际上，通过一些计算，你可以将协方差矩阵转换为相关矩阵。 你在说什么《黑客帝国(Matrix)》？那不是从上世纪90年代开始的科幻电影系列吗？ 在数学中，矩阵只是向量概念的推广:向量被认为只有一个维度，而矩阵可以是任意数量的维度。 那么矩阵 \\[ \\begin{pmatrix} 1 &amp; 4 &amp; 7 \\\\ 2 &amp; 5 &amp; 8 \\\\ 3 &amp; 6 &amp; 9 \\\\ \\end{pmatrix} \\] 是一个3(行) x 3(列)矩阵，包括了列向量\\(\\begin{pmatrix} 1 \\\\ 2 \\\\ 3 \\\\ \\end{pmatrix}\\)，\\(\\begin{pmatrix} 4 \\\\ 5 \\\\ 6 \\\\ \\end{pmatrix}\\)和\\(\\begin{pmatrix} 7 \\\\ 8 \\\\ 9 \\\\ \\end{pmatrix}\\)。通常我们用\\(i\\) x \\(j\\)的形式表示矩阵，\\(i\\)是行数，\\(j\\)是列数。因此，一个3x2矩阵有3行2列，像这样： \\[ \\begin{pmatrix} a &amp; d \\\\ b &amp; e \\\\ c &amp; f \\\\ \\end{pmatrix} \\] 方阵是行数等于列数的矩阵。 你可以用matrix()函数在R中创建一个方阵，或者使用base R的 cbind()和rbind()将向量连接在一起，它们分别将向量按列和按行连接在一起。在控制台试试cbina(1:3, 4:6, 7:9)吧。 那么“正定”和“对称”是什么呢？这是对可以表示多元正态分布的这类矩阵的数学要求。换句话说，你提供的协方差矩阵必须表示一个合法的多元正态分布。在这点上，你真的不需要知道再多了。 让我们从模拟假设的人类身高和体重的数据开始。我们知道这些是相关的。为了能够模拟数据，我们需要这两个变量的均值和标准差以及它们的相关性。 我找到了一些数据并把它转换为CSV文件。如果你想跟上，可以下载这个文件heights_and_weights.csv。这是散点图： handw &lt;- read_csv(&quot;data/heights_and_weights.csv&quot;, col_types = &quot;dd&quot;) ggplot(handw, aes(height_in, weight_lbs)) + geom_point(alpha = .2) + labs(x = &quot;height (inches)&quot;, y = &quot;weight (pounds)&quot;) 图2.5: 475人的身高和体重(包括婴儿) 这不是一个线性关系。我们可以先对每个变量进行对数(log)变换。 handw_log &lt;- handw %&gt;% mutate(hlog = log(height_in), wlog = log(weight_lbs)) 图2.6: 对数变换后的身高和体重 散点图右上侧尾部有一个大的点簇，这可能表示在这个样本中成年人比儿童更多，因为成年人更高和更重。 对数身高的均值是4.11 (SD = 0.26)，而对数体重的均值是4.74 (SD = 0.65)。对数身高和对数体重之间的相关性我们可以用cor()函数获得，高达0.96。 我们现在有了模拟500人身高和体重所需的所有信息。但我们如何将这些信息输入到MASS::mvrnorm()呢？我们知道函数调用的第一部分是MASS::mvrnorm(500, c(4.11,4.74), ...)，但Sigma——那个协方差矩阵呢？我们从上面知道\\(\\hat{\\sigma}_x = 0.26\\)和\\(\\hat{\\sigma}_y = 0.65\\)，以及\\(\\hat{\\sigma}_y = 0.65\\), and \\(\\hat{\\rho}_{xy} = 0.96\\)。 表示二元数据Sigma (\\(\\mathbf{\\Sigma}\\))的协方差矩阵如下： \\[ \\mathbf{\\Sigma} = \\begin{pmatrix} {\\sigma_x}^2 &amp; \\rho_{xy} \\sigma_x \\sigma_y \\\\ \\rho_{yx} \\sigma_y \\sigma_x &amp; {\\sigma_y}^2 \\\\ \\end{pmatrix} \\] 方差（标准差的平方，\\({\\sigma_x}^2\\)和\\({\\sigma_y}^2\\)）位于对角线上，协方差(相关系数乘以两个标准差，\\(\\rho_{xy} \\sigma_x \\sigma_y\\))位于非对角线上。记住协方差就是相关系数与两个标准差的积，这是很有用的。正如我们在上面的相关矩阵中看到的，表格中存在额外信息；也就是说，协方差同时出现在矩阵的右上角单元格和左下角单元格。 代入之前的值，协方差矩阵应该是： \\[ \\begin{pmatrix} .26^2 &amp; (.96)(.26)(.65) \\\\ (.96)(.65)(.26) &amp; .65^2 \\\\ \\end{pmatrix} = \\begin{pmatrix} .067 &amp; .162 \\\\ .162 &amp; .423 \\\\ \\end{pmatrix} \\] 很好，那么我们如何在R中形成Sigma以便我们可以将它传递给mvrnorm()函数呢？我们将使用matrix()函数，如下所示。 首先，让我们定义协方差并将其存储在变量my_cov中。 my_cov &lt;- .96 * .26 * .65 现在我们将使用matrix()来定义我们的Sigma为my_Sigma。 my_Sigma &lt;- matrix(c(.26^2, my_cov, my_cov, .65^2), ncol = 2) my_Sigma ## [,1] [,2] ## [1,] 0.06760 0.16224 ## [2,] 0.16224 0.42250 对matrix()函数感到困惑吗? 通过运行下面的代码，你可以发现matrix()是逐列填充矩阵元素，而不是逐行填充: matrix(c(\"a\", \"b\", \"c\", \"d\"), ncol = 2) 如果你想改变这种行为，将byrow参数设置为TRUE。 matrix(c(\"a\", \"b\", \"c\", \"d\"), ncol = 2, byrow = TRUE) 太好了！现在我们得到了my_Sigma，我们已经准备好使用MASS::mvrnorm()了。让我们通过创建6个模拟的人的数据来测试一下。 set.seed(62) # 为了可重复性 # 传递*命名的*向量c(height = 4.11, weight = 4.74)给mu可以在输出中得到列名 log_ht_wt &lt;- MASS::mvrnorm(6, c(height = 4.11, weight = 4.74), my_Sigma) log_ht_wt ## height weight ## [1,] 4.254209 5.282913 ## [2,] 4.257828 4.895222 ## [3,] 3.722376 3.759767 ## [4,] 4.191287 4.764229 ## [5,] 4.739967 6.185191 ## [6,] 4.058105 4.806485 那么MASS::mvrnorm()会返回一个矩阵，每个模拟的人对应一行，其中第一列表示对数身高，第二列表示对数体重。但是对数身高和对数体重对我们来说并不是很有用，所以让我们使用exp()函数来进行转换，它是log()转换的逆操作。 exp(log_ht_wt) ## height weight ## [1,] 70.40108 196.94276 ## [2,] 70.65632 133.64963 ## [3,] 41.36254 42.93844 ## [4,] 66.10779 117.24065 ## [5,] 114.43045 485.50576 ## [6,] 57.86453 122.30092 那么我们第一个模拟的人的身高是70.4英寸(大约是5’5”或者178.816 cm)，体重是196.94磅(约89.32 kg)。听起来感觉不错吧！(还是要注意，它会生成超出我们原始数据范围的观测值：我们会得到超高的人，例如第5个观测值，但至少体重/身高的关系会被保留)。 好的，让我们随机生成一群人的数据，将它们从对数转换为英寸和磅，然后将它们与我们的原始数据进行比较，看看效果如何。 ## 模拟新的人 new_humans &lt;- MASS::mvrnorm(500, c(height_in = 4.11, weight_lbs = 4.74), my_Sigma) %&gt;% exp() %&gt;% # 从对数转换回英寸和磅 as_tibble() %&gt;% # 为绘图转换为tibble格式 mutate(type = &quot;simulated&quot;) # 将他们标记为模拟(simulated) ## 合并真实和模拟的数据集，其中handw是来自heights_and_weights.csv的变量 alldata &lt;- bind_rows(handw %&gt;% mutate(type = &quot;real&quot;), new_humans) ggplot(alldata, aes(height_in, weight_lbs)) + geom_point(aes(colour = type), alpha = .1) 图2.7: 真实和模拟的人 你可以看到，我们模拟的人与正常的人非常相似，只是我们创建了一些身高和体重超出正常范围的人。 2.3 相关和回归的关系 好的，我们知道如何估计相关了，但如果我们想要根据身高来预测体重该怎么办呢？这可能听起来像一个不切实际的问题。但事实上，在使用或进行安全性取决于患者体重的药物或程序，但没时间称量患者体重时，急救医护人员可以使用这种技术，在紧急情况下迅速估算人们的体重。 回忆一下，简单回归模型的GLM是： \\[Y_i = \\beta_0 + \\beta_1 X_i + e_i.\\] 在这里，我们尝试根据他们观测到的身高(\\(X_i\\))来预测体重(\\(Y_i\\))。在这个方程里，\\(\\beta_0\\)和\\(\\beta_1\\)分别是y轴截距和斜率的参数，\\(e_i\\)是残差。传统上假设\\(e_i\\)的值来自均值为0、方差为\\(\\sigma^2\\)的正态分布；数学上的表述是\\(e_i \\sim N(0, \\sigma^2)\\)，其中\\(\\sim\\)表示“按照分布”，\\(N(0, \\sigma^2)\\)表示“均值为0、方差为\\(\\sigma^2\\)的正态分布(\\(N\\))”。 这表明如果我们有X和Y的均值估计值(分别标记为\\(\\mu_x\\)和\\(\\mu_y\\))、标准差估计值(\\(\\hat{\\sigma}_x\\)和\\(\\hat{\\sigma}_y\\))、X和Y之间相关系数的估计值(\\(\\hat{\\rho}\\))，我们就有了估计回归方程参数\\(\\beta_0\\)和\\(\\beta_1\\)所需要的所有信息。下面是具体做法。(译者注：这里的估计值是指根据样本信息来估计总体情况的估计值，是总体的估计值、样本的观测值) 首先，回归线的斜率\\(\\beta_1\\)等于相关系数\\(\\rho\\)乘以\\(Y\\)和\\(X\\)的标准差之比。 \\[\\beta_1 = \\rho \\frac{\\sigma_Y}{\\sigma_X}\\] 根据上面对数身高和对数体重的估计值，你能算出\\(\\beta_1\\)吗? b1 &lt;- .96 * (.65 / .26) b1 ## [1] 2.4 下一个要注意的点是，基于数学原理，回归线必须通过与\\(X\\)和\\(Y\\)均值对应的点，即点\\((\\mu_x, \\mu_y)\\)(你可以想象回归线根据斜率围绕该点“旋转”)。你也知道\\(\\beta_0\\)是y轴截距，即在\\(X = 0\\)处与纵轴相交的点。根据这些信息和上面的估计值，你能推断出\\(\\beta_0\\)的值吗？ 下面是你求解\\(\\beta_0\\)的推理过程。 想象一下，从\\(X = \\mu_x\\)逐步一个一个单位后退到\\(X = 0\\)。在\\(X = \\mu_x\\)处，\\(Y = 4.74\\)，每在X轴后退一个单位，\\(Y\\)将下降\\(\\beta_1 = 2.4\\)个单位。当你到0时，\\(Y\\)将从\\(\\mu_y\\)下降到\\(\\mu_y - \\mu_x \\beta_1\\)。 因此通解是：\\(\\beta_0 = \\mu_y - \\mu_x\\beta_1\\)。 因为\\(\\beta_1 = 2.4\\)、\\(\\mu_x = 4.11\\)、\\(\\mu_y = 4.74\\)，所以\\(\\beta_0 = -5.124\\)。因此，我们的回归方程是： \\[Y_i = -5.124 + 2.4X_i + e_i.\\] 为了验证我们的结果，我们先对对数转换后的数据进行回归，使用lm()函数，它采用最小二乘法(ordinary least squares regression)来估计参数。 summary(lm(wlog ~ hlog, handw_log)) ## ## Call: ## lm(formula = wlog ~ hlog, data = handw_log) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.63296 -0.09915 -0.01366 0.09285 0.65635 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -5.26977 0.13169 -40.02 &lt;2e-16 *** ## hlog 2.43304 0.03194 76.17 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.1774 on 473 degrees of freedom ## Multiple R-squared: 0.9246, Adjusted R-squared: 0.9245 ## F-statistic: 5802 on 1 and 473 DF, p-value: &lt; 2.2e-16 看起来非常接近。不完全匹配的原因仅仅是我们将估计值四舍五入到小数点后两位以方便计算。 作为另一个检查，让我们将手动计算的回归线叠加在对数转换后数据的散点图上。 ggplot(handw_log, aes(hlog, wlog)) + geom_point(alpha = .2) + labs(x = &quot;log(height)&quot;, y = &quot;log(weight)&quot;) + geom_abline(intercept = -5.124, slope = 2.4, colour = &#39;blue&#39;) 图2.8: 对数值和叠加的回归线 看起来是对的。 最后，以下是相关性和回归之间关系的一些影响： 当\\(\\beta_1 = 0\\)时，与\\(\\rho = 0\\)相同。 当\\(\\beta_1 &gt; 0\\)时， \\(\\rho &gt; 0\\)，因为标准差不能为负。 当\\(\\beta_1 &lt; 0\\)时， \\(\\rho &lt; 0\\)，原因同上。 拒绝零假设\\(\\beta_1 = 0\\)与拒绝零假设\\(\\rho = 0\\)是相同的。在lm()中得到的\\(\\beta_1\\)的p值与使用cor.test()得到的\\(\\rho\\)的p值相同。 2.4 练习 "],["多元回归.html", "3 多元回归 3.1 一个例子：如何在统计学上取得好成绩", " 3 多元回归 单层数据包含\\(m\\)个预测变量的一般模型是： \\[ Y_i = \\beta_0 + \\beta_1 X_{1i} + \\beta_2 X_{2i} + \\ldots + \\beta_m X_{mi} + e_i \\] 其中\\(e_i \\sim \\mathcal{N}\\left(0, \\sigma^2\\right)\\)，换句话说，我们假设误差来自一个均值为0，方差为\\(\\sigma^2\\)的正态分布。 注意，这里的关键假设不是响应变量(\\(Y\\))服从正态分布，也不是单个预测变量(\\(X\\))服从正态分布；而是仅模型残差服从正态分布(详细讨论见这篇博客)。单个\\(X\\)预测变量可以是任意组合的连续变量和/或分类变量，包括变量之间的交互。这个特定模型背后的进一步假设是，关系是“平面的”(可以用一个平面描述，类似于简单回归中的线性假设)，且误差方差与预测变量无关。 \\(\\beta\\)的值被称为回归系数(regression coefficient)。每个\\(\\beta_h\\)被解释为在保持其他所有预测变量不变的情况下\\(\\beta_h\\)的偏效应(partial effect)。如果你有\\(m\\)个预测变量，你将有\\(m+1\\)个回归系数：一个用于截距，每个预测变量各一个 尽管在统计教科书中对多元回归的讨论很常见，但你很少有机会应用到上述的精确模型。因为上述模型假设的是单层数据，而大多数心理学数据是多层的。然而，这两种数据集的基本原理是相同的，因此先学习比较简单的案例是值得的。 3.1 一个例子：如何在统计学上取得好成绩 让我们来看一些(虚构但基于现实的)数据，看看我们如何使用多元回归来回答各种研究问题。在这个假设的研究中，你有一个包含100名统计学学生的数据集，其中包括他们的最终课程成绩(grade)、每个学生参加讲座的次数(lecture，一个范围为0-10的整数)、每个学生点击下载在线资料的次数(nclicks)以及每个学生在修这门课程之前的平均绩点(GPA)，其范围从0(不及格)到4(最高可能成绩)。 3.1.1 数据导入和可视化 让我们加载数据grades.csv并看一看。 library(&quot;corrr&quot;) # 相关矩阵 library(&quot;tidyverse&quot;) grades &lt;- read_csv(&quot;data/grades.csv&quot;, col_types = &quot;ddii&quot;) grades ## # A tibble: 100 × 4 ## grade GPA lecture nclicks ## &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 2.40 1.13 6 88 ## 2 3.67 0.971 6 96 ## 3 2.85 3.34 6 123 ## 4 1.36 2.76 9 99 ## 5 2.31 1.02 4 66 ## 6 2.58 0.841 8 99 ## 7 2.69 4 5 86 ## 8 3.05 2.29 7 118 ## 9 3.21 3.39 9 98 ## 10 2.24 3.27 10 115 ## # ℹ 90 more rows 首先，让我们看一看所有的两两相关。 grades %&gt;% correlate() %&gt;% shave() %&gt;% fashion() ## Correlation computed with ## • Method: &#39;pearson&#39; ## • Missing treated using: &#39;pairwise.complete.obs&#39; ## term grade GPA lecture nclicks ## 1 grade ## 2 GPA .25 ## 3 lecture .24 .44 ## 4 nclicks .16 .30 .36 pairs(grades) 图2.2: grades数据集中的所有成对关系 3.1.2 估计和解释 我们将使用lm()函数来估计回归系数(\\(\\beta\\)s)。针对一个有\\(m\\)个预测变量的GLM： \\[ Y_i = \\beta_0 + \\beta_1 X_{1i} + \\beta_2 X_{2i} + \\ldots + \\beta_m X_{mi} + e_i \\] 对base R的lm()调用如下： lm(Y ~ X1 + X2 + ... + Xm, data) 变量Y是你的响应变量，变量X是预测变量。注意，你不需要明确指定截距或残差项;这些是默认包含的。 对于当前数据，让我们通过lecture和nclicks来预测grade。 my_model &lt;- lm(grade ~ lecture + nclicks, grades) summary(my_model) ## ## Call: ## lm(formula = grade ~ lecture + nclicks, data = grades) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.21653 -0.40603 0.02267 0.60720 1.38558 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.462037 0.571124 2.560 0.0120 * ## lecture 0.091501 0.045766 1.999 0.0484 * ## nclicks 0.005052 0.006051 0.835 0.4058 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.8692 on 97 degrees of freedom ## Multiple R-squared: 0.06543, Adjusted R-squared: 0.04616 ## F-statistic: 3.395 on 2 and 97 DF, p-value: 0.03756 我们通常会在参数符号的顶部加上一个帽子(hat)，以明确我们正在处理样本的估计值，而不是(未知的)真实总体值。由上可知: \\(\\hat{\\beta}_0\\) = 1.46 \\(\\hat{\\beta}_1\\) = 0.09 \\(\\hat{\\beta}_2\\) = 0.01 这告诉我们，一个人的预期成绩与他们的参加讲座的次数和点击下载在线资料的次数通过以下公式相关联： grade = 1.46 + 0.09 \\(\\times\\) lecture + 0.01 \\(\\times\\) nclicks 因为\\(\\hat{\\beta}_1\\)和\\(\\hat{\\beta}_2\\)都是正数，所以我们知道lecture和nclicks的值越高，成绩越好。 因此，如果有人问你，你预测一个参加了3次讲座并下载了70次的学生成绩是多少，你可以通过代入相应的值轻松算出来。 grade = 1.46 + 0.09 \\(\\times\\) 3 + 0.01 \\(\\times\\) 70 相当于： grade = 1.46 + 0.27 + 0.7 可化简为： grade = 2.43 3.1.3 使用predict()通过线性模型进行预测 如果我们想通过新的预测变量值来预测响应变量值，我们可以使用base R 的predict()函数。 predict()函数有两个主要参数。第一个参数是拟合的模型对象(即上面的my_model)，第二个参数是包含预测变量新值的数据框(或tibble，R中和数据框data frame类似的一种数据格式)。 在新表中，你需要包含所有的预测变量。如果您的tibble缺少任何预测变量，你将收到错误消息(error message)。您还需要确保新表中的变量名与模型中的变量名完全匹配。 让我们创建一个带有新值的tibble并进行测试。 ## “tribble”是一种按行而不是按列创建tibble的方法。有时这样做会很有用。 new_data &lt;- tribble(~lecture, ~nclicks, 3, 70, 10, 130, 0, 20, 5, 100) tribble()函数提供了一种按行而不是按列逐步构建tibble的方法，而使用tibble()函数则是按列逐步构建表格。 tribble()的第一行包含列名，每个列名前面都有一个波浪号(~)。 有时这种方法比逐行构建更容易阅读，尽管结果是相同的。考虑到这些，我们也可以使用以下方式创建上述表格： new_data &lt;- tibble(lecture = c(3, 10, 0, 5), nclicks = c(70, 130, 20, 100)) "],["参考文献.html", "参考文献", " 参考文献 Yarkoni, T. (2019). The generalizability crisis. https://doi.org/10.31234/osf.io/jqw35 "]]
