[["index.html", "学习统计模型——通过R模拟(施工中) 概述 译者按 如何引用本书 发现问题？ 教育者需知", " 学习统计模型——通过R模拟(施工中) 周博霖 2024-06-07 概述 本教材采用在R语言环境下模拟广义线性模型(General Linear Model, GLM)的方法来介绍统计分析。总体目标是教会学生如何将研究设计的描述转化为线性模型，来分析该研究的数据。重点是分析心理学实验数据所需的技能。 本教材包括以下内容： 线性模型工作流程; 方差-协方差矩阵; 多元回归; 交互效应(连续与分类; 分类与分类); 线性混合模型; 广义线性混合模型。 本课程的内容构成了格拉斯哥大学心理学院(University of Glasgow School of Psychology)由Dale Barr讲授的大学三年级一学期课程的基础。这也是由格拉斯哥大学心理学院工作人员开发的PsyTeachR系列课程材料的一部分。 与你可能遇到的其他教材不同，这是一本互动教材。每一章都包含嵌入式练习和网页应用来帮助学生更好地理解内容。你只有通过浏览器访问这些材料，这些互动内容才能正常工作。因此，不建议打印这些材料。如果你希望在没网的情况下访问教材或保存本地版本以防止网站变化或迁移，可以下载离线使用版本。只需要从ZIP压缩包中提取文件，在docs目录中找到index.html文件，然后使用浏览器打开这个文件即可。 译者按 对于线性混合模型的关注起源于本科毕业论文最初的研究设计，但因为各种原因，最终未采用混合线性模型进行研究。但在查阅资料的过程中对线性混合模型产生了一定兴趣，可之后没有进行深入探索。直到2024年初，阅读 Fraley et al. (2021) 的研究时又遇到了线性混合模型，而且还必须理清研究方法(如果你的研究领域是依恋关系，可以考虑阅读该论文，挺漂亮一论文)。幸运的是论文给出了相关R代码，不幸的是代码“充满”错误(也许是我理解不够深入，少量错误在我眼里被放大了)。这使得我下定决心跟线性混合模型死磕到底。 对于线性混合模型，网上并没有找到系统、免费、不太老旧的中文资料(反正我没找到，如知道欢迎推荐)。查阅R的lme4包(这应该是用R做GLMM最常用的包)相关资料时，发现了R包作者提供的GLMM FAQ中推荐了这篇教材，我就想着反正自己要看，干脆翻译一遍也当是为枯燥的生活添加一些小乐趣吧。 该教材相关信息在概述里面已经讲解，不再赘述。翻译的版本是公开的最新版本，应该是2023年进行微调后的版本(也可能就是2021版)，符合系统、免费、不太老旧三个要求，中文这个要求我尽量解决。本人非统计、英语相关专业，翻译习惯为：尽可能直译，实在无法翻译清楚的会根据自己的理解意译，对于自己想补充说明的地方会用“注”标识。这是本人第一次使用R书写材料，对bookdown十分不熟，只能尽可能还原原教材里的内容，如有条件建议阅读原教材。 希望这份译文对大家有所帮助，如发现错误或有修改建议，欢迎提交到github，或联系邮箱 zhoubolin0404@126.com。 如何引用本书 Barr, Dale J. (2021). Learning statistical models through simulation in R: An interactive textbook. Version 1.0.0. Retrieved from https://psyteachr.github.io/stat-models-v1. 发现问题？ 如果你发现错误或书写错误，有问题或建议，请在https://github.com/psyteachr/stat-models-v1/issues提交问题。谢谢！ 教育者需知 您可以根据自己的需求免费重复使用和修改本教材中的材料，但需要注明原作出处。请注意关于重复使用本材料的 Creative Commons CC-BY-SA 4.0 许可证的其他条款。 本书是使用R bookdown包构建的。源文件可在github上获得。 参考文献 Fraley, R. C., Gillath, O., &amp; Deboeck, P. R. (2021). Do life events lead to enduring changes in adult attachment styles? A naturalistic longitudinal investigation. Journal of Personality and Social Psychology, 120(6), 1567–1606. "],["前言.html", "1 前言 1.1 课程目的 1.2 广义线性混合模型(Generalized Linear Mixed-Effects Models, GLMMs) 1.3 关于可重复性的说明 1.4 基于模拟的方法", " 1 前言 1.1 课程目的 本课程的目的是教你如何分析(还有模拟!)作为心理学家你可能遇到的各种数据集。重点是行为数据——反应时、知觉判断、选择、决策、李克特量表评分、眼动、睡眠时间等。这些数据通常是在有计划的研究或实验中收集到的。 本课程旨在教授灵活、可推广、可重复的分析技术。你将学习到的技术是灵活的，这意味着它们可以应用到各式各样的研究设计和不同类型的数据上。通过充分考虑抽样对统计推断的潜在偏倚影响，它们在最大程度上具有可推广性——这有助于支持超越特定被试和实验中涉及的刺激得出结论。最后，你将学习到的技术会尽可能地做到可完全重复，因为你的分析将以R代码的纯文本脚本形式明确记录从原始数据到研究结果的每一个步骤。 1.2 广义线性混合模型(Generalized Linear Mixed-Effects Models, GLMMs) 本课程强调一个灵活的回归模型框架而不是教授处理不同类型数据的”公式”。课程假设你需要分析的基本数据类型将是多层的(multilevel)，而且你不仅仅需要处理连续测量数据，还要处理有序测量数据（李克特量表评分）、计数数据（特定事件发生的次数）以及名义数据（某物所属的类别）。 本课程结束时，你将学会如何使用广义线性混合模型(GLMMs)来量化因变量和一组预测变量之间的关系。要理解GLMMs，你需要学习以下三部分： “线性模型”部分，包括如何捕捉不同类型的预测变量及其交互效应； “混合”部分，包括如何使用随机效应来表示通过对同一批被试或刺激进行重复测量而产生的多层次依赖关系； “广义”部分，包括拓展线性模型来表示非完全正态自变量，包括计数、有序和二元变量。 1.2.1 线性模型 GLMMs是一般线性模型的扩展。一般线性模型是方差分析(ANOVA)、t检验和古典回归等更简单方法的基础。本课程的主要观点是：你可能遇到的几乎所有实验得到的数据都可以用GLMMs进行分析。 一个线性模型的简单例子： \\[Y_i = \\beta_0 + \\beta_1 X_i + e_i\\] 其中\\(Y_i\\)是样本\\(i\\)的因变量的观测值，由截距加上被系数\\(\\beta_1\\)加权的预测值\\(X_i\\)以及误差项构成。表示线性关系\\(Y_i = 3 + 2X_i + e_i\\)的模拟数据如图1.1所示。 图1.1: 线性模型Y = 3 + 2X的模拟数据 library(&quot;tidyverse&quot;) # if needed set.seed(62) dat &lt;- tibble(X = runif(100, -3, 3), Y = 3 + 2 * X + rnorm(100)) ggplot(dat, aes(X, Y)) + geom_point() + geom_abline(intercept = 3, slope = 2, color = &quot;blue&quot;) 你可能会发现上述方程表示的是一条直线(\\(y = mx + b\\))，其中\\(\\beta_0\\)是截距，\\(\\beta_1\\)是斜率。\\(e_i\\)是样本\\(i\\)的模型误差，表示样本观测值\\(Y_i\\)与给定\\(X_i\\)的模型预测值之间的差距。 表示法惯例 希腊字母(\\(\\beta\\), \\(\\rho\\), \\(\\tau\\))表示总体参数，通常是未观测到的，需要从数据中估计得到的。当我们想要区分估计参数和真实值时，我们会使用”hat”：如\\(\\hat{\\beta}_0\\)表示从数据中估计得到的\\(\\beta_0\\)的值。 大写拉丁字母(\\(X\\)、\\(Y\\))表示观测值——即你已经测量过的值，因此是已知的。你也会看到小写拉丁字母(如\\(e_i\\))，表示统计误差或其他我将称之为派生量或虚拟量的东西(这将在课程后面进行解释)。 线性模型中的”线性”并不像你想象的那样! 许多人认为”线性模型”只能捕捉线性关系，即可以用直线(或平面)来描述的关系。这是错误的。 线性模型是各种项的加权和，每个项都有一个预测变量(或常数)乘上一个系数。在上述模型中，系数是\\(\\beta_0\\)和\\(\\beta_1\\)。你可以用线性模型拟合各种复杂的关系，包括非线性关系，如下所示。 图1.2: 用线性模型建模的非线性关系 在左边面板中，我们使用线性模型\\(Y = \\beta_0 + \\beta_1 X + \\beta_2 X^2\\)捕捉了一个二次(抛物线)函数。X和Y之间的关系是非线性的，但模型本身是线性的。我们对预测变量\\(X\\)进行了平方处理，但系数\\(\\beta_0\\)、\\(\\beta_1\\)和\\(\\beta_2\\)并没有被平方、立方或类似的处理(它们都是”一次幂”)。 在中间面板中，我们使用线性模型捕捉了一个S形函数。在这里，Y变量表示某个事件的概率，例如基于学习时间来预测通过考试的概率。在这种情况下，我们通过在一个特殊的转换空间中估计线性模型来建模X和Y之间的关系，使得X-Y关系是线性的，然后将模型投影回非线性的概率空间(使用”链接函数”)。非线性来自于”链接函数”，但模型本身是线性的。 最后，右边面板展示了一种略显任意的波动模式，由广义可加混合模型捕获——这是一种我们在本课程中不会学到的高级技术。但从根本上说，它仍然是一个线性模型，因为它还是一系列复杂事物(在这种情况下是”基础函数”)的加权和，而系数提供了权重。 线性模型是一个系数是线性的模型；模型中的每个系数(\\(\\beta_0\\)、\\(\\beta_1\\))只允许被设置为一次幂，并且每个项\\(\\beta_i X_j\\)都只涉及单个系数。这些项只能与涉及其他系数的项相加，但不能相乘或相除(如\\(Y = \\frac{\\beta_1}{\\beta_2} X\\)是不允许的)。 当前课程的一个局限性是主要关注单变量数据，即将单一响应变量作为分析的焦点。通常情况下，你会处理相同对象的多个响应变量，但是同时对它们进行建模在技术上是非常困难的，并且超出了本课程的范围。一种更简单的方法(也是这里采用的方法)是对每个响应变量进行单独的单变量分析。 1.2.2 混合模型 研究结果的推断或解释的可推广性指的是它能够被轻松应用于超出特定研究背景(对象、刺激、任务等)的情境的程度。最理想的情况是，我们的发现能够适用于人类物种的所有成员，涵盖各种各样的刺激和任务；最糟糕的情况是，它们只能适用于那些受到我们使用的特定刺激的特定的人，在我们研究的特定背景下才观察得到。 研究结果的可推广性取决于几个因素：研究的设计方式、所使用的材料、被试的招募方式、给予被试的任务的性质以及数据分析的方式。在这门课程中我们将重点关注最后一点。在分析一个数据集时，如果你想要提出具有推广性的论断，你必须决定哪些可以算作你研究的重复——关于哪些方面应该在复制中保持不变，以及哪些方面允许变化。 不幸的是，有时你会发现数据以一种不太支持广泛意义上的可推广性的方式进行分析，这往往是因为低估了刺激材料或实验任务的独特特征对观测结果的影响 (Yarkoni, 2019)。 1.3 关于可重复性的说明 本课程的数据分析是使用R编写脚本进行的。 可重复性指的是在不同情况下重现研究结果的可能性程度。 如果我们能在给定原始数据的情况下得到相同的结果，我们会说这个发现在分析(analytically)或计算(computationally)上是可重复的。需要注意的是，这与说一个发现可复制(replicable)是不同的。可复制指的是能够在新样本中复制这一发现。对于这些术语并没有广泛的共识，但方便起见，我们可以将分析上的可重复性(reproducibility)和可复制性(replicability)视为两种不同但相关的可重复性(reproducibility)类型，前者反映分析员之间(或同一分析员随时间变化)的可重复性，而后者反映了在被试样本或亚群体之间的可重复性。 确保分析可重复性是一个难题。如果你未能正确记录自己的分析过程，或者你使用的软件被修改或过时并且变得不可用，你可能会在重现自己的发现时遇到麻烦！ 分析的另一个重要属性是透明度——在某种研究中所有步骤都可以公开的程度。一项研究可能是透明的但不可重复，反之亦然。使用促进透明度的工作流程非常重要。这使得脚本编程的“编辑–执行”工作流程对于数据分析来说是理想的选择，远远优于大多数商业统计软件的“指向–点击”的工作流程。通过编写代码，你可以使逻辑和决策过程对他人明确，并易于重建。 1.4 基于模拟的方法 本课程最后一个重要特点是采用了基于模拟的方法来学习统计模型。通过数据模拟，我们定义一个特定模型来描述感兴趣的总体，然后利用计算机的随机数生成器来模拟从该总体中抽样的过程。我们将在下面看一个简单的例子。 在分析数据时，你会面临的经典问题是你不知道你正在研究的总体的“真实情况”。你从该总体中抽取一个样本，对观测到的数据获取方式做出一些假设，然后利用观察到的数据来估计未知的总体参数及这些参数的不确定性。 数据模拟颠倒了这个过程。你会定义一个模型的参数，代表关于(假设的)总体的真实情况，从中获取数据。然后，你可以像平常一样分析获得的数据，并考察参数估计与真实值之间的对应程度。 让我们看一个例子。假设你对以下问题感兴趣：作为学步幼儿的父母是否会“提高”你的反应能力。如果你曾经照顾过一个幼儿，你就会知道身体危险似乎总是在即——他们可能从刚刚爬上的椅子上摔下来，被门里夹到，头撞在桌子角上等等——所以你需要保持警惕并准备迅速行动。你假设这种警惕会转化为在幼儿不在场的其他情况下的更快反应时间，比如在心理实验室里。因此，你招募了一组有幼儿的父母来实验室。你让每个父母在闪烁的灯光出现时尽快按下按钮，并测量他们的反应时(以毫秒为单位)。对于每个父母，你计算了他们在所有试验中的平均反应时。我们可以使用R中的rnorm()函数模拟50个父母的平均反应时。但在我们开始之前，我们将加载我们需要的包（tidyverse）并设置随机种子(random seed)，以确保你(读者)得到和我(作者)相同的随机值。 library(&quot;tidyverse&quot;) set.seed(2021) # 可以是任意整数 parents &lt;- rnorm(n = 50, mean = 480, sd = 40) ## [1] 475.1016 502.0983 493.9460 494.3853 515.9221 403.0972 490.4698 516.6227 ## [9] 480.5509 549.1985 436.7118 469.0870 487.2798 540.3417 544.1788 406.3410 ## [17] 544.9324 485.2556 539.2449 540.5327 442.3023 472.5726 435.9550 528.3246 ## [25] 415.0025 484.2151 421.7823 465.8394 476.2520 524.0267 401.4470 422.0822 ## [33] 520.7777 423.1433 455.8187 416.6610 428.5627 421.8126 476.5172 500.1895 ## [41] 484.6555 550.4085 466.1953 564.8000 478.6249 448.3138 539.0206 450.9777 ## [49] 492.4952 507.6786 我们选择使用rnorm()来生成数据，这是一个从正态分布中生成随机数的函数，这反映了我们的假设——平均反应时在总体中呈正态分布。正态分布由两个参数定义，一个是均值(通常用希腊字母\\(\\mu\\)表示，发音为”myoo”)，另一个是标准差(通常用希腊字母\\(\\sigma\\)表示，发音为”sigma”)。由于我们自己生成了数据，所以\\(\\mu\\)和\\(\\sigma\\)都是已知的，在调用rnorm()时，我们将它们分别设置为480和40。 当然，为了验证我们的假设，我们需要一个对照组，所以我们定义了一个非父母的对照组。我们用相同的方式从这个对照组生成数据，但改变了平均值。 control &lt;- rnorm(n = 50, mean = 500, sd = 40) 让我们将它们放入数据框(tibble)中，以便更容易绘制和分析数据。该数据框中的每一行表示来自特定被试的平均反应时。 dat &lt;- tibble(group = rep(c(&quot;parent&quot;, &quot;control&quot;), each = 50), rt = c(parents, control)) dat ## # A tibble: 100 × 2 ## group rt ## &lt;chr&gt; &lt;dbl&gt; ## 1 parent 475. ## 2 parent 502. ## 3 parent 494. ## 4 parent 494. ## 5 parent 516. ## 6 parent 403. ## 7 parent 490. ## 8 parent 517. ## 9 parent 481. ## 10 parent 549. ## # ℹ 90 more rows 下面是对模拟数据的一些尝试。 以某种合理的方式绘制数据。 计算平均值和标准差。它们与总体参数相比如何? 对这些数据进行t检验。群组效应显著吗? 做完这些后，再做一次，但改变样本量、总体参数或两者都改变。 参考文献 Yarkoni, T. (2019). The generalizability crisis. https://doi.org/10.31234/osf.io/jqw35 "],["相关和回归.html", "2 相关和回归 2.1 相关矩阵(Correlation matrices) 2.2 模拟二元数据 2.3 相关和回归的关系 2.4 练习", " 2 相关和回归 2.1 相关矩阵(Correlation matrices) 你可能已经通过阅读心理学论文对相关矩阵这个概念有所了解。相关矩阵是总结同一个体的多个测量值之间关系的常用方法。 假设你用多个量表测量了心理幸福感。一个问题是这些量表在多大程度上测量了相同的东西。通常，你会查看相关矩阵来探索测量之间所有成对关系。 回忆一下，相关系数量化了两个变量之间关系的强度和方向。它通常用符号\\(r\\)或\\(\\rho\\)(希腊字母”rho”)表示。相关系数的范围在-1到1之间，其中0表示没有关系，正值反映正相关(一个变量增加，另一个也增加)，负值反映负相关(一个变量增加，另一个减少)。 图2.1: 不同类型的二元关系 如果你有\\(n\\)个测量值，你可以计算多少个成对相关？你可以用下面蓝框中的公式来计算，也可以更简单地通过R中的choose(n, 2)函数直接计算。例如，要获得6个测量值之间可能的成对相关数量，你可以输入choose(6, 2)，这会告诉你有15对组合。 对于任意\\(n\\)个测量值，你可以计算\\(\\frac{n!}{2(n - 2)!}\\)个各值之间的成对相关。符号\\(!\\)称为阶乘(factorial)运算符，定义为从1到\\(n\\)所有数字的乘积。因此，如果你有6个测量值，你可以得到 \\[ \\frac{6!}{2(6-2)!} = \\frac{1 \\times 2 \\times 3 \\times 4 \\times 5 \\times 6}{2\\left(1 \\times 2 \\times 3 \\times 4\\right)} = \\frac{720}{2(24)} = 15 \\] 你可以使用R中的base::cor()或corrr::correlate()来创建相关矩阵。我们更喜欢后者函数，因为cor()要求你的数据存储在矩阵中，而我们将处理的大多数数据是存储在数据框中的表格数据。corrr::correlate()函数将数据框作为第一个参数，并提供”整洁”的输出，因此它可以更好地与tidyverse系列函数和管道操作符(%&gt;%)联动。 让我们创建一个相关矩阵来看看它是如何工作的。首先加载我们需要的包。 library(&quot;tidyverse&quot;) library(&quot;corrr&quot;) # 如缺失(missing)，在控制台(console)中输入install.packages(&quot;corrr&quot;) 我们将使用starwars数据集，这是在加载tidyverse包后可用的内置数据集。该数据集包含了出现在星球大战电影系列中的各种角色的信息。让我们来看看之间的相关性 starwars %&gt;% select(height, mass, birth_year) %&gt;% correlate() ## Correlation computed with ## • Method: &#39;pearson&#39; ## • Missing treated using: &#39;pairwise.complete.obs&#39; ## # A tibble: 3 × 4 ## term height mass birth_year ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 height NA 0.131 -0.404 ## 2 mass 0.131 NA 0.478 ## 3 birth_year -0.404 0.478 NA 你可以在任意给定的行或列的交叉处查找任何双变量相关系数。因此，height和mass之间的相关系数是.131，你可以在第1行，第2列或第2行，第1列找到它——它们是相同的。请注意，这里只有choose(3, 2) = 3个唯一的双变量关系，但每个关系在表中出现了两次。我们可能只想显示唯一的组合，这可以通过在管道中附加corrr::shave()来实现。 starwars %&gt;% select(height, mass, birth_year) %&gt;% correlate() %&gt;% shave() ## Correlation computed with ## • Method: &#39;pearson&#39; ## • Missing treated using: &#39;pairwise.complete.obs&#39; ## # A tibble: 3 × 4 ## term height mass birth_year ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 height NA NA NA ## 2 mass 0.131 NA NA ## 3 birth_year -0.404 0.478 NA 现在我们只有相关矩阵的下三角部分，但NA看起来很难看，前导0也不美观。corrr包还提供了fashion()函数，可以对其进行清理(更多选项请查阅?corrr::fashion)。 starwars %&gt;% select(height, mass, birth_year) %&gt;% correlate() %&gt;% shave() %&gt;% fashion() ## Correlation computed with ## • Method: &#39;pearson&#39; ## • Missing treated using: &#39;pairwise.complete.obs&#39; ## term height mass birth_year ## 1 height ## 2 mass .13 ## 3 birth_year -.40 .48 相关性只有在关系(大致)线性且没有严重的异常值对结果产生过大影响时才能很好地描述关系。因此，可视化相关性通常和量化它们一样是个好主意。base::pairs()函数可以实现这一点。pairs()的第一个参数形式为~ v1 + v2 + v3 + ... + vn，其中v1、v2等是你想要进行相关分析的变量名。 pairs(~ height + mass + birth_year, starwars) 图2.2: 星球大战数据集相关关系 我们会发现一个巨大的离群值影响了我们的数据。具体来说是有个体重超过1200kg的生物。让我们找出它并从数据集里面删掉它。 starwars %&gt;% filter(mass &gt; 1200) %&gt;% select(name, mass, height, birth_year) ## # A tibble: 1 × 4 ## name mass height birth_year ## &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 Jabba Desilijic Tiure 1358 175 600 好了，让我们看看没有了这个庞然大物的数据会是什么样子。 starwars2 &lt;- starwars %&gt;% filter(name != &quot;Jabba Desilijic Tiure&quot;) pairs(~height + mass + birth_year, starwars2) 图2.3: 去除体重离群值后星球大战数据集相关关系 好多了，但还有个生物的离群出生年份可能是我们不想要的。 starwars2 %&gt;% filter(birth_year &gt; 800) %&gt;% select(name, height, mass, birth_year) ## # A tibble: 1 × 4 ## name height mass birth_year ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Yoda 66 17 896 是尤达大师！他和宇宙一样古老。让我们抛开他看看图会怎么样。 starwars3 &lt;- starwars2 %&gt;% filter(name != &quot;Yoda&quot;) pairs(~height + mass + birth_year, starwars3) 图2.4: 去除体重和出生年份离群值后星球大战数据集相关关系 看起来更好了。让我们看看它是怎样改变我们的相关矩阵的。 starwars3 %&gt;% select(height, mass, birth_year) %&gt;% correlate() %&gt;% shave() %&gt;% fashion() ## Correlation computed with ## • Method: &#39;pearson&#39; ## • Missing treated using: &#39;pairwise.complete.obs&#39; ## term height mass birth_year ## 1 height ## 2 mass .73 ## 3 birth_year .44 .24 请注意，这些值与我们开始时的值有很大不同。 有时移除离群值不是一个好办法。处理离群值的另一个办法是使用一种更稳健(robust)的方法。使用corrr::correlate()默认计算的相关系数是Pearson积差相关(Pearson product-moment correlation)系数。我们也能通过改变correlate()的method()参数来计算Spearman相关系数。这将在计算相关性之前用排名替换原始值，因此仍会包括离群值，但影响将大大减小。 starwars %&gt;% select(height, mass, birth_year) %&gt;% correlate(method = &quot;spearman&quot;) %&gt;% shave() %&gt;% fashion() ## Correlation computed with ## • Method: &#39;spearman&#39; ## • Missing treated using: &#39;pairwise.complete.obs&#39; ## term height mass birth_year ## 1 height ## 2 mass .72 ## 3 birth_year .15 .15 顺便一提，如果你用R Markdown生成报告，并希望你的表格有个好看的格式，可以使用knitr:: able()。 starwars %&gt;% select(height, mass, birth_year) %&gt;% correlate(method = &quot;spearman&quot;) %&gt;% shave() %&gt;% fashion() %&gt;% knitr::kable() term height mass birth_year height mass .72 birth_year .15 .15 2.2 模拟二元数据 你已经学会了使用rnorm()函数从正态分布中模拟数据。回忆一下，rnorm()允许你指定单个变量的均值和标准差。那我们怎么模拟相关变量呢？ 应该很明确，你不能仅仅运行两次rnorm()后组合变量就完事。因为这会得到两个不相关的变量，即相关性为零。 MASS包提供mvrnorm()函数，这是rnorm的”多元”(multivariate)版(因此函数的名字是’mv’ + ‘rnorm’，这样更容易记住)。 R预装了MASS包。但MASS包中你唯一可能会用到的函数只是mvrnorm()，因此相比于使用library(\"MASS\")加载包，使用MASS::mvrnorm()是更好的办法，尤其是在MASS和tidyverse里的dplyr包不太合得来的情况下(因为两个包都有select()函数)。因此，如果在加载tidyverse之后加载MASS，那么最终得到的select()是MASS版本，而不是dplyr版本。这会让你绞尽脑汁来找出代码的问题所在，所以总在不加载的情况下使用MASS::mvrnorm()吧。 注：这里作者贴了一则他在Twitter(现X)上吐槽MASS的打油诗，不过现在已经查不到了QwQ，考虑到翻译水平不佳，附上原文！ MASS before dplyr, clashes not dire; dplyr before MASS, pain in the ass. —— Dale Barr(September 30, 2014) 请查看mvrnorm()函数的文档(在控制台输入?MASS::mvrnorm)。 有3个参数需要注意： 参数 描述 n 所需样本数 mu 一个给出变量均值的向量 Sigma 一个正定对称矩阵，用于指定变量的协方差矩阵 对n和mu的描述可以理解，但“一个正定对称矩阵(positive-definite symmetric matrix)，用于指定变量的协方差矩阵”是什么意思呢？ 当你有个多层数据时，协方差矩阵(也叫方差-协方差矩阵)反映了各个变量的方差及其相互关系。它类似于标准差的多维版本。要充分描述单变量正态分布，你只需要知道均值和标准差；要描述双变量正态分布，你需要分别知道两个变量的均值、标准差和他们的相关性；对于包含两个以上变量的多元分布，你需要知道所有变量的均值、它们的标准差以及所有可能的成对相关性。这些概念在我们开始讨论混合效应模型时会变得非常重要。 你可以将协方差矩阵看作类似于之前见过的相关矩阵；实际上，通过一些计算，你可以将协方差矩阵转换为相关矩阵。 你在说什么《黑客帝国(Matrix)》？那不是从上世纪90年代开始的科幻电影系列吗？ 在数学中，矩阵只是向量概念的推广:向量被认为只有一个维度，而矩阵可以是任意数量的维度。 那么矩阵 \\[ \\begin{pmatrix} 1 &amp; 4 &amp; 7 \\\\ 2 &amp; 5 &amp; 8 \\\\ 3 &amp; 6 &amp; 9 \\\\ \\end{pmatrix} \\] 是一个3(行) x 3(列)矩阵，包括了列向量\\(\\begin{pmatrix} 1 \\\\ 2 \\\\ 3 \\\\ \\end{pmatrix}\\)，\\(\\begin{pmatrix} 4 \\\\ 5 \\\\ 6 \\\\ \\end{pmatrix}\\)和\\(\\begin{pmatrix} 7 \\\\ 8 \\\\ 9 \\\\ \\end{pmatrix}\\)。通常我们用\\(i\\) x \\(j\\)的形式表示矩阵，\\(i\\)是行数，\\(j\\)是列数。因此，一个3x2矩阵有3行2列，像这样： \\[ \\begin{pmatrix} a &amp; d \\\\ b &amp; e \\\\ c &amp; f \\\\ \\end{pmatrix} \\] 方阵是行数等于列数的矩阵。 你可以用matrix()函数在R中创建一个方阵，或者使用base R的 cbind()和rbind()将向量连接在一起，它们分别将向量按列和按行连接在一起。在控制台试试cbina(1:3, 4:6, 7:9)吧。 那么“正定”和“对称”是什么呢？这是对可以表示多元正态分布的这类矩阵的数学要求。换句话说，你提供的协方差矩阵必须表示一个合法的多元正态分布。在这点上，你真的不需要知道再多了。 让我们从模拟假设的人类身高和体重的数据开始。我们知道这些是相关的。为了能够模拟数据，我们需要这两个变量的均值和标准差以及它们的相关性。 我找到了一些数据并把它转换为CSV文件。如果你想跟上，可以下载这个文件heights_and_weights.csv。这是散点图： handw &lt;- read_csv(&quot;data/heights_and_weights.csv&quot;, col_types = &quot;dd&quot;) ggplot(handw, aes(height_in, weight_lbs)) + geom_point(alpha = .2) + labs(x = &quot;height (inches)&quot;, y = &quot;weight (pounds)&quot;) 图2.5: 475人的身高和体重(包括婴儿) 这不是一个线性关系。我们可以先对每个变量进行对数(log)变换。 handw_log &lt;- handw %&gt;% mutate(hlog = log(height_in), wlog = log(weight_lbs)) 图2.6: 对数变换后的身高和体重 散点图右上侧尾部有一个大的点簇，这可能表示在这个样本中成年人比儿童更多，因为成年人更高和更重。 对数身高的均值是4.11 (SD = 0.26)，而对数体重的均值是4.74 (SD = 0.65)。对数身高和对数体重之间的相关性我们可以用cor()函数获得，高达0.96。 我们现在有了模拟500人身高和体重所需的所有信息。但我们如何将这些信息输入到MASS::mvrnorm()呢？我们知道函数调用的第一部分是MASS::mvrnorm(500, c(4.11,4.74), ...)，但Sigma——那个协方差矩阵呢？我们从上面知道\\(\\hat{\\sigma}_x = 0.26\\)和\\(\\hat{\\sigma}_y = 0.65\\)，以及\\(\\hat{\\sigma}_y = 0.65\\), and \\(\\hat{\\rho}_{xy} = 0.96\\)。 表示二元数据Sigma (\\(\\mathbf{\\Sigma}\\))的协方差矩阵如下： \\[ \\mathbf{\\Sigma} = \\begin{pmatrix} {\\sigma_x}^2 &amp; \\rho_{xy} \\sigma_x \\sigma_y \\\\ \\rho_{yx} \\sigma_y \\sigma_x &amp; {\\sigma_y}^2 \\\\ \\end{pmatrix} \\] 方差（标准差的平方，\\({\\sigma_x}^2\\)和\\({\\sigma_y}^2\\)）位于对角线上，协方差(相关系数乘以两个标准差，\\(\\rho_{xy} \\sigma_x \\sigma_y\\))位于非对角线上。记住协方差就是相关系数与两个标准差的积，这是很有用的。正如我们在上面的相关矩阵中看到的，表格中存在额外信息；也就是说，协方差同时出现在矩阵的右上角单元格和左下角单元格。 代入之前的值，协方差矩阵应该是： \\[ \\begin{pmatrix} .26^2 &amp; (.96)(.26)(.65) \\\\ (.96)(.65)(.26) &amp; .65^2 \\\\ \\end{pmatrix} = \\begin{pmatrix} .067 &amp; .162 \\\\ .162 &amp; .423 \\\\ \\end{pmatrix} \\] 很好，那么我们如何在R中形成Sigma以便我们可以将它传递给mvrnorm()函数呢？我们将使用matrix()函数，如下所示。 首先，让我们定义协方差并将其存储在变量my_cov中。 my_cov &lt;- .96 * .26 * .65 现在我们将使用matrix()来定义我们的Sigma为my_Sigma。 my_Sigma &lt;- matrix(c(.26^2, my_cov, my_cov, .65^2), ncol = 2) my_Sigma ## [,1] [,2] ## [1,] 0.06760 0.16224 ## [2,] 0.16224 0.42250 对matrix()函数感到困惑吗? 通过运行下面的代码，你可以发现matrix()是逐列填充矩阵元素，而不是逐行填充: matrix(c(\"a\", \"b\", \"c\", \"d\"), ncol = 2) 如果你想改变这种行为，将byrow参数设置为TRUE。 matrix(c(\"a\", \"b\", \"c\", \"d\"), ncol = 2, byrow = TRUE) 太好了！现在我们得到了my_Sigma，我们已经准备好使用MASS::mvrnorm()了。让我们通过创建6个模拟的人的数据来测试一下。 set.seed(62) # 为了可重复性 # 传递*命名的*向量c(height = 4.11, weight = 4.74)给mu可以在输出中得到列名 log_ht_wt &lt;- MASS::mvrnorm(6, c(height = 4.11, weight = 4.74), my_Sigma) log_ht_wt ## height weight ## [1,] 4.254209 5.282913 ## [2,] 4.257828 4.895222 ## [3,] 3.722376 3.759767 ## [4,] 4.191287 4.764229 ## [5,] 4.739967 6.185191 ## [6,] 4.058105 4.806485 那么MASS::mvrnorm()会返回一个矩阵，每个模拟的人对应一行，其中第一列表示对数身高，第二列表示对数体重。但是对数身高和对数体重对我们来说并不是很有用，所以让我们使用exp()函数来进行转换，它是log()转换的逆操作。 exp(log_ht_wt) ## height weight ## [1,] 70.40108 196.94276 ## [2,] 70.65632 133.64963 ## [3,] 41.36254 42.93844 ## [4,] 66.10779 117.24065 ## [5,] 114.43045 485.50576 ## [6,] 57.86453 122.30092 那么我们第一个模拟的人的身高是70.4英寸(大约是5’5”或者178.816 cm)，体重是196.94磅(约89.32 kg)。听起来感觉不错吧！(还是要注意，它会生成超出我们原始数据范围的观测值：我们会得到超高的人，例如第5个观测值，但至少体重/身高的关系会被保留)。 好的，让我们随机生成一群人的数据，将它们从对数转换为英寸和磅，然后将它们与我们的原始数据进行比较，看看效果如何。 ## 模拟新的人 new_humans &lt;- MASS::mvrnorm(500, c(height_in = 4.11, weight_lbs = 4.74), my_Sigma) %&gt;% exp() %&gt;% # 从对数转换回英寸和磅 as_tibble() %&gt;% # 为绘图转换为tibble格式 mutate(type = &quot;simulated&quot;) # 将他们标记为模拟(simulated) ## 合并真实和模拟的数据集，其中handw是来自heights_and_weights.csv的变量 alldata &lt;- bind_rows(handw %&gt;% mutate(type = &quot;real&quot;), new_humans) ggplot(alldata, aes(height_in, weight_lbs)) + geom_point(aes(colour = type), alpha = .1) 图2.7: 真实和模拟的人 你可以看到，我们模拟的人与正常的人非常相似，只是我们创建了一些身高和体重超出正常范围的人。 2.3 相关和回归的关系 好的，我们知道如何估计相关了，但如果我们想要根据身高来预测体重该怎么办呢？这可能听起来像一个不切实际的问题。但事实上，在使用或进行安全性取决于患者体重的药物或程序，但没时间称量患者体重时，急救医护人员可以使用这种技术，在紧急情况下迅速估算人们的体重。 回忆一下，简单回归模型的GLM是： \\[Y_i = \\beta_0 + \\beta_1 X_i + e_i.\\] 在这里，我们尝试根据他们观测到的身高(\\(X_i\\))来预测体重(\\(Y_i\\))。在这个方程里，\\(\\beta_0\\)和\\(\\beta_1\\)分别是y轴截距和斜率的参数，\\(e_i\\)是残差。传统上假设\\(e_i\\)的值来自均值为0、方差为\\(\\sigma^2\\)的正态分布；数学上的表述是\\(e_i \\sim N(0, \\sigma^2)\\)，其中\\(\\sim\\)表示“按照分布”，\\(N(0, \\sigma^2)\\)表示“均值为0、方差为\\(\\sigma^2\\)的正态分布(\\(N\\))”。 这表明如果我们有X和Y的均值估计值(分别标记为\\(\\mu_x\\)和\\(\\mu_y\\))、标准差估计值(\\(\\hat{\\sigma}_x\\)和\\(\\hat{\\sigma}_y\\))、X和Y之间相关系数的估计值(\\(\\hat{\\rho}\\))，我们就有了估计回归方程参数\\(\\beta_0\\)和\\(\\beta_1\\)所需要的所有信息。下面是具体做法。(译者注：这里的估计值是指根据样本信息来估计总体情况的估计值，是总体的估计值、样本的观测值) 首先，回归线的斜率\\(\\beta_1\\)等于相关系数\\(\\rho\\)乘以\\(Y\\)和\\(X\\)的标准差之比。 \\[\\beta_1 = \\rho \\frac{\\sigma_Y}{\\sigma_X}\\] 根据上面对数身高和对数体重的估计值，你能算出\\(\\beta_1\\)吗? b1 &lt;- .96 * (.65 / .26) b1 ## [1] 2.4 下一个要注意的点是，基于数学原理，回归线必须通过与\\(X\\)和\\(Y\\)均值对应的点，即点\\((\\mu_x, \\mu_y)\\)(你可以想象回归线根据斜率围绕该点“旋转”)。你也知道\\(\\beta_0\\)是y轴截距，即在\\(X = 0\\)处与纵轴相交的点。根据这些信息和上面的估计值，你能推断出\\(\\beta_0\\)的值吗？ 下面是你求解\\(\\beta_0\\)的推理过程。 想象一下，从\\(X = \\mu_x\\)逐步一个一个单位后退到\\(X = 0\\)。在\\(X = \\mu_x\\)处，\\(Y = 4.74\\)，每在X轴后退一个单位，\\(Y\\)将下降\\(\\beta_1 = 2.4\\)个单位。当你到0时，\\(Y\\)将从\\(\\mu_y\\)下降到\\(\\mu_y - \\mu_x \\beta_1\\)。 因此通解是：\\(\\beta_0 = \\mu_y - \\mu_x\\beta_1\\)。 因为\\(\\beta_1 = 2.4\\)、\\(\\mu_x = 4.11\\)、\\(\\mu_y = 4.74\\)，所以\\(\\beta_0 = -5.124\\)。因此，我们的回归方程是： \\[Y_i = -5.124 + 2.4X_i + e_i.\\] 为了验证我们的结果，我们先对对数转换后的数据进行回归，使用lm()函数，它采用最小二乘法(ordinary least squares regression)来估计参数。 summary(lm(wlog ~ hlog, handw_log)) ## ## Call: ## lm(formula = wlog ~ hlog, data = handw_log) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.63296 -0.09915 -0.01366 0.09285 0.65635 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -5.26977 0.13169 -40.02 &lt;2e-16 *** ## hlog 2.43304 0.03194 76.17 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.1774 on 473 degrees of freedom ## Multiple R-squared: 0.9246, Adjusted R-squared: 0.9245 ## F-statistic: 5802 on 1 and 473 DF, p-value: &lt; 2.2e-16 看起来非常接近。不完全匹配的原因仅仅是我们将估计值四舍五入到小数点后两位以方便计算。 作为另一个检查，让我们将手动计算的回归线叠加在对数转换后数据的散点图上。 ggplot(handw_log, aes(hlog, wlog)) + geom_point(alpha = .2) + labs(x = &quot;log(height)&quot;, y = &quot;log(weight)&quot;) + geom_abline(intercept = -5.124, slope = 2.4, colour = &#39;blue&#39;) 图2.8: 对数值和叠加的回归线 看起来是对的。 最后，以下是相关性和回归之间关系的一些影响： 当\\(\\beta_1 = 0\\)时，与\\(\\rho = 0\\)相同。 当\\(\\beta_1 &gt; 0\\)时， \\(\\rho &gt; 0\\)，因为标准差不能为负。 当\\(\\beta_1 &lt; 0\\)时， \\(\\rho &lt; 0\\)，原因同上。 拒绝零假设\\(\\beta_1 = 0\\)与拒绝零假设\\(\\rho = 0\\)是相同的。在lm()中得到的\\(\\beta_1\\)的p值与使用cor.test()得到的\\(\\rho\\)的p值相同。 2.4 练习 "],["多元回归.html", "3 多元回归 3.1 一个例子：如何在统计学上取得好成绩 3.2 处理分类预测变量 3.3 多元回归和单因素方差分析(one-way ANOVA)的等价性 3.4 练习答案", " 3 多元回归 单层数据包含\\(m\\)个预测变量的一般模型是： \\[ Y_i = \\beta_0 + \\beta_1 X_{1i} + \\beta_2 X_{2i} + \\ldots + \\beta_m X_{mi} + e_i \\] 其中\\(e_i \\sim \\mathcal{N}\\left(0, \\sigma^2\\right)\\)，换句话说，我们假设误差来自一个均值为0，方差为\\(\\sigma^2\\)的正态分布。 注意，这里的关键假设不是响应变量(\\(Y\\))服从正态分布，也不是单个预测变量(\\(X\\))服从正态分布；而是仅模型残差服从正态分布(详细讨论见这篇博客)。单个\\(X\\)预测变量可以是任意组合的连续变量和/或分类变量，包括变量之间的交互。这个特定模型背后的进一步假设是，关系是”平面的”(可以用一个平面描述，类似于简单回归中的线性假设)，且误差方差与预测变量无关。 \\(\\beta\\)的值被称为回归系数(regression coefficient)。每个\\(\\beta_h\\)被解释为在保持其他所有预测变量不变的情况下\\(\\beta_h\\)的偏效应(partial effect)。如果你有\\(m\\)个预测变量，你将有\\(m+1\\)个回归系数：一个用于截距，每个预测变量各一个 尽管在统计教科书中对多元回归的讨论很常见，但你很少有机会应用到上述的精确模型。因为上述模型假设的是单层数据，而大多数心理学数据是多层的。然而，这两种数据集的基本原理是相同的，因此先学习比较简单的案例是值得的。 3.1 一个例子：如何在统计学上取得好成绩 让我们来看一些(虚构但基于现实的)数据，看看我们如何使用多元回归来回答各种研究问题。在这个假设的研究中，你有一个包含100名统计学学生的数据集，其中包括他们的最终课程成绩(grade)、每个学生参加讲座的次数(lecture，一个范围为0-10的整数)、每个学生点击下载在线资料的次数(nclicks)以及每个学生在修这门课程之前的平均绩点(GPA)，其范围从0(不及格)到4(最高可能成绩)。 3.1.1 数据导入和可视化 让我们加载数据grades.csv并看一看。 library(&quot;corrr&quot;) # 相关矩阵 library(&quot;tidyverse&quot;) grades &lt;- read_csv(&quot;data/grades.csv&quot;, col_types = &quot;ddii&quot;) grades ## # A tibble: 100 × 4 ## grade GPA lecture nclicks ## &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 2.40 1.13 6 88 ## 2 3.67 0.971 6 96 ## 3 2.85 3.34 6 123 ## 4 1.36 2.76 9 99 ## 5 2.31 1.02 4 66 ## 6 2.58 0.841 8 99 ## 7 2.69 4 5 86 ## 8 3.05 2.29 7 118 ## 9 3.21 3.39 9 98 ## 10 2.24 3.27 10 115 ## # ℹ 90 more rows 首先，让我们看一看所有的两两相关。 grades %&gt;% correlate() %&gt;% shave() %&gt;% fashion() ## Correlation computed with ## • Method: &#39;pearson&#39; ## • Missing treated using: &#39;pairwise.complete.obs&#39; ## term grade GPA lecture nclicks ## 1 grade ## 2 GPA .25 ## 3 lecture .24 .44 ## 4 nclicks .16 .30 .36 pairs(grades) 图2.2: grades数据集中的所有成对关系 3.1.2 估计和解释 我们将使用lm()函数来估计回归系数(\\(\\beta\\)s)。针对一个有\\(m\\)个预测变量的GLM： \\[ Y_i = \\beta_0 + \\beta_1 X_{1i} + \\beta_2 X_{2i} + \\ldots + \\beta_m X_{mi} + e_i \\] 对base R的lm()调用如下： lm(Y ~ X1 + X2 + ... + Xm, data) 变量Y是你的响应变量，变量X是预测变量。注意，你不需要明确指定截距或残差项;这些是默认包含的。 对于当前数据，让我们通过lecture和nclicks来预测grade。 my_model &lt;- lm(grade ~ lecture + nclicks, grades) summary(my_model) ## ## Call: ## lm(formula = grade ~ lecture + nclicks, data = grades) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.21653 -0.40603 0.02267 0.60720 1.38558 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.462037 0.571124 2.560 0.0120 * ## lecture 0.091501 0.045766 1.999 0.0484 * ## nclicks 0.005052 0.006051 0.835 0.4058 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.8692 on 97 degrees of freedom ## Multiple R-squared: 0.06543, Adjusted R-squared: 0.04616 ## F-statistic: 3.395 on 2 and 97 DF, p-value: 0.03756 我们通常会在参数符号的顶部加上一个帽子(hat)，以明确我们正在处理样本的估计值，而不是(未知的)真实总体值。由上可知: \\(\\hat{\\beta}_0\\) = 1.46 \\(\\hat{\\beta}_1\\) = 0.09 \\(\\hat{\\beta}_2\\) = 0.01 这告诉我们，一个人的预期成绩与他们的参加讲座的次数和点击下载在线资料的次数通过以下公式相关联： grade = 1.46 + 0.09 \\(\\times\\) lecture + 0.01 \\(\\times\\) nclicks 因为\\(\\hat{\\beta}_1\\)和\\(\\hat{\\beta}_2\\)都是正数，所以我们知道lecture和nclicks的值越高，成绩越好。 因此，如果有人问你，你预测一个参加了3次讲座并下载了70次的学生成绩是多少，你可以通过代入相应的值轻松算出来。 grade = 1.46 + 0.09 \\(\\times\\) 3 + 0.01 \\(\\times\\) 70 相当于： grade = 1.46 + 0.27 + 0.7 可化简为： grade = 2.43 3.1.3 使用predict()通过线性模型进行预测 如果我们想通过新的预测变量值来预测响应变量值，我们可以使用base R 的predict()函数。 predict()函数有两个主要参数。第一个参数是拟合的模型对象(即上面的my_model)，第二个参数是包含预测变量新值的数据框(或tibble，R中和数据框data frame类似的一种数据格式)。 在新表中，你需要包含所有的预测变量。如果您的tibble缺少任何预测变量，你将收到错误消息(error message)。您还需要确保新表中的变量名与模型中的变量名完全匹配。 让我们创建一个带有新值的tibble并进行测试。 ## “tribble”是一种按行而不是按列创建tibble的方法。有时这样做会很有用。 new_data &lt;- tribble(~lecture, ~nclicks, 3, 70, 10, 130, 0, 20, 5, 100) tribble()函数提供了一种按行而不是按列逐步构建tibble的方法，而使用tibble()函数则是按列逐步构建表格。 tribble()的第一行包含列名，每个列名前面都有一个波浪号(~)。 有时这种方法比逐行构建更容易阅读，尽管结果是相同的。考虑到这些，我们也可以使用以下方式创建上述表格： new_data &lt;- tibble(lecture = c(3, 10, 0, 5), nclicks = c(70, 130, 20, 100)) 现在我们已经创建了表new_data，只需将其传递给predict()函数，这会返回一个关于\\(Y\\)(grade)预测值的向量。 predict(my_model, new_data) ## 1 2 3 4 ## 2.090214 3.033869 1.563087 2.424790 这很好，但也许我们希望将预测值和预测变量对应起来。我们可以通过将预测值作为新列添加到new_data中来实现这一点。 new_data %&gt;% mutate(predicted_grade = predict(my_model, new_data)) ## # A tibble: 4 × 3 ## lecture nclicks predicted_grade ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 3 70 2.09 ## 2 10 130 3.03 ## 3 0 20 1.56 ## 4 5 100 2.42 想查看predict()的更多操作吗？使用?predict.lm来获得帮助。 3.1.4 偏效应可视化 如上所述，每个回归系数的参数估计值告诉我们该变量的偏效应；即保持其他所有变量不变时它的效应。有办法可视化这个偏效应吗？是的，你可以使用predict()函数来实现，通过创建一个表，其中焦点预测变量(focal predictor)的值是多样的，其他所有预测变量用均值填充。 例如，我们要可视化lecture对grade的偏效应，同时将nclicks的值保持在其均值不变。 nclicks_mean &lt;- grades %&gt;% pull(nclicks) %&gt;% mean() ## 预测用的新数据 new_lecture &lt;- tibble(lecture = 0:10, nclicks = nclicks_mean) ## 将预测值添加到new_lecture new_lecture2 &lt;- new_lecture %&gt;% mutate(grade = predict(my_model, new_lecture)) new_lecture2 ## # A tibble: 11 × 3 ## lecture nclicks grade ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0 98.3 1.96 ## 2 1 98.3 2.05 ## 3 2 98.3 2.14 ## 4 3 98.3 2.23 ## 5 4 98.3 2.32 ## 6 5 98.3 2.42 ## 7 6 98.3 2.51 ## 8 7 98.3 2.60 ## 9 8 98.3 2.69 ## 10 9 98.3 2.78 ## 11 10 98.3 2.87 现在让我们作图。 ggplot(grades, aes(lecture, grade)) + geom_point() + geom_line(data = new_lecture2) 图3.1: nclicks固定在均值，lecture对成绩的偏效应 偏效应图只有在模型中焦点预测变量与其他预测变量之间没有交互效应时才有意义。 原因是当存在交互效应时，焦点预测变量\\(X_i\\)的偏效应会随着与其交互的变量的变动而变动。 现在你能可视化nclicks对grade的偏效应吗? 本页最后给出解决方法。 3.1.5 标准化系数 我们经常用多元回归来解决的一类问题是，哪个预测变量对预测Y最重要？ 现在，你不能简单地读取\\(\\hat{\\beta}\\)值并选择绝对值最大的一个，因为这些预测变量都在不同的尺度上。为了回答这个问题，你需要对预测变量进行中心化(center)和比例化(scale)。 还记得\\(z\\)分数吗？ \\[ z = \\frac{X - \\mu_x}{\\sigma_x} \\] \\(z\\)分数(\\(z\\)-score)表示\\(X\\)与样本均值(\\(\\mu_x\\))之间的标准差单位距离(\\(\\sigma_x\\))。因此，\\(z\\)分数为1意味着该值高于均值1个标准差；\\(z\\)分数为-2.5意味着低于均值2.5个标准差。\\(Z\\)分数通过将它们校准为标准正态分布(均值为0，标准差为1的分布)给了我们一种比较来自不同总体的事物的办法。 那么我们通过将预测变量转换为\\(z\\)分数来重新缩放它们。这是相当容易做到的。 grades2 &lt;- grades %&gt;% mutate(lecture_c = (lecture - mean(lecture)) / sd(lecture), nclicks_c = (nclicks - mean(nclicks)) / sd(nclicks)) grades2 ## # A tibble: 100 × 6 ## grade GPA lecture nclicks lecture_c nclicks_c ## &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2.40 1.13 6 88 -0.484 -0.666 ## 2 3.67 0.971 6 96 -0.484 -0.150 ## 3 2.85 3.34 6 123 -0.484 1.59 ## 4 1.36 2.76 9 99 0.982 0.0439 ## 5 2.31 1.02 4 66 -1.46 -2.09 ## 6 2.58 0.841 8 99 0.493 0.0439 ## 7 2.69 4 5 86 -0.972 -0.796 ## 8 3.05 2.29 7 118 0.00488 1.27 ## 9 3.21 3.39 9 98 0.982 -0.0207 ## 10 2.24 3.27 10 115 1.47 1.08 ## # ℹ 90 more rows 现在让我们用居中和缩放后的预测变量重新拟合模型。 my_model_scaled &lt;- lm(grade ~ lecture_c + nclicks_c, grades2) summary(my_model_scaled) ## ## Call: ## lm(formula = grade ~ lecture_c + nclicks_c, data = grades2) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.21653 -0.40603 0.02267 0.60720 1.38558 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.59839 0.08692 29.895 &lt;2e-16 *** ## lecture_c 0.18734 0.09370 1.999 0.0484 * ## nclicks_c 0.07823 0.09370 0.835 0.4058 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.8692 on 97 degrees of freedom ## Multiple R-squared: 0.06543, Adjusted R-squared: 0.04616 ## F-statistic: 3.395 on 2 and 97 DF, p-value: 0.03756 这告诉我们lecture_c的影响相对更大，该变量每个标准差的提高，grade相应地提高0.19。 另一种常见的标准化方法是同时对响应变量和预测变量进行标准化，即对\\(Y\\)值和\\(X\\)值都进行\\(z\\)分数转换。采用这种方法时，回归系数的相对(影响力)排序将保持不变。主要区别在于，系数将反映响应变量以标准差(\\(SD\\))为单位的变化，而不是原始单位。 多重共线性(multicollinearity)及其不足 在关于多元回归的讨论中，你可能会听到对”多重共线性”的担忧，这是指预测变量之间存在交互关系的一种高级说法。这只是一个潜在的问题，因为它可能会影响对单个预测变量效应的解释。当预测变量相关时，\\(\\beta\\)值可能会根据模型中包含或排除的预测变量而变化，有时甚至会改变符号。关于这一点需要记住的关键是： 观察性研究(observational studies)中预测变量之间相关是不可避免的； 回归不假设你的预测变量彼此独立(换句话说，在预测变量之间找到相关性本身并不是质疑模型的理由)； 当存在强相关时，解释单个回归系数时要谨慎； 目前没有已知的”补救措施”，也不清楚是否需要任何此类补救措施，许多所谓的补救措施弊大于利。 更多信息和指导请查阅(Vanhove, 2021)。 3.1.6 模型比较 另一种使用多元回归模型解决的常见问题是：某个预测变量或一组预测变量在超出某些控制变量的影响之外，对我的响应变量有显著影响吗？ 举个例子，上述包含lecture和nclicks的模型在统计上是显著的， \\(F(2,97) = 3.395, p =0.038\\)。 \\(m\\)个预测因子的回归模型的原假设(null hypothesis)为： \\[H_0: \\beta_1 = \\beta_2 = \\ldots = \\beta_m = 0;\\] 换句话说，所有的系数(除了截距)都是0。如果原假设成立，那么原模型(null model) \\[Y_i = \\beta_0\\] 与包含所有预测变量及其系数的模型一样能给出很好的预测。换句话说，你对\\(Y\\)的最佳预测只是它的均值(\\(\\mu_y\\))；\\(X\\)变量是无关紧要的。我们拒绝了这个原假设，意味着通过纳入我们的两个预测变量lecture和nclicks，可以做得更好。 但你可能会问：也许是成绩更好的学生获得了更好的成绩，而lecture、nclicks和grade之间的关系仅仅是通过学生质量的中介来实现。毕竟，成绩更好的学生更有可能去听讲座并下载材料。因此，我们可以问，出勤率和下载次数是否在超出学生能力(通过GPA测量)之外与更好的成绩相关？ 我们可以通过模型比较来检验这一假设。逻辑是这样的：首先，估计一个包含所有控制预测变量但不包含焦点预测变量的模型。其次，估计一个包含控制预测变量和焦点预测变量的模型。最后，比较这两个模型，看看包含预测因子是否有统计学上显著的增益。 下面展示你如何做到这一点： m1 &lt;- lm(grade ~ GPA, grades) # control model m2 &lt;- lm(grade ~ GPA + lecture + nclicks, grades) # bigger model anova(m1, m2) ## Analysis of Variance Table ## ## Model 1: grade ~ GPA ## Model 2: grade ~ GPA + lecture + nclicks ## Res.Df RSS Df Sum of Sq F Pr(&gt;F) ## 1 98 73.528 ## 2 96 71.578 2 1.9499 1.3076 0.2752 原假设是我们仅通过GPA预测grade与通过GPA加上lecture和nclicks预测grade一样准确。如果添加这两个变量能够显著减少残差平方和(RSS)，即它们能解释足够多的残差方差，我们就会拒绝这个原假设。 我们看到情况并非如此：\\(F(2,96) = 1.308\\), \\(p =0.275\\)。因此，我们没有证据表明课堂出勤率和下载在线材料在通过GPA衡量的学生能力之外与更好的成绩相关。 3.2 处理分类预测变量 回归公式将响应变量描述为加权预测变量的总和。但如果其中一个预测变量是分类变量(如代表”农村”或”城市”等群组)，而不是数值型变量会怎样呢？许多变量是名义(nominal)变量：包含名称的分类变量，在变量的级别之间没有固有的顺序。例如，宠物所有权(猫、狗、雪貂)是一个名义变量；不考虑喜好，拥有猫不等于拥有狗，拥有狗不等于拥有雪貂。 使用数值型预测变量表示名义数据 在回归模型中表示一个\\(k\\)水平的名义变量需要\\(k-1\\)个数值型预测变量；例如，如果有4水平，你需要3个预测变量。大多数编码方案要求你在\\(k\\)个水平中选择一个作为基线水平。\\(k-1\\)个变量中，每个变量都是其表示的水平与基线水平对比。 举例：你有一个三水平变量pet_type(猫、狗、雪貂)。 你选择猫为基线并创建两个数值型预测变量： dog_v_cat用来编码狗和猫之间的对比； ferret_v_cat用来编码雪貂和猫之间的对比。 名义变量通常在数据框中表示character或factor类型。 字符(character)变量和因子(factor)变量的区别在于因子包含关于水平及其顺序的信息，而字符向量则缺乏此信息。 当你使用R公式语法(R formula syntax)指定模型时，R会检查公式右侧预测变量的数据类型。例如，如果你的模型将income回归到pet_type上(income ~ pet_type)，R会检查pet_type的数据类型。 对于所有类型为字符或因子的变量，R都会隐式地(implicitly)创建一个(或一组)数值型预测变量来表示该变量在模型中的作用。有多种方案可用于创建名义变量的数值表示。R中的默认方法是使用虚拟(dummy，或叫处理(treatment))编码(见下文)。不幸的是，这种默认方法(注：不是指虚拟编码，而是指R自动建立虚拟编码)不适合心理学中的许多研究设计，因此我建议你学习如何“手动”编码你的预测变量，并养成这样做的习惯。 不要用数字表示分类变量的水平！ 上述例子中，我们有一个名为pet_type的变量，其水平为cat、dog和ferret。有时人们用数字表示名义变量的水平，像这样： 1表示猫， 2表示狗， 3表示雪貂。 这是个坏主意。 首先，这样的标记是任意且不透明的，任何试图使用你数据的人都不知道哪个数字对应哪个类别(你自己也可能会忘记！)。 更糟糕的是，如果你把这个变量作为回归模型中的预测变量引入，R将无法知道你使用1、2和3作为变量内各水平标签的意图，而是会假设pet_type是一个测量值，其中狗比猫大1个单位，雪貂比猫大2个单位，比狗大1个单位，这完全是无意义的！ 这种错误太容易犯了，而且如果作者不分享他们的数据和代码，这很难发现。2016年，《Current Biology》发表的一篇关于儿童宗教信仰和利他行为的论文就因为这种错误而被撤稿。 所以，不要用数字来表示名义变量的各个水平，除非你是有意创建预测变量来编码代表名义变量的\\(k-1\\)对比项，以便在回归模型中正确表示名义变量。 3.2.1 虚拟编码(又称“处理”编码) 对于只有两个水平的名义变量，选择一个水平作为基线，并创建一个新变量，当名义变量是基线时，该新变量为0，非基线时为1。基线的选择是任意的，只会影响系数是正还是负，但不会影响大小、标准误或相关的p值。 为了说明这点，让我们生成一些只包含一个两水平分类预测变量的假数据。 fake_data &lt;- tibble(Y = rnorm(10), group = rep(c(&quot;A&quot;, &quot;B&quot;), each = 5)) fake_data ## # A tibble: 10 × 2 ## Y group ## &lt;dbl&gt; &lt;chr&gt; ## 1 -0.0879 A ## 2 -1.69 A ## 3 1.19 A ## 4 -1.12 A ## 5 -0.658 A ## 6 0.383 B ## 7 -0.742 B ## 8 1.98 B ## 9 0.954 B ## 10 -1.18 B 现在让我们来添加一个新变量group_d，这是经过虚拟编码的分组变量。我们将使用dplyr::if_else()函数来定义新列。 fake_data2 &lt;- fake_data %&gt;% mutate(group_d = if_else(group == &quot;B&quot;, 1, 0)) fake_data2 ## # A tibble: 10 × 3 ## Y group group_d ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 -0.0879 A 0 ## 2 -1.69 A 0 ## 3 1.19 A 0 ## 4 -1.12 A 0 ## 5 -0.658 A 0 ## 6 0.383 B 1 ## 7 -0.742 B 1 ## 8 1.98 B 1 ## 9 0.954 B 1 ## 10 -1.18 B 1 现在我们把它作为常规的回归模型来运行。 summary(lm(Y ~ group_d, fake_data2)) ## ## Call: ## lm(formula = Y ~ group_d, data = fake_data2) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.45894 -0.92797 -0.04096 0.60197 1.70407 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.4739 0.5333 -0.889 0.400 ## group_d 0.7539 0.7542 1.000 0.347 ## ## Residual standard error: 1.192 on 8 degrees of freedom ## Multiple R-squared: 0.111, Adjusted R-squared: -8.15e-05 ## F-statistic: 0.9993 on 1 and 8 DF, p-value: 0.3468 让我们反转编码。我们得到相同的结果，只是符号不同。 fake_data3 &lt;- fake_data %&gt;% mutate(group_d = if_else(group == &quot;A&quot;, 1, 0)) summary(lm(Y ~ group_d, fake_data3)) ## ## Call: ## lm(formula = Y ~ group_d, data = fake_data3) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.45894 -0.92797 -0.04096 0.60197 1.70407 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.2800 0.5333 0.525 0.614 ## group_d -0.7539 0.7542 -1.000 0.347 ## ## Residual standard error: 1.192 on 8 degrees of freedom ## Multiple R-squared: 0.111, Adjusted R-squared: -8.15e-05 ## F-statistic: 0.9993 on 1 and 8 DF, p-value: 0.3468 截距的解释是编码为0的组的估计均值。你可以通过将0代入到下面的预测公式中的X看到这一点。因此，\\(\\beta_1\\)可以解释为基线组和编码为1的组之间的均值差异。 \\[\\hat{Y_i} = \\hat{\\beta}_0 + \\hat{\\beta}_1 X_i \\] 请注意，如果我们只是将字符变量group作为模型的预测变量，R将根据需要自动为我们创建虚拟变量。 lm(Y ~ group, fake_data) %&gt;% summary() ## ## Call: ## lm(formula = Y ~ group, data = fake_data) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.45894 -0.92797 -0.04096 0.60197 1.70407 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.4739 0.5333 -0.889 0.400 ## groupB 0.7539 0.7542 1.000 0.347 ## ## Residual standard error: 1.192 on 8 degrees of freedom ## Multiple R-squared: 0.111, Adjusted R-squared: -8.15e-05 ## F-statistic: 0.9993 on 1 and 8 DF, p-value: 0.3468 lm()函数检查group并确定变量不同的水平——在这种情况下是A和B。然后，它选择按字母顺序排在最前面的水平作为基线(注：中文一样是字母顺序)，并编码另一个水平(B)与基线水平(A)之间的对比。(如果group被定义为因子，基线水平就是levels(fake_data$group)的第一个元素)。 它创建的新变量以groupB的名称出现在输出中。 3.2.2 当\\(k &gt; 2\\)时的虚拟编码 当名义预测变量超过两水平(\\(k &gt; 2\\))时，一个数值预测变量就不够用了，我们需要\\(k-1\\)个预测变量。如果名义预测变量有4水平，我们将需要定义3个预测变量。让我们模拟一些要处理的数据，season_wt表示一年四季一个人的体重(以kg为单位)。 season_wt &lt;- tibble(season = rep(c(&quot;winter&quot;, &quot;spring&quot;, &quot;summer&quot;, &quot;fall&quot;), each = 5), bodyweight_kg = c(rnorm(5, 105, 3), rnorm(5, 103, 3), rnorm(5, 101, 3), rnorm(5, 102.5, 3))) season_wt ## # A tibble: 20 × 2 ## season bodyweight_kg ## &lt;chr&gt; &lt;dbl&gt; ## 1 winter 102. ## 2 winter 101. ## 3 winter 103. ## 4 winter 104. ## 5 winter 109. ## 6 spring 104. ## 7 spring 103. ## 8 spring 106. ## 9 spring 104. ## 10 spring 100. ## 11 summer 100. ## 12 summer 97.2 ## 13 summer 102. ## 14 summer 101. ## 15 summer 99.0 ## 16 fall 99.6 ## 17 fall 98.7 ## 18 fall 110. ## 19 fall 101. ## 20 fall 106. 现在让我们添加三个预测变量来编码变量season。尝试一下，看看你是否能弄清楚了它是如何工作的。 ## 基线变量是“winter” season_wt2 &lt;- season_wt %&gt;% mutate(spring_v_winter = if_else(season == &quot;spring&quot;, 1, 0), summer_v_winter = if_else(season == &quot;summer&quot;, 1, 0), fall_v_winter = if_else(season == &quot;fall&quot;, 1, 0)) season_wt2 ## # A tibble: 20 × 5 ## season bodyweight_kg spring_v_winter summer_v_winter fall_v_winter ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 winter 102. 0 0 0 ## 2 winter 101. 0 0 0 ## 3 winter 103. 0 0 0 ## 4 winter 104. 0 0 0 ## 5 winter 109. 0 0 0 ## 6 spring 104. 1 0 0 ## 7 spring 103. 1 0 0 ## 8 spring 106. 1 0 0 ## 9 spring 104. 1 0 0 ## 10 spring 100. 1 0 0 ## 11 summer 100. 0 1 0 ## 12 summer 97.2 0 1 0 ## 13 summer 102. 0 1 0 ## 14 summer 101. 0 1 0 ## 15 summer 99.0 0 1 0 ## 16 fall 99.6 0 0 1 ## 17 fall 98.7 0 0 1 ## 18 fall 110. 0 0 1 ## 19 fall 101. 0 0 1 ## 20 fall 106. 0 0 1 提醒：始终查看你的数据 每当你写的代码可能改变数据时，都应该通过查看数据来确保代码按预期工作。这在你手动编码用于回归的名义变量时尤其重要，因为有时代码会写错，但不会引发报错。 考虑上面的代码块，我们定义了三个对比来表示名义变量season，winter是我们的基线。 如果你意外地拼错了一个水平(使用summre而不是summer)，你能注意到吗？ season_wt3 &lt;- season_wt %&gt;% mutate(spring_v_winter = if_else(season == &quot;spring&quot;, 1, 0), summer_v_winter = if_else(season == &quot;summre&quot;, 1, 0), fall_v_winter = if_else(season == &quot;fall&quot;, 1, 0)) 虽然上面的代码块可以运行，但当我们运行回归时，我们会得到令人困惑的输出，即summer_v_winter的系数是NA(不可用，not available)。 lm(bodyweight_kg ~ spring_v_winter + summer_v_winter + fall_v_winter, season_wt3) ## ## Call: ## lm(formula = bodyweight_kg ~ spring_v_winter + summer_v_winter + ## fall_v_winter, data = season_wt3) ## ## Coefficients: ## (Intercept) spring_v_winter summer_v_winter fall_v_winter ## 101.916 1.444 NA 1.296 发生了什么？让我们看看数据来找到答案。我们将使用distinct函数找出原始变量season和我们创建的三个变量的不同组合(详细信息参阅?dplyr::distinct)。 season_wt3 %&gt;% distinct(season, spring_v_winter, summer_v_winter, fall_v_winter) ## # A tibble: 4 × 4 ## season spring_v_winter summer_v_winter fall_v_winter ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 winter 0 0 0 ## 2 spring 1 0 0 ## 3 summer 0 0 0 ## 4 fall 0 0 1 由于我们的拼写错误，当season == \"summer\"时，预测变量summer_v_winter不是1；相反，它总是0。if_else()字面上意思是“如果season == \"summre\"，则将summer_v_winter设置为1，否则为0”。当然，season永远不会等于summre，因为summre是一个拼写错误。我们本可以通过使用distinct()进行上面的检查轻松发现这一点。当你创建自己的数值预测变量时，养成这样做的习惯是很重要的。 更仔细地看看R的默认情况 如果你曾经使用过像SPSS这样的指向-点击的统计软件，你可能从未学习过如何编码分类预测变量。通常，软件会识别预测变量是否为分类变量，并在后台将其重新编码为数值型预测变量。R也是如此：如果你将character或factor类型的预测变量提供给线性建模函数，它将为你创建数值型虚拟编码的预测变量，如下方代码所示。 lm(bodyweight_kg ~ season, season_wt) %&gt;% summary() ## ## Call: ## lm(formula = bodyweight_kg ~ season, data = season_wt) ## ## Residuals: ## Min 1Q Median 3Q Max ## -4.5457 -2.3306 -0.0187 1.6354 7.2122 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 103.2119 1.4457 71.393 &lt;2e-16 *** ## seasonspring 0.1481 2.0445 0.072 0.943 ## seasonsummer -3.3458 2.0445 -1.636 0.121 ## seasonwinter 0.7541 2.0445 0.369 0.717 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 3.233 on 16 degrees of freedom ## Multiple R-squared: 0.2353, Adjusted R-squared: 0.09197 ## F-statistic: 1.641 on 3 and 16 DF, p-value: 0.2194 在这里，R隐式地创建了三个虚拟变量来编码season的四个水平，分别命名为seasonspring、seasonsummer和seasonwinter。未提及的季节fall被选为基线，因为它在字母表中最早出现。这三个预测变量的值如下： seasonspring：如果是春季则为1，否则为0； seasonsummer：如果是夏季则为1，否则为0； seasonwinter：如果是冬季则为1，否则为0； 这似乎是让R为我们做的一件方便的事情，但是在按赖默认设置时可能会有潜在风险。在下一章中，当我们讨论交互效应时，我们将更多地了解这些风险。 3.3 多元回归和单因素方差分析(one-way ANOVA)的等价性 如果我们想要查看我们的体重是否随季节变化，我们可以对season_wt2进行单因素方差分析，如下所示。 ## 将季节变为一个以“winter”为基线的因子变量 season_wt3 &lt;- season_wt2 %&gt;% mutate(season = factor(season, levels = c(&quot;winter&quot;, &quot;spring&quot;, &quot;summer&quot;, &quot;fall&quot;))) my_anova &lt;- aov(bodyweight_kg ~ season, season_wt3) summary(my_anova) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## season 3 51.46 17.15 1.641 0.219 ## Residuals 16 167.20 10.45 好了，现在我们可以用下面的回归模型复制这个结果吗? \\[Y_i = \\beta_0 + \\beta_1 X_{1i} + \\beta_2 X_{2i} + \\beta_3 X_{3i} + e_i\\] summary(lm(bodyweight_kg ~ spring_v_winter + summer_v_winter + fall_v_winter, season_wt2)) ## ## Call: ## lm(formula = bodyweight_kg ~ spring_v_winter + summer_v_winter + ## fall_v_winter, data = season_wt2) ## ## Residuals: ## Min 1Q Median 3Q Max ## -4.5457 -2.3306 -0.0187 1.6354 7.2122 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 103.9661 1.4457 71.914 &lt;2e-16 *** ## spring_v_winter -0.6060 2.0445 -0.296 0.7707 ## summer_v_winter -4.0999 2.0445 -2.005 0.0621 . ## fall_v_winter -0.7541 2.0445 -0.369 0.7171 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 3.233 on 16 degrees of freedom ## Multiple R-squared: 0.2353, Adjusted R-squared: 0.09197 ## F-statistic: 1.641 on 3 and 16 DF, p-value: 0.2194 请注意，这两种方法的 \\(F\\) 值和 \\(p\\) 值是相同的! 3.4 练习答案 展开答案 首先创建一个包含新预测变量的tibble。我们可能还想知道nclicks的取值范围。 lecture_mean &lt;- grades %&gt;% pull(lecture) %&gt;% mean() min_nclicks &lt;- grades %&gt;% pull(nclicks) %&gt;% min() max_nclicks &lt;- grades %&gt;% pull(nclicks) %&gt;% max() ## 预测变量的新数据 new_nclicks &lt;- tibble(lecture = lecture_mean, nclicks = min_nclicks:max_nclicks) ## 将预测值添加到new_lecture中 new_nclicks2 &lt;- new_nclicks %&gt;% mutate(grade = predict(my_model, new_nclicks)) new_nclicks2 ## # A tibble: 76 × 3 ## lecture nclicks grade ## &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 6.99 54 2.37 ## 2 6.99 55 2.38 ## 3 6.99 56 2.38 ## 4 6.99 57 2.39 ## 5 6.99 58 2.39 ## 6 6.99 59 2.40 ## 7 6.99 60 2.40 ## 8 6.99 61 2.41 ## 9 6.99 62 2.41 ## 10 6.99 63 2.42 ## # ℹ 66 more rows 现在作图。 ggplot(grades, aes(nclicks, grade)) + geom_point() + geom_line(data = new_nclicks2) 图3.2: nclicks对grade的偏效应图 参考文献 Vanhove, J. (2021). Collinearity isn’t a disease that needs curing. Meta-Psychology, 5. "],["交互效应.html", "4 交互效应 4.1 连续变量-分类变量交互效应 4.2 分类变量-分类变量交互效应 4.3 用于因子设计的GLM 4.4 在因子设计中对分类预测因子进行编码 4.5 分类变量的编码方案", " 4 交互效应 到目前为止，我们一直专注于估计和解释一个变量或预测变量线性组合对响应变量的影响。然而，往往存在这样的情况，一个预测变量对响应变量的影响取决于另一个预测变量。实际上，我们可以在模型中包含一个交互项来估计和解释这种依赖性。 4.1 连续变量-分类变量交互效应 让我们考虑一个简单的虚构例子。假设你对声波干扰对认知表现的影响感兴趣。你的研究中的每个被试在执行一个简单的反应时任务时(尽快对闪光灯做出反应)，被随机分配接受特定水平的声波干扰。你有一种技术，可以自动生成不同水平的背景噪音（例如城市声音的频率和振幅：鸣笛声、钻地声、喧哗声、玻璃破碎声等）。每个参与者在一个随机选择的干扰水平(0到100)下执行任务。你的假设是，城市生活使人们的任务表现更不受声波干扰的影响。你想要比较城市居民和乡村居民(来自更安静的乡村环境)之间干扰与表现关系的差异。 你有3个变量： 一个连续响应变量，mean_RT，其较高的水平反映较慢的反应时； 一个连续预测变量，声波干扰水平(dist_level)，其较高的水平表示更多的干扰； 一个两水平的因子，group (城市vs.乡村)。 让我们从模拟一些城市组的数据开始。假设在0干扰(静音)下，平均反应时约为450毫秒，且干扰每增加1个单位，反应时就增加约2毫秒。这给了我们以下线性模型： \\[Y_i = 450 + 2 X_i + e_i\\] 其中\\(X_i\\)是声音干扰的水平。 让我们模拟100名被试的数据，设定\\(\\sigma = 80\\)，并在开始之前设置种子。 library(tidyverse) set.seed(1031) n_subj &lt;- 100L # 模拟100名被试的数据(注：L是说明100是整数) b0_urban &lt;- 450 # y轴截距 b1_urban &lt;- 2 # 斜率 # 分解表(decomposition table) urban &lt;- tibble( subj_id = 1:n_subj, group = &quot;urban&quot;, b0 = 450, b1 = 2, dist_level = sample(0:n_subj, n_subj, replace = TRUE), err = rnorm(n_subj, mean = 0, sd = 80), simple_rt = b0 + b1 * dist_level + err) urban ## # A tibble: 100 × 7 ## subj_id group b0 b1 dist_level err simple_rt ## &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 urban 450 2 59 -36.1 532. ## 2 2 urban 450 2 45 128. 668. ## 3 3 urban 450 2 55 23.5 584. ## 4 4 urban 450 2 8 1.04 467. ## 5 5 urban 450 2 47 48.7 593. ## 6 6 urban 450 2 96 88.2 730. ## 7 7 urban 450 2 62 110. 684. ## 8 8 urban 450 2 8 -91.6 374. ## 9 9 urban 450 2 15 -109. 371. ## 10 10 urban 450 2 70 20.7 611. ## # ℹ 90 more rows 让我们绘制创建的数据，并作出最佳拟合线。 ggplot(urban, aes(dist_level, simple_rt)) + geom_point(alpha = .2) + geom_smooth(method = &quot;lm&quot;, se = FALSE) 图4.1: 声波干扰对简单反应时的影响(城市组) 现在让我们为乡村组模拟数据。我们假设这些被试的截距可能会略高一些，可能是因为他们对技术不太熟悉。最重要的是，我们假设他们的斜率会更陡，因为他们受到噪音的影响更大。大致如下： \\[Y_i = 500 + 3 X_i + e_i\\] b0_rural &lt;- 500 b1_rural &lt;- 3 rural &lt;- tibble( subj_id = 1:n_subj + n_subj, group = &quot;rural&quot;, b0 = b0_rural, b1 = b1_rural, dist_level = sample(0:n_subj, n_subj, replace = TRUE), err = rnorm(n_subj, mean = 0, sd = 80), simple_rt = b0 + b1 * dist_level + err) 现在让我们把这两组的数据一起画出来。 all_data &lt;- bind_rows(urban, rural) ggplot(all_data %&gt;% mutate(group = fct_relevel(group, &quot;urban&quot;)), aes(dist_level, simple_rt, colour = group)) + geom_point() + geom_smooth(method = &quot;lm&quot;, se = FALSE) + facet_wrap(~ group) + theme(legend.position = &quot;none&quot;) 图4.2: 声波干扰对简单反应时的影响(城市和乡村) 这里我们可以很清楚地看到我们在数据中建立的斜率差异。我们如何测试两个斜率是否有显著不同呢？要做到这一点，我们不能做两个单独的回归。我们需要将这两条回归线纳入同一个模型中。我们应该怎么做呢？ 请注意，我们可以用”偏移(offset)“值来表示其中一条回归线。我们(任意地)选一组作为我们的”基线”组，并将另一组的y轴截距和斜率表示为相对于这个基准的偏移值。因此，如果我们选择城市组作为基线，我们可以用两个偏移值\\(\\beta_2\\)和\\(\\beta_3\\)分别表示乡村组的y轴截距和斜率偏移。 y轴截距: \\(\\beta_{0\\_rural} = \\beta_{0\\_urban} + \\beta_2\\) 斜率: \\(\\beta_{1\\_rural} = \\beta_{1\\_urban} + \\beta_3\\) 我们有城市组参数：\\(\\beta_{0\\_urban} = 450\\)和\\(\\beta_{1\\_urban} = 2\\)，乡村组参数：\\(\\beta_{0\\_rural} = 500\\)和\\(\\beta_{1\\_rural} = 3\\)。因此可以得出： \\(\\beta_2 = 50\\)，因为\\(\\beta_{0\\_rural} - \\beta_{0\\_urban} = 500 - 450 = 50\\) \\(\\beta_3 = 1\\)，因为\\(\\beta_{1\\_rural} - \\beta_{1\\_urban} = 3 - 2 = 1\\) 现在我们的两个回归模型是： \\[Y_{i\\_urban} = \\beta_{0\\_urban} + \\beta_{1\\_urban} X_i + e_i\\] 和 \\[Y_{i\\_rural} = (\\beta_{0\\_urban} + \\beta_2) + (\\beta_{1\\_urban} + \\beta_3) X_i + e_i\\] 好的，看起来我们更接近将这些模型合并为一个单一的回归模型了。这里有最后的技巧。我们定义一个额外的虚拟变量，该变量在城市组中取值为0(我们选择作为”基线”组)，在其他组中取值为1。下框包含我们的最终模型。 含有连续-分类变量交互效应的回归模型 \\[Y_{i} = \\beta_0 + \\beta_1 X_{1i} + \\beta_2 X_{2i} + \\beta_3 X_{1i} X_{2i} + e_{i}\\] 其中 \\(X_{1i}\\)是连续变量 \\(X_{2i}\\)是虚拟变量，0表示基线组，1表示其他组 参数解释： \\(\\beta_0\\): 基线组y轴截距； \\(\\beta_1\\): 基线组斜率； \\(\\beta_2\\): 其他组的y轴截距偏移量； \\(\\beta_3\\): 其他组的斜率偏移量。 用R估计： lm(Y ~ X1 + X2 + X1:X2, data)或者缩写: lm(Y ~ X1 * X2, data)。这里*的意思是：“所有可能的主效应以及X1和X2的交互” \\(\\beta_3 X_{1i} X_{2i}\\)项是两个预测变量相乘，被称为交互项(interaction term)。现在让我们展示上述广义线性模型(GLM)是如何得出两条回归线的。 为了得到城市组的回归方程，我们将0代入到\\(X_{2i}\\)中。得到公式： \\[Y_{i} = \\beta_0 + \\beta_1 X_{1i} + \\beta_2 0 + \\beta_3 X_{1i} 0 + e_i\\] 去掉等于0的项，就得到： \\[Y_{i} = \\beta_0 + \\beta_1 X_{1i} + e_i,\\] 这就是基线组(城市组)的回归方程。将其与上面的\\(Y_{i\\_urban}\\)进行对比。 将1代入到\\(X_{2i}\\)里会得到乡村组的方程。我们得到： \\[Y_{i} = \\beta_0 + \\beta_1 X_{1i} + \\beta_2 1 + \\beta_3 X_{1i} 1 + e_i\\] 化简和运用一些代数后，也能表示为： \\[Y_{i} = \\beta_0 + \\beta_2 + (\\beta_1 + \\beta_3) X_{1i} + e_i.\\] 将其和上面的\\(Y_{i\\_rural}\\)进行对比。虚拟编码起作用了！ 我们如何在R中估计回归系数？假设我们想检验两条线的斜率是否不同。注意，这实际上只是检验原假设\\(\\beta_3 = 0\\)，因为\\(\\beta_3\\)是我们的斜率偏移量。如果这个参数为0，意味着两个组具有相同的斜率(尽管它们可以有不同的截距)。换句话说，这意味着两条斜线是平行的。如果它非0，这意味着两个组具有不同的斜率，也就是说，两条斜线不平行。 样本中的平行线 vs. 总体中的平行线 我刚刚提到，两条不平行的线意味着分类预测变量和连续预测变量之间存在交互效应，而平行的线则意味着不存在交互效应。要明确的是，我所说的平行与否是指在总体(population)中的情况。在样本(sample)中的平行与否不仅取决于它们在总体中的情况，还取决于测量和抽样引入的偏差。总体中是平行的线，在样本中却极有可能出现斜率不同的线，尤其是在样本量较小的情况下。 通常，你会对总体中斜率相同与否感兴趣，而不是样本中的情况。因此，你不能仅仅看样本数据的图表就推断出”线不平行，因此存在交互效应”，或相反”线看起来平行，所以没有交互效应”。你必须进行推论统计检验。 当交互项在某个\\(\\alpha\\)水平(如0.05)上具有统计显著性时，你会拒绝交互系数为0的原假设(如\\(H_0: \\beta_3 = 0\\))，这意味着在总体中这些线不是平行的。 然而，交互项不显著并不一定意味着在总体中这些线是平行的。它们可能是平行的，但也可能不是，而你的研究只是缺乏足够的统计效力(power)来检测出差异。 为了获得关于原假设的证据，最好的方法是进行所谓的等效性检验(equivalence test)。在这个检验中你试图拒绝一个原假设，该原假设是总体效应大于某个你感兴趣的最小效应值；教程详见(Lakens et al., 2018)。 我们已经创建了结合两组模拟数据的数据集all_data。我们使用R公式语法表示模型的方式是Y ~ X1 + X2 + X1:X2，其中X1:X2告诉R创建一个预测变量，该预测变量是X1和X2的乘积。还有一个缩写方式Y ~ X1 * X2，它告诉R计算所有可能的主效应和交互效应。首先，我们将向模型添加一个虚拟预测变量，并将结果存储在all_data2中。 all_data2 &lt;- all_data %&gt;% mutate(grp = if_else(group == &quot;rural&quot;, 1, 0)) sonic_mod &lt;- lm(simple_rt ~ dist_level + grp + dist_level:grp, all_data2) summary(sonic_mod) ## ## Call: ## lm(formula = simple_rt ~ dist_level + grp + dist_level:grp, data = all_data2) ## ## Residuals: ## Min 1Q Median 3Q Max ## -261.130 -50.749 3.617 62.304 191.211 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 460.1098 15.5053 29.674 &lt; 2e-16 *** ## dist_level 1.9123 0.2620 7.299 7.07e-12 *** ## grp 4.8250 21.7184 0.222 0.824 ## dist_level:grp 1.5865 0.3809 4.166 4.65e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 81.14 on 196 degrees of freedom ## Multiple R-squared: 0.5625, Adjusted R-squared: 0.5558 ## F-statistic: 83.99 on 3 and 196 DF, p-value: &lt; 2.2e-16 练习 在下面的空格中输入你的答案，至少保留两位小数。 给定回归模型 \\[Y_{i} = \\beta_0 + \\beta_1 X_{1i} + \\beta_2 X_{2i} + \\beta_3 X_{1i} X_{2i} + e_{i}\\] (其中\\(X_{1i}\\)是连续预测变量，\\(X_{2i}\\)是分类预测变量)且上方给出了lm()的输出结果，填写以下参数的估计值。 \\(\\hat{\\beta}_0\\): \\(\\hat{\\beta}_1\\): \\(\\hat{\\beta}_2\\): \\(\\hat{\\beta}_3\\): 根据这些参数估计，(基线)城市组的回归线为: \\(Y_i =\\) \\(+\\) \\(X_{1i}\\) 乡村组的： \\(Y_i =\\) \\(+\\) \\(X_{1i}\\) 展开答案 \\(\\beta_0=\\) 460.11 \\(\\beta_1=\\) 1.91 \\(\\beta_2=\\) 4.83 \\(\\beta_3=\\) 1.59 城市组的回归线是： \\(Y_i = \\beta_0 + \\beta_1 X_{1i}\\)即 \\(Y_i =\\) 460.11 \\(+\\) 1.91 \\(X_{1i}\\) 乡村组的是： \\(Y_i = \\beta_0 + \\beta_2 + \\left(\\beta_1 + \\beta_3\\right) X_{1i}\\)即 \\(Y_i=\\) 464.93 \\(+\\) 3.5 \\(X_{1i}\\) 4.2 分类变量-分类变量交互效应 因子设计(factorial design)在心理学中很常见，通常使用基于ANOVA的技术进行分析，这可能掩盖了ANOVA与回归一样也假设了一个潜在的线性模型的事实。 因子是一种所有预测变量(自变量，IVs)都是分类变量的设计：每个都是具有固定数量水平的因子。在一个全因子设计(full-factorial design)中，因子之间完全交叉，以表示每种可能的因子组合。我们称每个唯一的组合为设计的一个单元(cell)。你经常会听到设计被称为“二乘二(two-by-two)设计”(2x2)，这意味着有2个因子，每个因子有2个水平。一个“三乘三设计”(3x3)是其中有2个因子，每个因子有3个水平的设计；一个“二乘二乘二设计”(2x2x2)是其中有3个因子，每个因子有2个水平，以此类推。 通常，因子设计都以表格形式给出，显示所有因子水平的组合。下面是一个2x2设计的表格表示。 \\(B_1\\) \\(B_2\\) \\(A_1\\) \\(AB_{11}\\) \\(AB_{12}\\) \\(A_2\\) \\(AB_{21}\\) \\(AB_{22}\\) 一个3x2设计可能如下所示。 \\(B_1\\) \\(B_2\\) \\(A_1\\) \\(AB_{11}\\) \\(AB_{12}\\) \\(A_2\\) \\(AB_{21}\\) \\(AB_{22}\\) \\(A_3\\) \\(AB_{31}\\) \\(AB_{32}\\) 最后是一个2x2x2设计. \\[C_1\\] \\(B_1\\) \\(B_2\\) \\(A_1\\) \\(ABC_{111}\\) \\(ABC_{121}\\) \\(A_2\\) \\(ABC_{211}\\) \\(ABC_{221}\\) \\[C_2\\] \\(B_1\\) \\(B_2\\) \\(A_1\\) \\(ABC_{112}\\) \\(ABC_{122}\\) \\(A_2\\) \\(ABC_{212}\\) \\(ABC_{222}\\) 不要混淆因子和水平！ 如果你听说一个研究有三个处理组(处理组A、处理组B和对照组)，这不是一个“三因子(three-factor, three-way)设计”。这是一个单因子(one-factor, one-way)设计，具有一个三水平因子(处理条件)。 不存在只有一个水平的因子。 你可以通过将每个因子的水平数相乘来确定设计中有多少个单元。因此，一个2x3x4设计将在设计中有24个单元。 4.2.1 认知治疗与药物治疗对情绪的影响 让我们考虑一个简单的因子设计，并思考我们的数据可能展示方式。在从这个具体例子中了解概念之后，我们将将其映射到更抽象的统计术语上。 想象一下，你正在进行一项研究，内容是两种不同类型的治疗(认知疗法和药物疗法)对抑郁症患者的影响。一半的被试被随机分配接受认知行为疗法(Cognitive Behavioral Therapy, CBT)，另一半接受其他控制操作(no-CBT)。此外，你通过随机分配进一步将你的患者分为两组：药物治疗组(接受抗抑郁药物, drug)和对照组(接受安慰剂, placebo)。接受治疗(或对照/安慰剂)后，你使用一个评分标准来测量他们的情绪，较高的数字对应较积极的情绪。 让我们想象一下，下面我们得到的均值是不受测量或抽样误差影响的总体均值。我们将花一点时间考虑3种不同的可能结果，以及它们暗示这些疗法如何独立或交互地影响情绪。 在分类变量-连续变量交互效应部分关于的总体和样本的提醒在这里同样适用。除非模拟数据，你几乎永远不会知道你正在研究的任何总体的真实均值。下面，我们讨论的是你实际知道总体均值并且可以在没有任何统计测试的情况下得出结论的假设情况。你观察到的任何真实样本均值都会包含抽样和测量误差，你所做的任何推断都将取决于统计检验的结果，而不是观察到的均值。 情景A 图4.3: 情景A, 单元平均值图 下面是一个单元均值(cell mean)和边际均值(marginal mean)的表格。单元均值是设计的每个单元中因变量(情绪)的平均值。边际均值(在表格的边缘)提供了每行和每列的均值。 No CBT CBT Placebo 40 60 50 Drug 60 80 70 50 70 如果这是我们的结果，你会得出什么结论？认知疗法对情绪有影响吗？药物疗法呢？对于这两个问题的答案都是肯定的：接受CBT的人平均心情(70；第2列的均值)比没有接受的人高出20(50；第1列的均值)。 同样，接受抗抑郁药物的人情绪(70；第2行均值)相对于接受安慰剂的人(50; 第1行均值)更好。 现在我们还可以问下个问题：认知疗法的效果是否取决于患者是否同时接受药物疗法？答案是否定的。看看为什么，注意到对于安慰剂组(第1行)，认知疗法使情绪提高了20分(从40提高到60)。但对于药物组来说也是一样的：从60提高到80也是20分的提高。因此，没有证据表明一个因素对心情的影响取决于另一个因素。 情景B 图4.4: 情景B, 单元平均值图 No CBT CBT Placebo 40 60 50 Drug 40 60 50 40 60 在这种情景下，我们也发现CBT改善了情绪(同样提高了20分)，但药物疗法没有效果(第1行和第2行的边际均值都是50)。我们还可以看到，CBT的效果也不依赖于药物疗法：每行都有20分的提高。 情景C 图4.5: 情景C, 单元平均值图 No CBT CBT Placebo 40 60 50 Drug 50 90 70 45 75 根据前面的逻辑，我们发现总体上接受认知疗法的人相比于对照组，情绪有所提升(75分对45分)，而接受药物疗法的人相比于安慰剂组，情绪也有所提升(70分对50分)。但这里还有其他情况：认知疗法对情绪的影响在同时接受药物疗法的患者中更明显。对于服用抗抑郁药的患者，情绪相对于对照组提高了40分(从50分到90分；表中的第2行)。对于接受安慰剂的患者，情绪只提高了20分，从40分到60分(表中的第1行)。因此，在这个假设情景中，认知疗法的效果取决于是否同时进行药物疗法。 4.2.2 因子设计中的效应 如果你理解了上一节描述的基本效应模式，那么你就准备好将这些概念映射到统计语言上了。 4.2.2.1 主效应(main effect) 主效应：在忽略设计中其他因子的情况下，一个因子对因变量的效应。 主效应的检验是对边际均值是否等价的检验。因此，在上述场景A中，当你比较药物治疗的行均值时，你是在评估该因子对情绪的主效应。原假设是这两个边际均值相等： \\[\\bar{Y}_{1..} = \\bar{Y}_{2..}\\] 其中\\(Y_{i..}\\)是不考虑列因子的情况下\\(i\\)行的平均值。 如果你有一个因子有\\(k\\)水平，且\\(k &gt; 2\\)，此时主效应的原假设是： \\[\\bar{Y}_{1..} = \\bar{Y}_{2..} = \\ldots = \\bar{Y}_{k..},\\] 即所有的行(或列)都是相等的。 4.2.2.2 简单效应(simple effect) 简单效应是指在另一个因子的特定水平上(将该因子保持在特定值)，一个因子的效应。 例如，在情景C中，我们讨论了CBT对抗抑郁药组被试的效应。在这种情况下，对于接受抗抑郁药的被试来说，CBT的简单效应是40个单位。 我们也可以讨论药物治疗对接受认知疗法的患者的简单效应。在情景C中，这体现为情绪得分从60增加到90(第2列)。 4.2.2.3 交互效应 当一个变量的效应在另一个变量的各个水平上不同的时候，我们称之为存在交互效应。 更像数学定义的表述是，当一个因子的简单效应在另一个因子的各个水平上不同时，就存在交互效应。我们在情景C中看到了这一点，CBT对抗抑郁药组的效果提升了40个单位，而对安慰剂组的效果只提升了20个单位。也许抗抑郁药带来的情绪提升使患者更容易接受CBT。 关键在于，当A的简单效应在B的各个水平上不同时，我们称A和B之间存在简单交互效应。你也可以检查B的简单效应在A上是否不同。如果其中一个陈述为真，另一个陈述也必为真，因此查看简单效应的方式并不重要。 4.2.3 高阶设计(Higher-order designs) 双因子设计(也称为“two-way”)在心理学和神经科学中非常常见，但有时你也会遇到超过两个因子的设计，比如2x2x2设计。 为了计算不同类型效应的数量，我们使用下面的公式，这个公式给出了从\\(n\\)个元素中取\\(k\\)个元素的可能组合数： \\[\\frac{n!}{k!(n - k)!}\\] 相比于实际上的手算，我们可以在R中使用choose(n, k)函数。 对于有\\(n\\)个因子的设计，你会有： \\(n\\)个主效应； \\(\\frac{n!}{2!(n - 2)!}\\)个2因素交互效应； \\(\\frac{n!}{3!(n - 3)!}\\)个3因素交互效应； \\(\\frac{n!}{4!(n - 4)!}\\)个4因素交互效应…以此类推。 因此，如果我们有一个3因子设计，如一个2x2x2设计，其中包含因子\\(A\\)，\\(B\\)和\\(C\\)，我们将有3个主效应：\\(A\\)，\\(B\\)和\\(C\\)；choose(3, 2) = 3个2因素交互效应：\\(AB\\)，\\(AC\\)和\\(BC\\)，以及choose(3, 3) = 1个3因素交互效应：\\(ABC\\)。 3因素交互效应很难解释，但它们意味着任意两个给定因子之间的简单交互效应会随着第3个因子的水平变化而不同。例如，它可能意味着\\(C_1\\)处的\\(AB\\)交互效应与\\(C_2\\)处的\\(AB\\)交互效应不同。 如果你有一个4因子设计，你将会有四个主效应，choose(4, 2) = 6个2因素交互效应，choose(4, 3) = 4个3因素交互效应，以及1个4因素交互效应。从4因子设计中解释结果几乎是不可能的，所以请保持你的设计简单！ 常见错误 比较简单效应的显著性不等于检验简单效应是否有显著差异。 4.3 用于因子设计的GLM 现在让我们看一下这些模型背后的数学。通常情况下，你会看到为2x2因子设计编写的方差分析(ANOVA)的GLM使用“ANOVA”符号，如下所示： \\[Y_{ijk} = \\mu + A_i + B_j + AB_{ij} + S(AB)_{ijk}.\\] 在上方公式中： \\(Y_{ijk}\\)表示在因子\\(A\\)的第\\(i\\)个水平和因子\\(B\\)的第\\(j\\)个水平中观测到的\\(k\\)的值； \\(\\mu\\)表示总体均值； \\(A_i\\)表示因子\\(A\\)在\\(A\\)的第\\(i\\)个水平上的主效应； \\(B_j\\)表示因子\\(B\\)在\\(B\\)的第\\(j\\)个水平上的主效应； \\(AB_{ij}\\)表示在\\(A\\)的第\\(i\\)个水平和\\(B\\)的第\\(j\\)个水平处的\\(AB\\)交互效应； \\(S(AB)_{ijk}\\)表示残差。 一个重要的数学事实是，各个主效应和交互效应的总和为零，通常写成： \\(\\Sigma_i A_i = 0\\); \\(\\Sigma_j B_j = 0\\); \\(\\Sigma_{ij} AB_{ij} = 0\\)。 理解这些效应的最好方法是查看分解表。研究下面的分解表，该表包含了从具有因子\\(A\\)和\\(B\\)的2x2设计中获取的12个模拟观测值。提供了索引\\(i\\)、\\(j\\)和\\(k\\)，只是为了帮助你跟踪正在处理的观测值。请记住，\\(i\\)表示因子\\(A\\)的水平，\\(j\\)表示因子\\(B\\)的水平，\\(k\\)表示单元\\(AB_{ij}\\)内的观测值编号。 ## # A tibble: 12 × 9 ## Y i j k mu A_i B_j AB_ij err ## &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 11 1 1 1 10 4 -2 -1 0 ## 2 14 1 1 2 10 4 -2 -1 3 ## 3 8 1 1 3 10 4 -2 -1 -3 ## 4 17 1 2 1 10 4 2 1 0 ## 5 15 1 2 2 10 4 2 1 -2 ## 6 19 1 2 3 10 4 2 1 2 ## 7 8 2 1 1 10 -4 -2 1 3 ## 8 4 2 1 2 10 -4 -2 1 -1 ## 9 3 2 1 3 10 -4 -2 1 -2 ## 10 10 2 2 1 10 -4 2 -1 3 ## 11 7 2 2 2 10 -4 2 -1 0 ## 12 4 2 2 3 10 -4 2 -1 -3 4.3.1 估计方程(estimation equations) 这些是你在ANOVA中用来估计效应的方程。 \\(\\hat{\\mu} = Y_{...}\\) \\(\\hat{A}_i = Y_{i..} - \\hat{\\mu}\\) \\(\\hat{B}_j = Y_{.j.} - \\hat{\\mu}\\) \\(\\widehat{AB}_{ij} = Y_{ij.} - \\hat{\\mu} - \\hat{A}_i - \\hat{B}_j\\) 注意，带有下标点的\\(Y\\)变量是\\(Y\\)的均值，忽略了下标中的任何内容。因此，\\(Y_{...}\\)是\\(Y\\)的均值，\\(Y_{i..}\\)是\\(Y\\)在\\(A\\)的第\\(i\\)个水平上的均值，\\(Y_{.j.}\\)是\\(Y\\)在\\(B\\)的第\\(j\\)个水平上的均值，\\(Y_{ij.}\\)是\\(Y\\)在\\(A\\)的第\\(i\\)个水平和\\(B\\)的第\\(j\\)个水平上的均值，即单元均值\\(ij\\)。 4.3.2 因子设计App 启动这个网页APP，尝试因子设计，直到你理解因子设计中主效应和交互效应的关键概念。 4.4 在因子设计中对分类预测因子进行编码 心理学研究(尤其是实验心理学)经常涉及分类自变量。分析这些研究的数据时，需要仔细指定预测变量，因为R中的默认设置对实验情景而言并不理想。主要问题是分类预测变量的默认编码在输出中给出的是简单效应而非主效应，但后者通常是你所需要的。人们有时没有意识到这一点，误读了他们的输出结果。研究人员有时会报告含有分类预测变量的回归结果，但未明确报告他们是如何编码这些变量的，这使得他们的研究结果难以解读和再现。为了确保可重复性、透明度和准确解释，学习如何“手动”编码分类预测变量并在报告中习惯性地报告这些编码是一个好主意。 由于R的默认设置不适合因子设计，我建议在将分类变量作为线性模型中的预测变量时，应该总是手动编码分类变量。不要将它们包括为factor变量。 4.5 分类变量的编码方案 许多实验研究者在尝试从方差分析(ANOVA)转向使用R进行线性混合模型(linear mixed-effects models，LMEMs)时，都会在编码分类预测变量时遇到困难。这比预期的要复杂得多，而R提供的默认设置对于因子实验来说完全不合适。实际上，在因子实验中使用这些默认设置可能会导致研究人员从数据中得出错误的结论。 为了简化问题，我们将从设计因子不超过两水平的情况开始，然后再讨论具有三个以上水平的设计。 4.5.1 简单效应 vs. 主效应 理解简单效应(simple effect)和主效应(main effect)以及简单交互效应(simple interaction)和主交互效应(main interaction)在三因素设计中的区别是非常重要的。 在\\(A{\\times}B\\)设计中，\\(A\\)的简单效应是控制\\(B\\)后的\\(A\\)的效应，而\\(A\\)的主效应是忽略\\(B\\)后\\(A\\)的效应。另一种看待这个问题的方法是考虑因子设计中的单元均值(\\(\\bar{Y}_{11}\\)，\\(\\bar{Y}_{12}\\)，\\(\\bar{Y}_{21}\\)和\\(\\bar{Y}_{22}\\))以及边际均值(\\(\\bar{Y}_{1.}\\)，\\(\\bar{Y}_{2.}\\)，\\(\\bar{Y}_{.1}\\)和\\(\\bar{Y}_{.2}\\))。(下标的点告诉你“忽略”该点的维度；例如：\\(\\bar{Y}_{.1}\\)告诉你忽略行变量取第1列的均值)。测试\\(A\\)的主效应是测试原假设\\(\\bar{Y}_{1.}=\\bar{Y}_{2.}\\)。测试\\(A\\)的简单效应，即在\\(B\\)的特定水平上\\(A\\)的效应，例如，测试原假设\\(\\bar{Y}_{11}=\\bar{Y}_{21}\\)。 \\(B_1\\) \\(B_2\\) \\(A_1\\) \\(\\bar{Y}_{11}\\) \\(\\bar{Y}_{12}\\) \\(\\bar{Y}_{1.}\\) \\(A_2\\) \\(\\bar{Y}_{21}\\) \\(\\bar{Y}_{22}\\) \\(\\bar{Y}_{2.}\\) \\(\\bar{Y}_{.1}\\) \\(\\bar{Y}_{.2}\\) 区别简单交互效应和主交互效应的逻辑相同：在\\(ABC\\)设计中，\\(AB\\)的简单交互效应是在\\(C\\)的特定水平上\\(AB\\)交互效应；而\\(AB\\)的主交互效应是忽略\\(C\\)后\\(AB\\)的交互效应。后者是我们在三因子设计中通常讨论的低阶交互效应(lower-order interaction)。这也是标准ANOVA程序(如R的aov()函数、SPSS、SAS等)输出中所提供的内容。 4.5.2 主要编码方案 通常，编码方案的选择会影响对数据的解释： 截距项的解释 因子设计中除最高阶效应和(最高阶)交互效应之外的所有测试的解释。 它还会影响混合效应模型中随机效应的解释/估计(详见这篇博客)。如果你的设计只有一个两水平因素，并且使用了最大随机效应结构( maximal random-effects structure)，那么编码方案的选择实际上并不重要。 有许多可能的编码方案(详见?contr.treatment)。最相关的编码方案是处理(treatment)编码、求和(sum)编码和偏差(deviation)编码。求和编码和偏差编码可以被视为效应编码(effect coding)的特例——人们通常把那些编码总和为0的编码称为效应编码。 对于2水平因子，你可以使用下面代码： Scheme \\(A_1\\) \\(A_2\\) Treatment (dummy) \\(0\\) \\(1\\) Sum \\(-1\\) \\(1\\) Deviation \\(-\\frac{1}{2}\\) \\(\\frac{1}{2}\\) 默认情况下，R对模型中定义为=factor=的任何变量使用处理编码(详见?factor和?contrasts)。要了解为什么这对因子设计而言并不理想，可以考虑一个2x2x2的因子设计，因子包括\\(A\\)、\\(B\\) 和\\(C\\)。我们将只考虑一个完全的被试内设计，每个被试只有一个观测值，因为这允许我们使用最简单的可能的误差结构(error structure)。我们将使用lm()来拟合一个这样的模型： lm(Y ~ A * B * C) 下图详细说明了2x2x2设计的各种单元均值和边际均值的符号。 \\[C_1\\] \\(B_1\\) \\(B_2\\) \\(A_1\\) \\(\\bar{Y}_{111}\\) \\(\\bar{Y}_{121}\\) \\(\\bar{Y}_{1.1}\\) \\(A_2\\) \\(\\bar{Y}_{211}\\) \\(\\bar{Y}_{221}\\) \\(\\bar{Y}_{2.1}\\) \\(\\bar{Y}_{.11}\\) \\(\\bar{Y}_{.21}\\) \\[C_2\\] \\(B_1\\) \\(B_2\\) \\(A_1\\) \\(\\bar{Y}_{112}\\) \\(\\bar{Y}_{122}\\) \\(\\bar{Y}_{1.2}\\) \\(A_2\\) \\(\\bar{Y}_{212}\\) \\(\\bar{Y}_{222}\\) \\(\\bar{Y}_{2.2}\\) \\(\\bar{Y}_{.12}\\) \\(\\bar{Y}_{.22}\\) 下表提供了在三种不同编码方案下模型中各种效应的解释。注意，\\(Y\\)是因变量，下标的点表示“忽略”相应的维度。因此，\\(\\bar{Y}_{.1.}\\)是B_1的均值(忽略因子\\(A\\)和因子\\(C\\))，而\\(\\bar{Y}_{...}\\)是“总均值”(忽略所有因子)。 term treatment sum deviation \\(\\mu\\) \\(\\bar{Y}_{111}\\) \\(\\bar{Y}_{...}\\) \\(\\bar{Y}_{...}\\) \\(A\\) \\(\\bar{Y}_{211} - \\bar{Y}_{111}\\) \\(\\frac{(\\bar{Y}_{2..} - \\bar{Y}_{1..})}{2}\\) \\(\\bar{Y}_{2..} - \\bar{Y}_{1..}\\) \\(B\\) \\(\\bar{Y}_{121} - \\bar{Y}_{111}\\) \\(\\frac{(\\bar{Y}_{.2.} - \\bar{Y}_{.1.})}{2}\\) \\(\\bar{Y}_{.2.} - \\bar{Y}_{.1.}\\) \\(C\\) \\(\\bar{Y}_{112} - \\bar{Y}_{111}\\) \\(\\frac{(\\bar{Y}_{..2} - \\bar{Y}_{..1})}{2}\\) \\(\\bar{Y}_{..2} - \\bar{Y}_{..1}\\) \\(AB\\) \\((\\bar{Y}_{221} - \\bar{Y}_{121}) - (\\bar{Y}_{211} - \\bar{Y}_{111})\\) \\(\\frac{(\\bar{Y}_{22.} - \\bar{Y}_{12.}) - (\\bar{Y}_{21.} - \\bar{Y}_{11.})}{4}\\) \\((\\bar{Y}_{22.} - \\bar{Y}_{12.}) - (\\bar{Y}_{21.} - \\bar{Y}_{11.})\\) \\(AC\\) \\((\\bar{Y}_{212} - \\bar{Y}_{211}) - (\\bar{Y}_{112} - \\bar{Y}_{111})\\) \\(\\frac{(\\bar{Y}_{2.2} - \\bar{Y}_{1.2}) - (\\bar{Y}_{2.1} - \\bar{Y}_{1.1})}{4}\\) \\((\\bar{Y}_{2.2} - \\bar{Y}_{1.2}) - (\\bar{Y}_{2.1} - \\bar{Y}_{1.1})\\) \\(BC\\) \\((\\bar{Y}_{122} - \\bar{Y}_{112}) - (\\bar{Y}_{121} - \\bar{Y}_{111})\\) \\(\\frac{(\\bar{Y}_{.22} - \\bar{Y}_{.12}) - (\\bar{Y}_{.21} - \\bar{Y}_{.11})}{4}\\) \\((\\bar{Y}_{.22} - \\bar{Y}_{.12}) - (\\bar{Y}_{.21} - \\bar{Y}_{.11})\\) 对于三因子\\(A \\times B \\times C\\)的交互效应： scheme interpretation treatment \\(\\displaystyle\\left[\\displaystyle\\left(\\bar{Y}_{221} - \\bar{Y}_{121}\\right) - \\displaystyle\\left(\\bar{Y}_{211} - \\bar{Y}_{111}\\right)\\right] - \\displaystyle\\left[\\displaystyle\\left(\\bar{Y}_{222} - \\bar{Y}_{122}\\right) - \\displaystyle\\left(\\bar{Y}_{212} - \\bar{Y}_{112}\\right)\\right]\\) sum \\(\\frac{\\displaystyle\\left[\\displaystyle\\left(\\bar{Y}_{221} - \\bar{Y}_{121}\\right) - \\displaystyle\\left(\\bar{Y}_{211} - \\bar{Y}_{111}\\right)\\right] - \\displaystyle\\left[\\displaystyle\\left(\\bar{Y}_{222} - \\bar{Y}_{122}\\right) - \\displaystyle\\left(\\bar{Y}_{212} - \\bar{Y}_{112}\\right)\\right]}{8}\\) deviation \\(\\displaystyle\\left[\\displaystyle\\left(\\bar{Y}_{221} - \\bar{Y}_{121}\\right) - \\displaystyle\\left(\\bar{Y}_{211} - \\bar{Y}_{111}\\right)\\right] - \\displaystyle\\left[\\displaystyle\\left(\\bar{Y}_{222} - \\bar{Y}_{122}\\right) - \\displaystyle\\left(\\bar{Y}_{212} - \\bar{Y}_{112}\\right)\\right]\\) 请注意，尽管求和编码的参数估计值为其他方案的八分之一，但\\(A \\times B \\times C\\)的推断检验结果全部相同。对于所有低阶效应(lower-order effects)，求和编码和偏差编码将给出不同的参数估计，但相同的推断结果。这两种编码方案都对主效应和主交互效应提供了和3因素ANOVA中相同的检测。相反，处理(虚拟)编码将提供简单效应和简单交互效应的推断检测。因此，如果您感兴趣的是获得方差分析中的“经典”检测结果，请使用求和编码或偏差编码。 4.5.3 超过2水平的因子呢？ 一个具有\\(k\\)水平的因子需要\\(k-1\\)个变量。每个预测变量将因子的特定“目标”水平与你(任意地)选择为“基线”的水平进行对比。例如，对于一个3水平因子\\(A\\)，选择\\(A1\\)作为基线，你将有两个预测变量，一个比较\\(A2\\)和\\(A1\\)，另一个比较\\(A3\\)和\\(A1\\)。 对于处理(虚拟)编码，目标水平设置为1，否则为0。 对于求和编码，水平的总和必须为零，因此对于给定的预测变量，目标水平被赋值为1，基线水平被赋值为-1，任何其他水平被赋值为0。 对于偏差编码，值也必须总和为0。无论哪种情况，建议在尝试进行ANOVA式推断时使用偏差编码。根据这种方案，目标水平的值为\\(\\frac{k-1}{k}\\)，而任何非目标水平的值为\\(-\\frac{1}{k}\\)。 有趣的事实：对平衡数据进行均值中心处理编码(Mean-centering treatment codes)，你会得到偏差编码。 注：配合这篇知乎帖子阅读，有助理解。 4.5.4 举例：3水平因子 4.5.4.1 处理(虚拟)编码 level A2v1 A3v1 A1 0 0 A2 1 0 A3 0 1 4.5.4.2 求和编码 level A2v1 A3v1 A1 -1 -1 A2 1 0 A3 0 1 4.5.4.3 偏差编码 level A2v1 A3v1 A1 \\(-\\frac{1}{3}\\) \\(-\\frac{1}{3}\\) A2 \\(\\frac{2}{3}\\) \\(-\\frac{1}{3}\\) A3 \\(-\\frac{1}{3}\\) \\(\\frac{2}{3}\\) 4.5.4.4 举例：5水平因子 4.5.4.5 处理(虚拟)编码 level A2v1 A3v1 A4v1 A5v1 A1 0 0 0 0 A2 1 0 0 0 A3 0 1 0 0 A4 0 0 1 0 A5 0 0 0 1 4.5.4.6 求和编码 level A2v1 A3v1 A4v1 A5v1 A1 -1 -1 -1 -1 A2 1 0 0 0 A3 0 1 0 0 A4 0 0 1 0 A5 0 0 0 1 4.5.4.7 偏差编码 level A2v1 A3v1 A4v1 A5v1 A1 \\(-\\frac{1}{5}\\) \\(-\\frac{1}{5}\\) \\(-\\frac{1}{5}\\) \\(-\\frac{1}{5}\\) A2 \\(\\frac{4}{5}\\) \\(-\\frac{1}{5}\\) \\(-\\frac{1}{5}\\) \\(-\\frac{1}{5}\\) A3 \\(-\\frac{1}{5}\\) \\(\\frac{4}{5}\\) \\(-\\frac{1}{5}\\) \\(-\\frac{1}{5}\\) A4 \\(-\\frac{1}{5}\\) \\(-\\frac{1}{5}\\) \\(\\frac{4}{5}\\) \\(-\\frac{1}{5}\\) A5 \\(-\\frac{1}{5}\\) \\(-\\frac{1}{5}\\) \\(-\\frac{1}{5}\\) \\(\\frac{4}{5}\\) 4.5.5 如何创建你自己的数值型预测变量 让我们假设你的数据包含在如下所示的表dat中。 ## 创建你自己的数值型预测变量 ## 创建一个示例表 dat &lt;- tibble(Y = rnorm(12), A = rep(paste0(&quot;A&quot;, 1:3), each = 4)) 单击查看示例数据 Y A -0.41 A1 -1.44 A1 -2.01 A1 0.56 A1 -0.67 A2 1.00 A2 -1.61 A2 0.32 A2 -0.44 A3 1.19 A3 0.87 A3 -0.50 A3 4.5.5.1 mutate()、if_else()、case_when() 方法操作3水平因子 4.5.5.2 处理编码 ## 3水平因子示例 ## 处理编码 dat_treat &lt;- dat %&gt;% mutate(A2v1 = if_else(A == &quot;A2&quot;, 1L, 0L), A3v1 = if_else(A == &quot;A3&quot;, 1L, 0L)) 点击查看结果 ## # A tibble: 12 × 4 ## Y A A2v1 A3v1 ## &lt;dbl&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; ## 1 -0.410 A1 0 0 ## 2 -1.44 A1 0 0 ## 3 -2.01 A1 0 0 ## 4 0.562 A1 0 0 ## 5 -0.671 A2 1 0 ## 6 1.00 A2 1 0 ## 7 -1.61 A2 1 0 ## 8 0.322 A2 1 0 ## 9 -0.443 A3 0 1 ## 10 1.19 A3 0 1 ## 11 0.868 A3 0 1 ## 12 -0.500 A3 0 1 4.5.5.3 求和编码 ## 求和编码 dat_sum &lt;- dat %&gt;% mutate(A2v1 = case_when(A == &quot;A1&quot; ~ -1L, # 基线 A == &quot;A2&quot; ~ 1L, # 目标 TRUE ~ 0L), # 其他 A3v1 = case_when(A == &quot;A1&quot; ~ -1L, # 基线 A == &quot;A3&quot; ~ 1L, # 目标 TRUE ~ 0L)) # 其他 点击查看结果 ## # A tibble: 12 × 4 ## Y A A2v1 A3v1 ## &lt;dbl&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; ## 1 -0.410 A1 -1 -1 ## 2 -1.44 A1 -1 -1 ## 3 -2.01 A1 -1 -1 ## 4 0.562 A1 -1 -1 ## 5 -0.671 A2 1 0 ## 6 1.00 A2 1 0 ## 7 -1.61 A2 1 0 ## 8 0.322 A2 1 0 ## 9 -0.443 A3 0 1 ## 10 1.19 A3 0 1 ## 11 0.868 A3 0 1 ## 12 -0.500 A3 0 1 4.5.5.4 偏差编码 ## 偏差编码 ## 基线A1 dat_dev &lt;- dat %&gt;% mutate(A2v1 = if_else(A == &quot;A2&quot;, 2/3, -1/3), # 目标A2 A3v1 = if_else(A == &quot;A3&quot;, 2/3, -1/3)) # 目标A3 点击查看结果 dat_dev ## # A tibble: 12 × 4 ## Y A A2v1 A3v1 ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 -0.410 A1 -0.333 -0.333 ## 2 -1.44 A1 -0.333 -0.333 ## 3 -2.01 A1 -0.333 -0.333 ## 4 0.562 A1 -0.333 -0.333 ## 5 -0.671 A2 0.667 -0.333 ## 6 1.00 A2 0.667 -0.333 ## 7 -1.61 A2 0.667 -0.333 ## 8 0.322 A2 0.667 -0.333 ## 9 -0.443 A3 -0.333 0.667 ## 10 1.19 A3 -0.333 0.667 ## 11 0.868 A3 -0.333 0.667 ## 12 -0.500 A3 -0.333 0.667 4.5.6 小结 除最高阶效应外，所有效应的解释都取决于编码方案。 使用处理编码，你将查看简单效应和简单交互效应，而不是主效应和主交互效应。 求和编码的参数估计与偏差编码只在参数估计的大小上有所不同，但具有相同的解释。 由于偏差编码不受求和编码中的缩放效应的影响，因此在ANOVA式设计中应默认(建议)使用偏差编码。 R中因子的默认编码方案是“处理”编码。 因此，每当你将一个变量声明为factor类型，并将该变量用作回归模型中的预测变量时，R将自动创建处理编码操作后的变量。 要点：在R中使用回归来分析因子设计时，为了获得主效应和交互效应的经典ANOVA式解释，请使用偏差编码，而不是默认的处理编码。 参考文献 Lakens, D., Scheel, A. M., &amp; Isager, P. M. (2018). Equivalence testing for psychological research: A tutorial. Advances in Methods and Practices in Psychological Science, 1, 259–269. https://journals.sagepub.com/doi/abs/10.1177/2515245918770963 "],["介绍线性混合模型.html", "5 介绍线性混合模型 5.1 多层数据建模 5.2 如何对这些数据进行建模 5.3 使用混合效果模型的部分混合", " 5 介绍线性混合模型 5.1 多层数据建模 本章中的一些观点来自 McElreath (2020) 的《Statistical Rethinking》，还广泛借鉴了Tristan Mahr关于部分混合(partial pooling)的出色博客。 在本章中，我们将使用一些来自研究睡眠剥夺对心理运动能力(psychomotor performance)影响的真实数据(Belenky et al., 2003)。该研究的数据包含在R的lme4包中的内置数据集sleepstudy中(Bates et al., 2015)。 让我们从查看sleepstudy数据集的文档开始。加载lme4包后，你可以在控制台中输入?sleepstudy来访问文档。 注：这是对数据集文档的中文翻译 sleepstudy package:lme4 R Documentation 睡眠剥夺研究中的反应时 描述： 一项睡眠剥夺研究中，被试每天的平均反应时(以毫秒为单位)。 第0-1天为适应和训练阶段(T1/T2)，第2天为基线(B)；睡眠剥夺从第2天开始。 格式： 一个包含180个观测结果的数据框，其中包含以下3个变量： Reaction：平均反应时(毫秒) Days：睡眠剥夺的天数 Subject：进行观测的被试编号 详细信息： 这些数据来自Belenky et al.(2003)描述的研究，针对的是最严重的睡 眠剥夺组(每天仅睡3小时)和研究的前10天，直到恢复期。原始研究分析 了速度(1/反应时)，并将天数作为分类而非连续预测变量进行处理。 参考文献： Gregory Belenky, Nancy J. Wesensten, David R. Thorne, Maria L. Thomas, Helen C. Sing, Daniel P. Redmond, Michael B. Russo and Thomas J. Balkin (2003) Patterns of performance degradation and restoration during sleep restriction and subsequent recovery: a sleep dose-response study. _Journal of Sleep Research_ *12*, 1-12. 这些数据符合我们对多层数据的定义，因为在十天内对同一被试的同一因变量(平均反应时)进行了重复测量。这种类型的多层数据在心理学中非常常见。不幸的是，大多数心理学课程常用的统计教材对多层数据的讨论是不充分的，通常只涉及配对样本t检验和重复测量ANOVA。sleepstudy数据集很有趣，因为它是多层的，但有一个连续的预测变量，因此不适合t检验或ANOVA，因为这两种方法都是针对分类预测变量的。有方法可以让数据适应其中一个框架，但会丢失信息或可能违反假设。 遗憾的是，心理学专业的学生并没有真正学会如何分析多层数据。想想你最近读过的心理学或神经科学的研究。有多少研究是对每个被试只测量一次因变量？很少，如果有的话。几乎所有研究都进行了多次测量，因为以下一种或多种原因：(1)研究者在被试内设计中跨因子多水平测量同一被试；(2)他们有兴趣评估随时间的变化；或(3)他们在测量对多种刺激的反应。多层数据如此常见，以至于多层分析应该作为心理学中的默认方法来教授。学习多层分析可能具有挑战性，但你已经通过学习相关和回归掌握了大部分所需的知识。你会发现它只是简单回归的扩展。 让我们更详细地看看sleepstudy数据。该数据集包含来自三小时睡眠情况下的十八位被试。在为期十天的时间里，被试每天进行十分钟的“心理运动警觉性测试(psychomotor vigilance test)”，在每次出现刺激时尽快按下按钮。数据集中的因变量是被试在当天任务中的平均反应时(RT)。 开始分析的一个好方法是绘制数据图。下面是一个被试的数据。 library(lme4) library(tidyverse) just_308 &lt;- sleepstudy %&gt;% filter(Subject == &quot;308&quot;) ggplot(just_308, aes(x = Days, y = Reaction)) + geom_point() + scale_x_continuous(breaks = 0:9) 图5.1: Belenky et al.(2003)中单个被试的数据 练习 使用ggplot重现下面的图，这包含了所有18个被试。 图5.2: Belenky et al.(2003)中的数据 从第2天开始到第10天，RT似乎随着睡眠剥夺天数的增加而增加。 请提示 上面给出了绘制单个被试数据的代码。通过去掉filter()语句并添加以facet_开头的ggplot2函数，将此代码改为显示所有被试的数据。 展示答案 和上面一样，只是你要增加一行：facet_wrap(~Subject) ggplot(sleepstudy, aes(x = Days, y = Reaction)) + geom_point() + scale_x_continuous(breaks = 0:9) + facet_wrap(~Subject) 5.2 如何对这些数据进行建模 要合理地对数据进行建模，我们首先需要了解更多关于设计的信息 Belenky et al. (2003) 在他们的研究中是这样描述的(p. 2)： 前3天(T1、T2和B)是适应和训练(T1和T2)以及基线(B)，被试要求从23:00到07:00上床睡觉[在床时间(time in bed，TIB)为8小时]。在第3天(B)，进行了基线测量。从第4天开始，连续7天(E1-E7)，被试处于4种睡眠条件之一[TIB为9小时(22:00–07:00)，TIB为7小时(24:00–07:00)，TIB为5小时(02:00–07:00)或TIB为3小时(04:00–07:00)]，实际上是一种睡眠延长条件和三种睡眠限制条件。 从第3天之后的第1晚开始，有7晚的睡眠限制。前2天，编码为0、1，是适应(adaptation)和训练(training)。编码为2的那天是进行基线测量的时间，应该是我们分析开始的地方。如果我们将0和1两天包含在我们的分析中，可能会偏倚(bias)我们的结果，因为前两天的任何表现变化都与训练有关，而不是与睡眠限制有关。 练习 从数据集中删除Days编码为0或1的观察值，然后根据Days变量创建一个新的变量days_deprived，使序列从第2天开始，第2天重新编码为第0天，第3天为第1天，第4天为第2天，依此类推。这个新变量现在追踪睡眠剥夺的天数。将新表存储为sleep2。 展开答案 sleep2 &lt;- sleepstudy %&gt;% filter(Days &gt;= 2L) %&gt;% mutate(days_deprived = Days - 2L) 仔细检查代码是否按预期工作总是一个好主意。首先，看看它： head(sleep2) ## Reaction Days Subject days_deprived ## 1 250.8006 2 308 0 ## 2 321.4398 3 308 1 ## 3 356.8519 4 308 2 ## 4 414.6901 5 308 3 ## 5 382.2038 6 308 4 ## 6 290.1486 7 308 5 检查Days和days_deprivation是否匹配。 sleep2 %&gt;% count(days_deprived, Days) ## days_deprived Days n ## 1 0 2 18 ## 2 1 3 18 ## 3 2 4 18 ## 4 3 5 18 ## 5 4 6 18 ## 6 5 7 18 ## 7 6 8 18 ## 8 7 9 18 看起来很好. 请注意，由count()生成的变量n会告诉你Days和days_deprivation的每个唯一组合有多少行。在这种情况下有18行，每个被试1行。 现在让我们重新绘制数据，只查看从第0天到第7天的这8个数据点。我们已经从上面的代码中复制了代码，将sleepstudy替换为sleep2，并使用days_deprived作为我们的x变量。 ggplot(sleep2, aes(x = days_deprived, y = Reaction)) + geom_point() + scale_x_continuous(breaks = 0:7) + facet_wrap(~Subject) + labs(y = &quot;反应时&quot;, x = &quot;睡眠剥夺的天数(0 = 基线)&quot;) 图5.3: 数据来自Belenky et al.(2003)，显示了基线(0天)和每天睡眠剥夺后的反应时 请稍作思考，我们如何对days_deprived和Reaction之间的关系建模。随着睡眠剥夺的增加，反应时间是增加还是减少？这种关系大致稳定还是随时间变化？ 除了一个例外(335号被试)，看起来反应时随着睡眠剥夺的增加而增加。看起来我们可以对每位被试的数据拟合一条直线。回想一下，一条直线的一般方程形式为y = y轴截距 + 斜率 \\(\\times\\) x。在回归分析中，我们通常用以下公式表示线性关系： \\[Y = \\beta_0 + \\beta_1 X\\] 其中\\(\\beta_0\\)是y轴截距，\\(\\beta_1\\)是斜率，这些参数都是我们从数据中估计而来的。 这些线的截距(剥夺睡眠开始前第0天的平均RT)和斜率(每增加一天的睡眠剥夺后RT的变化)都不同。但我们应该为每个被试拟合同一条线吗？还是每个被试拟合完全不同的线？或者介于两者之间的某种情况？ 让我们首先考虑可能用到的三种不同方法。根据McElreath的说法，我们将这些方法称为完全混合(complete pooling)、不混合(no pooling)和部分混合(partial pooling)。 5.2.1 完全混合：一刀切 完全混合是一种“一刀切”模型：它为整个数据集估计单一的截距和斜率，忽略了不同被试在截距或斜率上可能存在的差异。如果这听起来像是一种糟糕的方法，那确实是对的；但你知道这一点是因为你已经可视化了数据，并注意到每个参与者的模式似乎需要不同的y轴截距和斜率值。 拟合出一条线称为“完全混合”方法，因为我们将所有被试的数据混合在一起，得到总体截距和斜率的单一估计。该方法的广义线性模型(GLM)简单地表示为： \\[Y_{sd} = \\beta_0 + \\beta_1 X_{sd} + e_{sd}\\] \\[e_{sd} \\sim N\\left(0, \\sigma^2\\right)\\] 其中\\(Y_{sd}\\)是被试\\(s\\)在第\\(d\\)天的平均反应时，\\(X_{sd}\\)是与该情况相关的days_deprived值(0-7)，\\(e_{sd}\\)是误差。 我们可以在R中用lm()函数拟合一个这样的模型，如下： cp_model &lt;- lm(Reaction ~ days_deprived, sleep2) summary(cp_model) ## ## Call: ## lm(formula = Reaction ~ days_deprived, data = sleep2) ## ## Residuals: ## Min 1Q Median 3Q Max ## -112.284 -26.732 2.143 27.734 140.453 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 267.967 7.737 34.633 &lt; 2e-16 *** ## days_deprived 11.435 1.850 6.183 6.32e-09 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 50.85 on 142 degrees of freedom ## Multiple R-squared: 0.2121, Adjusted R-squared: 0.2066 ## F-statistic: 38.23 on 1 and 142 DF, p-value: 6.316e-09 根据这个模型，第0天的预测平均反应时约为268毫秒，随着剥夺天数的增加，每天的反应时平均增加约11毫秒。然而，我们不能相信回归系数的标准误，因为我们假设所有的观测值都是独立的(严格来说是残差独立)。但我们可以很确定这是一个糟糕的假设。 让我们把模型预测值添加到我们之前创建的图中。我们可以使用geom_abline()来做到这一点，指定截距和斜率为模型拟合的回归系数coef(cp_model)，该函数返回一个包含截距和斜率两个元素的向量。 coef(cp_model) ## (Intercept) days_deprived ## 267.96742 11.43543 ggplot(sleep2, aes(x = days_deprived, y = Reaction)) + geom_abline(intercept = coef(cp_model)[1], slope = coef(cp_model)[2], color = &#39;blue&#39;) + geom_point() + scale_x_continuous(breaks = 0:7) + facet_wrap(~Subject) + labs(y = &quot;反应时&quot;, x = &quot;睡眠剥夺的天数(0 = 基线)&quot;) 图5.4: 数据根据完全混合模型的预测结果绘制 这个模型与数据不太吻合。我们需要一种不同的方法。 5.2.2 不混合 将所有信息混合成一个截距和一个斜率来估计是不合适的。另一种方法是为每个被试拟合单独的线。这意味着每个被试的估计值将完全不受其他被试估计值的影响。换句话说，我们可以分别估计18组单独的截距/斜率对。 这个模型可以通过两种方式实现：(1)为每个被试运行单独的回归或(2)运行混合效应回归。我们将采用后者，这样所有内容都在一个大模型中。我们已经知道了如何做到这一点：我们为Subject因子添加虚拟编码。这个因子有18个水平，所以我们需要17个虚拟编码。幸运的是，R为我们省去了手动创建这17个变量的麻烦。我们只需要在模型中纳入Subject作为预测变量，并将这个分类预测变量与days_deprived进行交互，以允许截距和斜率变化。 sleep2数据集中的变量Subject是名义变量。我们只是用数字作为标签来保证匿名性，并不意味着被试310比被试309好1点，或者比被试308好2点。确保将其定义为因子变量，而不是作为连续变量包含在内！ 我们可以通过多种方式测试某个变量是否为因子变量。其中一种方法是对表格使用summary()函数。 sleep2 %&gt;% summary() ## Reaction Days Subject days_deprived ## Min. :203.0 Min. :2.00 308 : 8 Min. :0.00 ## 1st Qu.:265.2 1st Qu.:3.75 309 : 8 1st Qu.:1.75 ## Median :303.2 Median :5.50 310 : 8 Median :3.50 ## Mean :308.0 Mean :5.50 330 : 8 Mean :3.50 ## 3rd Qu.:347.7 3rd Qu.:7.25 331 : 8 3rd Qu.:5.25 ## Max. :466.4 Max. :9.00 332 : 8 Max. :7.00 ## (Other):96 这里你可以看到它并没有被当做一个数字变量，因为它没给出分布信息(均值等)，而是告诉你在每个水平上有多少个观测值。 你也可以直接测试它： sleep2 %&gt;% pull(Subject) %&gt;% is.factor() ## [1] TRUE 如果某些变量不是因子变量，你可以使用factor()函数重新定义它，使其变为因子变量。 np_model &lt;- lm(Reaction ~ days_deprived + Subject + days_deprived:Subject, data = sleep2) summary(np_model) ## ## Call: ## lm(formula = Reaction ~ days_deprived + Subject + days_deprived:Subject, ## data = sleep2) ## ## Residuals: ## Min 1Q Median 3Q Max ## -106.521 -8.541 1.143 8.889 128.545 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 288.2175 16.4772 17.492 &lt; 2e-16 *** ## days_deprived 21.6905 3.9388 5.507 2.49e-07 *** ## Subject309 -87.9262 23.3023 -3.773 0.000264 *** ## Subject310 -62.2856 23.3023 -2.673 0.008685 ** ## Subject330 -14.9533 23.3023 -0.642 0.522422 ## Subject331 9.9658 23.3023 0.428 0.669740 ## Subject332 27.8157 23.3023 1.194 0.235215 ## Subject333 -2.7581 23.3023 -0.118 0.906000 ## Subject334 -50.2051 23.3023 -2.155 0.033422 * ## Subject335 -25.3429 23.3023 -1.088 0.279207 ## Subject337 24.6143 23.3023 1.056 0.293187 ## Subject349 -59.2183 23.3023 -2.541 0.012464 * ## Subject350 -40.2023 23.3023 -1.725 0.087343 . ## Subject351 -24.2467 23.3023 -1.041 0.300419 ## Subject352 43.0655 23.3023 1.848 0.067321 . ## Subject369 -21.5040 23.3023 -0.923 0.358154 ## Subject370 -53.3072 23.3023 -2.288 0.024107 * ## Subject371 -30.4896 23.3023 -1.308 0.193504 ## Subject372 2.4772 23.3023 0.106 0.915535 ## days_deprived:Subject309 -17.3334 5.5703 -3.112 0.002380 ** ## days_deprived:Subject310 -17.7915 5.5703 -3.194 0.001839 ** ## days_deprived:Subject330 -13.6849 5.5703 -2.457 0.015613 * ## days_deprived:Subject331 -16.8231 5.5703 -3.020 0.003154 ** ## days_deprived:Subject332 -19.2947 5.5703 -3.464 0.000765 *** ## days_deprived:Subject333 -10.8151 5.5703 -1.942 0.054796 . ## days_deprived:Subject334 -3.5745 5.5703 -0.642 0.522423 ## days_deprived:Subject335 -25.8995 5.5703 -4.650 9.47e-06 *** ## days_deprived:Subject337 0.7518 5.5703 0.135 0.892895 ## days_deprived:Subject349 -5.2644 5.5703 -0.945 0.346731 ## days_deprived:Subject350 1.6007 5.5703 0.287 0.774382 ## days_deprived:Subject351 -13.1681 5.5703 -2.364 0.019867 * ## days_deprived:Subject352 -14.4019 5.5703 -2.585 0.011057 * ## days_deprived:Subject369 -7.8948 5.5703 -1.417 0.159273 ## days_deprived:Subject370 -1.0495 5.5703 -0.188 0.850912 ## days_deprived:Subject371 -9.3443 5.5703 -1.678 0.096334 . ## days_deprived:Subject372 -10.6041 5.5703 -1.904 0.059613 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 25.53 on 108 degrees of freedom ## Multiple R-squared: 0.849, Adjusted R-squared: 0.8001 ## F-statistic: 17.35 on 35 and 108 DF, p-value: &lt; 2.2e-16 这个模型将一个被试(具体来说是被试308)作为基线，并通过偏移量来表示每个被试相对于该基线的差异。在我们之前讨论连续变量-分类变量交互效应时你已经看过这种方法了。 回答这些问题(结果保留三位小数) 被试308的截距是多少？ 被试308的斜率是多少？ 被试335的截距是多少？ 被试335的斜率是多少？ 答案和解析 基线被试是308——R中默认按字母顺序排列因子的水平，并选择第一个作为基线。这意味着对于被试308，截距由(Intercept)给出，而斜率由days_deprived给出，因为其他17个虚拟变量对被试308而言都是0。 所有其他被试的回归系数都表示为相对于此基线被试的偏移量。如果我们想计算特定受试者的截距和斜率，只需加上相应的偏移量即可。因此，答案如下： 被试308的截距: 288.217 被试308的斜率: 21.69 被试355的截距: (Intercept) + Subject335 = 288.217 + -25.343 = 262.874 被试355的斜率: days_deprived + days_deprived:Subject335 = 21.69 + -25.899 = -4.209 在“不混合”模型中，没有整个总体截距和斜率的估计；在这种情况下，(Intercept)和days_deprived是被试308的截距和斜率的估计，因为被试308被(随意地)选择为基线被试。为了得到总体的估计值，我们可以引入第二阶段分析，计算各个被试的截距和斜率的平均值。让我们使用模型估计值来计算每个被试的截距和斜率。 all_intercepts &lt;- c(coef(np_model)[&quot;(Intercept)&quot;], coef(np_model)[3:19] + coef(np_model)[&quot;(Intercept)&quot;]) all_slopes &lt;- c(coef(np_model)[&quot;days_deprived&quot;], coef(np_model)[20:36] + coef(np_model)[&quot;days_deprived&quot;]) ids &lt;- sleep2 %&gt;% pull(Subject) %&gt;% levels() %&gt;% factor() # 用上面提取的数据创建一个tibble np_coef &lt;- tibble(Subject = ids, intercept = all_intercepts, slope = all_slopes) np_coef ## # A tibble: 18 × 3 ## Subject intercept slope ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 308 288. 21.7 ## 2 309 200. 4.36 ## 3 310 226. 3.90 ## 4 330 273. 8.01 ## 5 331 298. 4.87 ## 6 332 316. 2.40 ## 7 333 285. 10.9 ## 8 334 238. 18.1 ## 9 335 263. -4.21 ## 10 337 313. 22.4 ## 11 349 229. 16.4 ## 12 350 248. 23.3 ## 13 351 264. 8.52 ## 14 352 331. 7.29 ## 15 369 267. 13.8 ## 16 370 235. 20.6 ## 17 371 258. 12.3 ## 18 372 291. 11.1 让我们看看这个模型拟合数据的效果有多好。 ggplot(sleep2, aes(x = days_deprived, y = Reaction)) + geom_abline(data = np_coef, mapping = aes(intercept = intercept, slope = slope), color = &#39;blue&#39;) + geom_point() + scale_x_continuous(breaks = 0:7) + facet_wrap(~Subject) + labs(y = &quot;反应时&quot;, x = &quot;睡眠剥夺的天数(0 = 基线)&quot;) 图5.5: 数据根据不混合方法的拟合结果绘制 这比完全混合模型要好得多。如果要检验固定斜率为0的原假设，可以用单样本检验。 np_coef %&gt;% pull(slope) %&gt;% t.test() ## ## One Sample t-test ## ## data: . ## t = 6.1971, df = 17, p-value = 9.749e-06 ## alternative hypothesis: true mean is not equal to 0 ## 95 percent confidence interval: ## 7.542244 15.328613 ## sample estimates: ## mean of x ## 11.43543 这告诉我们平均斜率 11.435 显著不等于0, t(17) = 6.197, \\(p &lt; .001\\). 5.3 使用混合效果模型的部分混合 完全混合或不混合方法都不是令人满意的。如果我们能够利用对其他被试的了解来改进对单个被试的估计，那将是可取的。这将有助于更好地区分每个被试的信号(signal)和误差(error)，并提高对总体的可推广性。正如最下面的网页APP所示，当我们有不平衡或缺失的数据时，这变得尤为重要。 在不混合模型中，我们将Subject视为一个固定因子(fixed factor)。每对截距和斜率的估计仅由该被试的数据决定。然而，我们对这18个被试本身并不感兴趣；我们更感兴趣的是他们作为具有潜在被试的更大群体的代表。如果你的目标是推广到你感兴趣的群体中的新被试，那么这种被试作为固定效应因子的方法是不够优化的。 部分混合发生在你将一个因子视为随机因子而不是固定因子进行分析时。随机因子(random factor)是指其水平被认为代表所有潜在水平的一个真子集(proper subset)。通常情况下，当你数据中的水平是抽样结果，并且你希望推广到超出这些水平的范围时，你会将一个因子视为随机。在这种情况下，我们有18个独特被试，因此有18个Subject因子的水平，希望能够对潜在被试群体中睡眠剥夺效应做出一些一般性的陈述。 参考文献 Bates, D., Maechler, M., Bolker, B., &amp; Walker, S. (2015). Fitting linear mixed-effects models using lme4. Journal of Statistical Software, 67, 1–48. Belenky, G., Wesensten, N. J., Thorne, D. R., Thomas, M. L., Sing, H. C., Redmond, D. P., Russo, M. B., &amp; Balkin, T. J. (2003). Patterns of performance degradation and restoration during sleep restriction and subsequent recovery: A sleep dose-response study. Journal of Sleep Research, 12(1), 1–12. McElreath, R. (2020). Statistical Rethinking: A Bayesian course with examples in R and STAN. CRC Press. "],["参考文献.html", "参考文献", " 参考文献 Bates, D., Maechler, M., Bolker, B., &amp; Walker, S. (2015). Fitting linear mixed-effects models using lme4. Journal of Statistical Software, 67, 1–48. Belenky, G., Wesensten, N. J., Thorne, D. R., Thomas, M. L., Sing, H. C., Redmond, D. P., Russo, M. B., &amp; Balkin, T. J. (2003). Patterns of performance degradation and restoration during sleep restriction and subsequent recovery: A sleep dose-response study. Journal of Sleep Research, 12(1), 1–12. Fraley, R. C., Gillath, O., &amp; Deboeck, P. R. (2021). Do life events lead to enduring changes in adult attachment styles? A naturalistic longitudinal investigation. Journal of Personality and Social Psychology, 120(6), 1567–1606. Lakens, D., Scheel, A. M., &amp; Isager, P. M. (2018). Equivalence testing for psychological research: A tutorial. Advances in Methods and Practices in Psychological Science, 1, 259–269. https://journals.sagepub.com/doi/abs/10.1177/2515245918770963 McElreath, R. (2020). Statistical Rethinking: A Bayesian course with examples in R and STAN. CRC Press. Vanhove, J. (2021). Collinearity isn’t a disease that needs curing. Meta-Psychology, 5. Yarkoni, T. (2019). The generalizability crisis. https://doi.org/10.31234/osf.io/jqw35 "]]
